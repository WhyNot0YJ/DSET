#!/usr/bin/env python3
"""YOLOv8 æ‰¹é‡æ¨ç†è„šæœ¬ - å¤„ç†æ•´ä¸ªå›¾åƒç›®å½•"""

import sys
import argparse
import yaml
import torch
import cv2
import numpy as np
from pathlib import Path

try:
    from tqdm import tqdm
    HAS_TQDM = True
except ImportError:
    HAS_TQDM = False
    class SimpleProgress:
        def __init__(self, iterable, desc=""):
            self.iterable = iterable
            self.desc = desc
            self.total = len(iterable)
            self.current = 0
            print(f"{desc}: å¼€å§‹å¤„ç† {self.total} ä¸ªæ–‡ä»¶...")
        
        def __iter__(self):
            for item in self.iterable:
                self.current += 1
                if self.current % 10 == 0 or self.current == self.total:
                    print(f"  è¿›åº¦: {self.current}/{self.total} ({100*self.current/self.total:.1f}%)")
                yield item
    
    def tqdm(iterable, desc=""):
        return SimpleProgress(iterable, desc) if not HAS_TQDM else iterable

# æ·»åŠ é¡¹ç›®è·¯å¾„
project_root = Path(__file__).parent.resolve()
if str(project_root) not in sys.path:
    sys.path.insert(0, str(project_root))
if str(project_root.parent) not in sys.path:
    sys.path.insert(0, str(project_root.parent))

from ultralytics import YOLO

# ç±»åˆ«åç§°å’Œé¢œè‰²ï¼ˆç”¨äºå¯è§†åŒ–ï¼‰- 8ç±»
CLASS_NAMES = [
    "Car", "Truck", "Van", "Bus", "Pedestrian", 
    "Cyclist", "Motorcyclist", "Trafficcone"
]
COLORS = [
    (255, 0, 0),      # Car - çº¢è‰²
    (0, 255, 0),      # Truck - ç»¿è‰²
    (255, 128, 0),    # Van - æ©™è‰²
    (0, 0, 255),      # Bus - è“è‰²
    (255, 255, 0),    # Pedestrian - é»„è‰²
    (255, 0, 255),    # Cyclist - å“çº¢
    (0, 255, 255),    # Motorcyclist - é’è‰²
    (128, 128, 128),  # Trafficcone - ç°è‰²
]


def load_model(checkpoint_path: str, device: str = "cuda"):
    """åŠ è½½YOLOæ¨¡å‹"""
    print(f"ğŸ“¦ åŠ è½½æ¨¡å‹: {checkpoint_path}")
    
    if not Path(checkpoint_path).exists():
        raise FileNotFoundError(f"æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {checkpoint_path}")
    
    model = YOLO(checkpoint_path)
    model.to(device)
    model.eval()
    
    print(f"âœ“ æ¨¡å‹åŠ è½½å®Œæˆ")
    return model


def draw_boxes(image, boxes, labels, scores, conf_threshold=0.3):
    """åœ¨å›¾åƒä¸Šç»˜åˆ¶æ£€æµ‹æ¡†
    
    Args:
        image: è¾“å…¥å›¾åƒ (BGRæ ¼å¼ï¼ŒOpenCVæ ¼å¼)
        boxes: è¾¹ç•Œæ¡†åˆ—è¡¨ï¼Œæ ¼å¼ä¸º [[x1, y1, x2, y2], ...]
        labels: ç±»åˆ«æ ‡ç­¾åˆ—è¡¨
        scores: ç½®ä¿¡åº¦åˆ—è¡¨
        conf_threshold: ç½®ä¿¡åº¦é˜ˆå€¼
    
    Returns:
        ç»˜åˆ¶äº†æ£€æµ‹æ¡†çš„å›¾åƒ
    """
    image = image.copy()
    
    for box, label, score in zip(boxes, labels, scores):
        if score < conf_threshold:
            continue
        
        x1, y1, x2, y2 = map(int, box)
        
        # è·å–ç±»åˆ«é¢œè‰²
        color = COLORS[label] if label < len(COLORS) else (255, 255, 255)
        
        # ç»˜åˆ¶è¾¹ç•Œæ¡†
        cv2.rectangle(image, (x1, y1), (x2, y2), color, 2)
        
        # å‡†å¤‡æ ‡ç­¾æ–‡æœ¬
        class_name = CLASS_NAMES[label] if label < len(CLASS_NAMES) else f"Class_{label}"
        label_text = f"{class_name} {score:.2f}"
        
        # è®¡ç®—æ–‡æœ¬å¤§å°
        (text_width, text_height), baseline = cv2.getTextSize(
            label_text, cv2.FONT_HERSHEY_SIMPLEX, 0.5, 1
        )
        
        # ç»˜åˆ¶æ–‡æœ¬èƒŒæ™¯
        cv2.rectangle(
            image,
            (x1, y1 - text_height - baseline - 5),
            (x1 + text_width, y1),
            color,
            -1
        )
        
        # ç»˜åˆ¶æ–‡æœ¬
        cv2.putText(
            image,
            label_text,
            (x1, y1 - baseline - 2),
            cv2.FONT_HERSHEY_SIMPLEX,
            0.5,
            (255, 255, 255),
            1
        )
    
    return image


def inference_image(model, image_path: str, conf_threshold: float = 0.3, device: str = "cuda"):
    """å¯¹å•å¼ å›¾åƒè¿›è¡Œæ¨ç†
    
    Args:
        model: YOLOæ¨¡å‹
        image_path: å›¾åƒè·¯å¾„
        conf_threshold: ç½®ä¿¡åº¦é˜ˆå€¼
        device: è®¾å¤‡
    
    Returns:
        (boxes, labels, scores): æ£€æµ‹ç»“æœ
    """
    # ä½¿ç”¨YOLOçš„predictæ–¹æ³•
    results = model.predict(
        source=str(image_path),
        conf=conf_threshold,
        device=device,
        verbose=False
    )
    
    # è§£æç»“æœ
    if len(results) == 0:
        return [], [], []
    
    result = results[0]
    
    # æå–æ£€æµ‹ç»“æœ
    boxes = []
    labels = []
    scores = []
    
    if result.boxes is not None:
        boxes_tensor = result.boxes.xyxy.cpu().numpy()  # [N, 4] xyxyæ ¼å¼
        labels_tensor = result.boxes.cls.cpu().numpy().astype(int)  # [N]
        scores_tensor = result.boxes.conf.cpu().numpy()  # [N]
        
        for box, label, score in zip(boxes_tensor, labels_tensor, scores_tensor):
            boxes.append(box.tolist())
            labels.append(int(label))
            scores.append(float(score))
    
    return boxes, labels, scores


def batch_inference(
    model,
    image_dir: str,
    output_dir: str,
    conf_threshold: float = 0.5,
    device: str = "cuda",
    max_images: int = None
):
    """æ‰¹é‡æ¨ç†
    
    Args:
        model: YOLOæ¨¡å‹
        image_dir: è¾“å…¥å›¾åƒç›®å½•
        output_dir: è¾“å‡ºç›®å½•
        conf_threshold: ç½®ä¿¡åº¦é˜ˆå€¼
        device: è®¾å¤‡
        max_images: æœ€å¤§å¤„ç†å›¾åƒæ•°ï¼ˆNoneè¡¨ç¤ºå¤„ç†æ‰€æœ‰ï¼‰
    """
    image_dir = Path(image_dir)
    output_dir = Path(output_dir)
    output_dir.mkdir(parents=True, exist_ok=True)
    
    # è·å–æ‰€æœ‰å›¾åƒæ–‡ä»¶
    image_extensions = ['.jpg', '.jpeg', '.png', '.bmp']
    image_files = []
    for ext in image_extensions:
        image_files.extend(list(image_dir.glob(f"*{ext}")))
        image_files.extend(list(image_dir.glob(f"*{ext.upper()}")))
    
    image_files = sorted(image_files)
    
    if max_images is not None:
        image_files = image_files[:max_images]
    
    print(f"ğŸ“¸ æ‰¾åˆ° {len(image_files)} å¼ å›¾åƒ")
    
    # æ‰¹é‡å¤„ç†
    processed_count = 0
    total_detections = 0
    
    for image_path in tqdm(image_files, desc="å¤„ç†å›¾åƒ"):
        try:
            # æ¨ç†
            boxes, labels, scores = inference_image(
                model, str(image_path), conf_threshold, device
            )
            
            # åŠ è½½åŸå§‹å›¾åƒç”¨äºç»˜åˆ¶
            image = cv2.imread(str(image_path))
            if image is None:
                print(f"âš ï¸  æ— æ³•è¯»å–å›¾åƒ: {image_path}")
                continue
            
            # ç»˜åˆ¶æ£€æµ‹æ¡†
            result_image = draw_boxes(image, boxes, labels, scores, conf_threshold)
            
            # ä¿å­˜ç»“æœ
            output_path = output_dir / image_path.name
            cv2.imwrite(str(output_path), result_image)
            
            processed_count += 1
            total_detections += len(boxes)
            
        except Exception as e:
            print(f"âš ï¸  å¤„ç†å›¾åƒå¤±è´¥ {image_path}: {e}")
            continue
    
    print(f"\nâœ… æ‰¹é‡æ¨ç†å®Œæˆï¼")
    print(f"  å¤„ç†å›¾åƒæ•°: {processed_count}/{len(image_files)}")
    print(f"  æ€»æ£€æµ‹æ•°: {total_detections}")
    print(f"  å¹³å‡æ¯å¼ å›¾åƒ: {total_detections/max(processed_count, 1):.2f} ä¸ªæ£€æµ‹")
    print(f"  ç»“æœä¿å­˜åœ¨: {output_dir}")


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description='YOLOv8æ‰¹é‡æ¨ç†è„šæœ¬')
    parser.add_argument('--checkpoint', type=str, required=True,
                       help='æ¨¡å‹æ£€æŸ¥ç‚¹è·¯å¾„ï¼ˆ.ptæ–‡ä»¶ï¼‰')
    parser.add_argument('--image_dir', type=str, required=True,
                       help='è¾“å…¥å›¾åƒç›®å½•')
    parser.add_argument('--output_dir', type=str, required=True,
                       help='è¾“å‡ºç›®å½•')
    parser.add_argument('--conf', type=float, default=0.5,
                       help='ç½®ä¿¡åº¦é˜ˆå€¼ï¼ˆé»˜è®¤: 0.5ï¼‰')
    parser.add_argument('--device', type=str, default='cuda',
                       help='è®¾å¤‡ï¼ˆé»˜è®¤: cudaï¼‰')
    parser.add_argument('--max_images', type=int, default=None,
                       help='æœ€å¤§å¤„ç†å›¾åƒæ•°ï¼ˆé»˜è®¤: å¤„ç†æ‰€æœ‰ï¼‰')
    
    args = parser.parse_args()
    
    print("="*60)
    print("ğŸš€ YOLOv8 æ‰¹é‡æ¨ç†")
    print("="*60)
    print(f"æ¨¡å‹: {args.checkpoint}")
    print(f"è¾“å…¥ç›®å½•: {args.image_dir}")
    print(f"è¾“å‡ºç›®å½•: {args.output_dir}")
    print(f"ç½®ä¿¡åº¦é˜ˆå€¼: {args.conf}")
    print(f"è®¾å¤‡: {args.device}")
    if args.max_images:
        print(f"æœ€å¤§å¤„ç†æ•°: {args.max_images}")
    print("="*60)
    
    # åŠ è½½æ¨¡å‹
    model = load_model(args.checkpoint, args.device)
    
    # æ‰¹é‡æ¨ç†
    batch_inference(
        model=model,
        image_dir=args.image_dir,
        output_dir=args.output_dir,
        conf_threshold=args.conf,
        device=args.device,
        max_images=args.max_images
    )


if __name__ == '__main__':
    main()


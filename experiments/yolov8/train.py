#!/usr/bin/env python3
"""
YOLOv8è®­ç»ƒè„šæœ¬ - æ”¯æŒDAIR-V2Xæ•°æ®é›†
"""

import sys
import os
import argparse
import yaml
import torch
import logging
import pandas as pd
import matplotlib.pyplot as plt
import numpy as np
from pathlib import Path
from datetime import datetime
from typing import Optional, Dict

# æ·»åŠ é¡¹ç›®è·¯å¾„
project_root = Path(__file__).parent.resolve()
if str(project_root) not in sys.path:
    sys.path.insert(0, str(project_root))
if str(project_root.parent) not in sys.path:
    sys.path.insert(0, str(project_root.parent))

# å¯¼å…¥ultralyticsï¼ˆæœ¬åœ°å‰¯æœ¬ï¼‰
from ultralytics import YOLO

# DAIR-V2Xç±»åˆ«å®šä¹‰ï¼ˆ8ç±»ï¼‰
CLASS_NAMES = [
    "Car", "Truck", "Van", "Bus", "Pedestrian", 
    "Cyclist", "Motorcyclist", "Trafficcone"
]


class YOLOv8Trainer:
    """YOLOv8è®­ç»ƒå™¨ - é€‚é…DAIR-V2Xæ•°æ®é›†"""
    
    def __init__(self, config: Dict, config_path: Optional[str] = None):
        """
        åˆå§‹åŒ–è®­ç»ƒå™¨
        
        Args:
            config: é…ç½®å­—å…¸
            config_path: é…ç½®æ–‡ä»¶è·¯å¾„ï¼ˆç”¨äºä¿å­˜ï¼‰
        """
        self.config = config
        self.config_path = config_path
        
        # è®¾ç½®æ—¥å¿—
        self.setup_logging()
        
        # éªŒè¯é…ç½®
        self._validate_config()
        
        # è·å–é…ç½®å‚æ•°
        self.model_config = config.get('model', {})
        self.training_config = config.get('training', {})
        self.data_config = config.get('data', {})
        self.checkpoint_config = config.get('checkpoint', {})
        self.misc_config = config.get('misc', {})
        
        # ç±»åˆ«ä¿¡æ¯
        self.class_names = CLASS_NAMES
        self.num_classes = len(CLASS_NAMES)
        
        self.logger.info(f"âœ“ åˆå§‹åŒ–YOLOv8è®­ç»ƒå™¨")
        self.logger.info(f"  ç±»åˆ«æ•°é‡: {self.num_classes}")
        self.logger.info(f"  ç±»åˆ«: {', '.join(self.class_names)}")
    
    def _validate_config(self):
        """éªŒè¯é…ç½®æ–‡ä»¶"""
        required_keys = {
            'model': ['model_name'],
            'training': ['epochs', 'batch_size'],
            'data': ['data_yaml']
        }
        
        missing_keys = []
        for section, keys in required_keys.items():
            if section not in self.config:
                missing_keys.append(f"ç¼ºå°‘é…ç½®èŠ‚: {section}")
                continue
            for key in keys:
                if key not in self.config[section]:
                    missing_keys.append(f"{section}.{key}")
        
        if missing_keys:
            error_msg = f"é…ç½®æ–‡ä»¶ç¼ºå°‘å¿…éœ€çš„é…ç½®é¡¹:\n"
            error_msg += "\n".join(f"  - {key}" for key in missing_keys)
            raise ValueError(error_msg)
    
    def setup_logging(self):
        """è®¾ç½®æ—¥å¿—ç³»ç»Ÿ"""
        # æ£€æŸ¥æ˜¯å¦ä»æ£€æŸ¥ç‚¹æ¢å¤
        resume_checkpoint = getattr(self, '_resume_checkpoint_path', None)
        
        if resume_checkpoint and Path(resume_checkpoint).exists():
            # æ¢å¤è®­ç»ƒï¼šä½¿ç”¨æ£€æŸ¥ç‚¹æ‰€åœ¨ç›®å½•
            self.log_dir = Path(resume_checkpoint).parent
            self.experiment_name = self.log_dir.name
        else:
            # æ–°è®­ç»ƒï¼šåˆ›å»ºå¸¦æ—¶é—´æˆ³çš„ç›®å½•
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            model_name = self.config.get('model', {}).get('model_name', 'yolov8n')
            self.experiment_name = f"yolo_{model_name.replace('yolov8', 'v8').replace('yolo11', 'v11')}"
            log_base = self.checkpoint_config.get('log_dir', 'logs')
            self.log_dir = Path(f"{log_base}/{self.experiment_name}_{timestamp}")
            self.log_dir.mkdir(parents=True, exist_ok=True)
        
        # é…ç½®æ—¥å¿—å¤„ç†å™¨
        handlers = [
            logging.FileHandler(self.log_dir / 'training.log', mode='a'),
            logging.StreamHandler()
        ]
        
        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s - %(levelname)s - %(message)s',
            handlers=handlers,
            force=True
        )
        
        self.logger = logging.getLogger(__name__)
        
        # ä¿å­˜é…ç½®æ–‡ä»¶ï¼ˆä»…æ–°è®­ç»ƒæ—¶ï¼‰
        if not resume_checkpoint:
            config_save_path = self.log_dir / 'config.yaml'
            with open(config_save_path, 'w', encoding='utf-8') as f:
                yaml.dump(self.config, f, default_flow_style=False, allow_unicode=True)
            self.logger.info(f"âœ“ é…ç½®å·²ä¿å­˜åˆ°: {config_save_path}")
    
    def create_model(self):
        """åˆ›å»ºYOLOæ¨¡å‹"""
        model_name = self.model_config.get('model_name', 'yolov8n.pt')
        pretrained_weights = self.model_config.get('pretrained_weights', None)
        
        # å¦‚æœæŒ‡å®šäº†é¢„è®­ç»ƒæƒé‡ï¼Œä½¿ç”¨å®ƒï¼›å¦åˆ™ä½¿ç”¨æ¨¡å‹åç§°
        if pretrained_weights and Path(pretrained_weights).exists():
            self.logger.info(f"âœ“ åŠ è½½é¢„è®­ç»ƒæƒé‡: {pretrained_weights}")
            model = YOLO(pretrained_weights)
        else:
            self.logger.info(f"âœ“ åˆ›å»ºæ¨¡å‹: {model_name}")
            model = YOLO(model_name)
        
        # YOLOæ¨¡å‹åœ¨è®­ç»ƒæ—¶ä¼šè‡ªåŠ¨ä»data.yamlè¯»å–ç±»åˆ«æ•°å¹¶è°ƒæ•´æ¨¡å‹
        # è¿™é‡Œæˆ‘ä»¬åªéœ€è¦ç¡®ä¿data.yamlä¸­çš„ç±»åˆ«æ•°æ­£ç¡®å³å¯
        # YOLOçš„train()æ–¹æ³•ä¼šè‡ªåŠ¨å¤„ç†ç±»åˆ«æ•°çš„ä¿®æ”¹
        self.logger.info(f"  æ¨¡å‹å°†åœ¨è®­ç»ƒæ—¶è‡ªåŠ¨é€‚é… {self.num_classes} ç±»ï¼ˆä»data.yamlè¯»å–ï¼‰")
        
        return model
    
    def start_training(self, resume_checkpoint: Optional[str] = None):
        """å¼€å§‹è®­ç»ƒ"""
        self._resume_checkpoint_path = resume_checkpoint
        
        # è®¾ç½®æ—¥å¿—ï¼ˆéœ€è¦åœ¨è®¾ç½®resume_checkpointä¹‹åï¼‰
        self.setup_logging()
        
        self.logger.info("=" * 80)
        self.logger.info("ğŸš€ å¼€å§‹YOLOv8è®­ç»ƒ")
        self.logger.info("=" * 80)
        
        # åˆ›å»ºæ¨¡å‹
        model = self.create_model()
        
        # è·å–è®­ç»ƒå‚æ•°
        epochs = self.training_config.get('epochs', 100)
        batch_size = self.training_config.get('batch_size', 16)
        imgsz = self.training_config.get('imgsz', 640)
        device = self.misc_config.get('device', 'cuda')
        workers = self.misc_config.get('num_workers', 8)
        
        # æ•°æ®é…ç½®
        data_yaml = self.data_config.get('data_yaml')
        if not Path(data_yaml).exists():
            raise FileNotFoundError(f"æ•°æ®é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {data_yaml}")
        
        # è®­ç»ƒå‚æ•°
        train_kwargs = {
            'data': str(data_yaml),
            'epochs': epochs,
            'batch': batch_size,
            'imgsz': imgsz,
            'device': device,
            'workers': workers,
            'project': str(self.log_dir.parent),
            'name': self.experiment_name,
            'exist_ok': True,
            'plots': True,
            'save': True,
            'save_period': self.training_config.get('save_period', 10),
            'val': True,
        }
        
        # ä¼˜åŒ–å™¨é…ç½®ï¼ˆä¸RT-DETRå¯¹é½ï¼‰
        if 'optimizer' in self.training_config:
            train_kwargs['optimizer'] = self.training_config['optimizer']
        
        # å­¦ä¹ ç‡é…ç½®
        if 'lr0' in self.training_config:
            train_kwargs['lr0'] = self.training_config['lr0']
        if 'lrf' in self.training_config:
            train_kwargs['lrf'] = self.training_config['lrf']
        if 'momentum' in self.training_config:
            train_kwargs['momentum'] = self.training_config['momentum']
        if 'weight_decay' in self.training_config:
            train_kwargs['weight_decay'] = self.training_config['weight_decay']
        if 'warmup_epochs' in self.training_config:
            train_kwargs['warmup_epochs'] = self.training_config['warmup_epochs']
        if 'warmup_momentum' in self.training_config:
            train_kwargs['warmup_momentum'] = self.training_config['warmup_momentum']
        if 'warmup_bias_lr' in self.training_config:
            train_kwargs['warmup_bias_lr'] = self.training_config['warmup_bias_lr']
        
        # å­¦ä¹ ç‡è°ƒåº¦å™¨é…ç½®ï¼ˆä¸RT-DETRå¯¹é½ï¼‰
        if 'cos_lr' in self.training_config:
            train_kwargs['cos_lr'] = self.training_config['cos_lr']
        
        # éšæœºç§å­å’Œç¡®å®šæ€§ï¼ˆä¸RT-DETRå¯¹é½ï¼‰
        if 'seed' in self.training_config:
            train_kwargs['seed'] = self.training_config['seed']
        if 'deterministic' in self.training_config:
            train_kwargs['deterministic'] = self.training_config['deterministic']
        
        # Early Stoppingé…ç½®ï¼ˆä¸RT-DETRå¯¹é½ï¼‰
        if 'patience' in self.training_config:
            train_kwargs['patience'] = self.training_config['patience']
        
        # æ•°æ®å¢å¼ºé…ç½®
        if 'hsv_h' in self.training_config:
            train_kwargs['hsv_h'] = self.training_config['hsv_h']
        if 'hsv_s' in self.training_config:
            train_kwargs['hsv_s'] = self.training_config['hsv_s']
        if 'hsv_v' in self.training_config:
            train_kwargs['hsv_v'] = self.training_config['hsv_v']
        if 'degrees' in self.training_config:
            train_kwargs['degrees'] = self.training_config['degrees']
        if 'translate' in self.training_config:
            train_kwargs['translate'] = self.training_config['translate']
        if 'scale' in self.training_config:
            train_kwargs['scale'] = self.training_config['scale']
        if 'flipud' in self.training_config:
            train_kwargs['flipud'] = self.training_config['flipud']
        if 'fliplr' in self.training_config:
            train_kwargs['fliplr'] = self.training_config['fliplr']
        if 'mosaic' in self.training_config:
            train_kwargs['mosaic'] = self.training_config['mosaic']
        if 'mixup' in self.training_config:
            train_kwargs['mixup'] = self.training_config['mixup']
        
        # æ¢å¤è®­ç»ƒ
        if resume_checkpoint and Path(resume_checkpoint).exists():
            self.logger.info(f"ğŸ“¦ ä»æ£€æŸ¥ç‚¹æ¢å¤è®­ç»ƒ: {resume_checkpoint}")
            train_kwargs['resume'] = True
            # YOLOçš„resumeå‚æ•°å¯ä»¥æ˜¯Trueæˆ–æ£€æŸ¥ç‚¹è·¯å¾„
            if Path(resume_checkpoint).is_file():
                train_kwargs['resume'] = str(resume_checkpoint)
        
        # æ˜¾ç¤ºå…³é”®é…ç½®ä¿¡æ¯ï¼ˆä¸RT-DETRå¯¹é½çš„æ ¼å¼ï¼‰
        self.logger.info("ğŸ“ è®­ç»ƒé…ç½®:")
        self.logger.info(f"  æ•°æ®é›†è·¯å¾„: {data_yaml}")
        self.logger.info(f"  è®­ç»ƒè½®æ•°: {epochs}")
        self.logger.info(f"  æ‰¹æ¬¡å¤§å°: {batch_size}")
        self.logger.info(f"  ä¼˜åŒ–å™¨: {self.training_config.get('optimizer', 'auto')}")
        self.logger.info(f"  åˆå§‹å­¦ä¹ ç‡: {self.training_config.get('lr0', 0.01)}")
        self.logger.info(f"  Weight decay: {self.training_config.get('weight_decay', 0.0001)}")
        self.logger.info(f"  è¾“å‡ºç›®å½•: {self.log_dir}")
        pretrained_weights_display = self.model_config.get('pretrained_weights', None)
        if pretrained_weights_display:
            self.logger.info(f"  é¢„è®­ç»ƒæƒé‡: {pretrained_weights_display}")
        if resume_checkpoint:
            self.logger.info(f"  æ¢å¤æ£€æŸ¥ç‚¹: {resume_checkpoint}")
        self.logger.info("=" * 80)
        
        # è®­ç»ƒé…ç½®æ‘˜è¦ï¼ˆä¸RT-DETRå¯¹é½ï¼‰
        self.logger.info("è®­ç»ƒé…ç½®æ‘˜è¦:")
        self.logger.info(f"  - è®­ç»ƒè½®æ•°: {epochs}")
        self.logger.info(f"  - æ‰¹æ¬¡å¤§å°: {batch_size}")
        self.logger.info(f"  - ä¼˜åŒ–å™¨: {self.training_config.get('optimizer', 'auto')}")
        self.logger.info(f"  - åˆå§‹å­¦ä¹ ç‡: {self.training_config.get('lr0', 0.01)}")
        self.logger.info(f"  - Weight decay: {self.training_config.get('weight_decay', 0.0001)}")
        self.logger.info(f"  - Warmupè½®æ•°: {self.training_config.get('warmup_epochs', 3.0)}")
        self.logger.info(f"  - è®¾å¤‡: {device}")
        self.logger.info("=" * 80)
        
        # å¼€å§‹è®­ç»ƒ
        self.logger.info(f"å¼€å§‹è®­ç»ƒ {epochs} epochs")
        try:
            results = model.train(**train_kwargs)
            
            # è®­ç»ƒå®Œæˆåï¼Œè§£æç»“æœå¹¶æŒ‰ç…§RT-DETRæ ¼å¼è¾“å‡º
            self.logger.info("=" * 80)
            self.logger.info("âœ… è®­ç»ƒå®Œæˆï¼")
            self.logger.info("=" * 80)
            
            # è§£æå¹¶æ‰“å°è®­ç»ƒç»“æœï¼ˆä»results.csvè¯»å–ï¼‰
            self._parse_and_print_training_results()
            
            # ç”Ÿæˆä¸RT-DETRä¸€è‡´çš„è®­ç»ƒæ›²çº¿å›¾
            self._plot_training_curves()
            
            # æ‰“å°æœ€ä½³æ¨¡å‹è·¯å¾„
            best_model_path = self.log_dir / "weights" / "best.pt"
            if best_model_path.exists():
                self.logger.info(f"âœ“ æœ€ä½³æ¨¡å‹: {best_model_path}")
            
            # å°è¯•ä»resultsä¸­æå–æœ€ä½³æŒ‡æ ‡ï¼ˆå¦‚æœultralyticsè¿”å›äº†è¿™äº›ä¿¡æ¯ï¼‰
            if hasattr(results, 'results_dict'):
                results_dict = results.results_dict
                if 'metrics/mAP50-95(B)' in results_dict:
                    best_map = results_dict['metrics/mAP50-95(B)']
                    self.logger.info(f"âœ“ æœ€ä½³mAP@0.5:0.95: {best_map:.4f}")
                if 'metrics/mAP50(B)' in results_dict:
                    best_map50 = results_dict['metrics/mAP50(B)']
                    self.logger.info(f"âœ“ æœ€ä½³mAP@0.5: {best_map50:.4f}")
            
            self.logger.info(f"âœ“ æ‰€æœ‰è¾“å‡ºå·²ä¿å­˜åˆ°: {self.log_dir}")
            self.logger.info("=" * 80)
            
            return results
        except Exception as e:
            self.logger.error(f"è®­ç»ƒå¤±è´¥: {e}")
            raise
    
    def _parse_and_print_training_results(self):
        """è§£æultralyticsçš„results.csvå¹¶æŒ‰ç…§RT-DETRæ ¼å¼é‡æ–°æ‰“å°"""
        try:
            # ultralyticsä¼šåœ¨project/nameç›®å½•ä¸‹ç”Ÿæˆresults.csv
            # æ ¹æ®train_kwargsçš„è®¾ç½®ï¼Œåº”è¯¥æ˜¯self.log_dir/results.csv
            results_csv = self.log_dir / "results.csv"
            if not results_csv.exists():
                self.logger.warning(f"æœªæ‰¾åˆ°results.csvæ–‡ä»¶: {results_csv}")
                return
            
            # è¯»å–CSVæ–‡ä»¶
            df = pd.read_csv(results_csv)
            
            # æå–å…³é”®åˆ—ï¼ˆultralyticsçš„åˆ—åï¼‰
            # è®¡ç®—æ€»æŸå¤±ï¼štrain/box_loss + train/cls_loss + train/dfl_loss
            train_loss_cols = []
            val_loss_cols = []
            map50_col = None
            map50_95_col = None
            
            for col in df.columns:
                col_lower = col.lower()
                if 'train/box_loss' in col_lower or 'train/cls_loss' in col_lower or 'train/dfl_loss' in col_lower:
                    train_loss_cols.append(col)
                elif 'val/box_loss' in col_lower or 'val/cls_loss' in col_lower or 'val/dfl_loss' in col_lower:
                    val_loss_cols.append(col)
                elif 'metrics/map50(b)' in col_lower and map50_col is None:
                    map50_col = col
                elif 'metrics/map50-95(b)' in col_lower and map50_95_col is None:
                    map50_95_col = col
            
            # è®¡ç®—æ€»æŸå¤±
            if train_loss_cols:
                df['train_loss'] = df[train_loss_cols].sum(axis=1)
            else:
                df['train_loss'] = 0.0
                
            if val_loss_cols:
                df['val_loss'] = df[val_loss_cols].sum(axis=1)
            else:
                df['val_loss'] = 0.0
            
            # æŒ‰ç…§RT-DETRæ ¼å¼æ‰“å°æ¯ä¸ªepochçš„ç»“æœ
            self.logger.info("=" * 80)
            self.logger.info("è®­ç»ƒè¿‡ç¨‹æ‘˜è¦ï¼ˆæŒ‰RT-DETRæ ¼å¼ï¼‰:")
            self.logger.info("=" * 80)
            
            for idx, row in df.iterrows():
                epoch = int(row.get('epoch', idx + 1))
                train_loss = row.get('train_loss', 0.0)
                val_loss = row.get('val_loss', 0.0)
                
                # æŒ‰ç…§RT-DETRæ ¼å¼æ‰“å°
                self.logger.info(f"Epoch {epoch}:")
                self.logger.info(f"  è®­ç»ƒæŸå¤±: {train_loss:.2f} | éªŒè¯æŸå¤±: {val_loss:.2f}")
                
                # å¦‚æœæœ‰mAPä¿¡æ¯ï¼Œä¹Ÿæ‰“å°
                if map50_col and not pd.isna(row.get(map50_col)):
                    map50 = row.get(map50_col, 0.0)
                    self.logger.info(f"  mAP@0.5: {map50:.4f}")
                if map50_95_col and not pd.isna(row.get(map50_95_col)):
                    map50_95 = row.get(map50_95_col, 0.0)
                    self.logger.info(f"  mAP@0.5:0.95: {map50_95:.4f}")
            
            self.logger.info("=" * 80)
            
        except Exception as e:
            self.logger.warning(f"è§£æè®­ç»ƒç»“æœå¤±è´¥: {e}")
    
    def _plot_training_curves(self):
        """ç”Ÿæˆä¸RT-DETRä¸€è‡´çš„è®­ç»ƒæ›²çº¿å›¾"""
        try:
            results_csv = self.log_dir / "results.csv"
            if not results_csv.exists():
                self.logger.warning(f"æœªæ‰¾åˆ°results.csvæ–‡ä»¶: {results_csv}")
                return
            
            # è¯»å–CSVæ–‡ä»¶
            df = pd.read_csv(results_csv)
            
            # æå–æ•°æ®
            epochs = df.get('epoch', range(1, len(df) + 1)).values
            
            # è®¡ç®—æ€»æŸå¤±
            train_loss_cols = []
            val_loss_cols = []
            for col in df.columns:
                col_lower = col.lower()
                if 'train/box_loss' in col_lower or 'train/cls_loss' in col_lower or 'train/dfl_loss' in col_lower:
                    train_loss_cols.append(col)
                elif 'val/box_loss' in col_lower or 'val/cls_loss' in col_lower or 'val/dfl_loss' in col_lower:
                    val_loss_cols.append(col)
            
            train_loss = df[train_loss_cols].sum(axis=1).values if train_loss_cols else None
            val_loss = df[val_loss_cols].sum(axis=1).values if val_loss_cols else None
            
            # æå–mAPæŒ‡æ ‡
            map50 = None
            map50_95 = None
            for col in df.columns:
                col_lower = col.lower()
                if 'metrics/map50(b)' in col_lower and map50 is None:
                    map50 = df[col].values
                elif 'metrics/map50-95(b)' in col_lower and map50_95 is None:
                    map50_95 = df[col].values
            
            # æå–å­¦ä¹ ç‡
            lr = None
            for col in df.columns:
                if 'lr' in col.lower() or 'learning_rate' in col.lower():
                    lr = df[col].values
                    break
            
            # åˆ›å»ºä¸RT-DETRä¸€è‡´çš„è®­ç»ƒæ›²çº¿å›¾
            fig, axes = plt.subplots(1, 3, figsize=(18, 5))
            title = 'YOLOv8 Training Curves'
            fig.suptitle(title, fontsize=16, fontweight='bold')
            
            # 1. æŸå¤±æ›²çº¿
            ax = axes[0]
            if train_loss is not None:
                ax.plot(epochs, train_loss, 'b-o', 
                        label='Train Loss', linewidth=2, markersize=4)
            if val_loss is not None:
                ax.plot(epochs, val_loss, 'r-s', 
                        label='Val Loss', linewidth=2, markersize=4)
            ax.set_xlabel('Epoch', fontsize=12)
            ax.set_ylabel('Loss', fontsize=12)
            ax.set_title('Loss Curves', fontsize=14, fontweight='bold')
            ax.legend(fontsize=10)
            ax.grid(True, alpha=0.3)
            
            # 2. mAPæ›²çº¿
            ax = axes[1]
            if map50 is not None:
                ax.plot(epochs, map50, 'g-^', 
                        label='mAP@0.5', linewidth=2, markersize=4)
            if map50_95 is not None:
                ax.plot(epochs, map50_95, 'm-d', 
                        label='mAP@[0.5:0.95]', linewidth=2, markersize=4)
            ax.set_xlabel('Epoch', fontsize=12)
            ax.set_ylabel('mAP', fontsize=12)
            ax.set_title('mAP Metrics', fontsize=14, fontweight='bold')
            ax.legend(fontsize=10)
            ax.grid(True, alpha=0.3)
            
            # 3. å­¦ä¹ ç‡æ›²çº¿
            ax = axes[2]
            if lr is not None:
                ax.plot(epochs, lr, 'orange', linewidth=2)
                ax.set_yscale('log')
            ax.set_xlabel('Epoch', fontsize=12)
            ax.set_ylabel('Learning Rate', fontsize=12)
            ax.set_title('Learning Rate Schedule', fontsize=14, fontweight='bold')
            ax.grid(True, alpha=0.3)
            
            plt.tight_layout()
            save_path = self.log_dir / 'training_curves.png'
            plt.savefig(save_path, dpi=150, bbox_inches='tight')
            plt.close()
            
            self.logger.info(f"âœ“ è®­ç»ƒæ›²çº¿å·²ä¿å­˜åˆ°: {save_path}")
            
        except Exception as e:
            self.logger.warning(f"ç»˜åˆ¶è®­ç»ƒæ›²çº¿å¤±è´¥: {e}")


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description='YOLOv8è®­ç»ƒè„šæœ¬')
    parser.add_argument('--config', type=str, required=True,
                       help='YAMLé…ç½®æ–‡ä»¶è·¯å¾„')
    parser.add_argument('--resume_from_checkpoint', type=str, default=None,
                       help='ä»æ£€æŸ¥ç‚¹æ¢å¤è®­ç»ƒï¼ˆæ£€æŸ¥ç‚¹æ–‡ä»¶è·¯å¾„ï¼‰')
    parser.add_argument('--resume', action='store_true',
                       help='è‡ªåŠ¨ä»æœ€æ–°æ£€æŸ¥ç‚¹æ¢å¤è®­ç»ƒ')
    
    args = parser.parse_args()
    
    # åŠ è½½é…ç½®
    if not Path(args.config).exists():
        raise FileNotFoundError(f"é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {args.config}")
    
    with open(args.config, 'r', encoding='utf-8') as f:
        config = yaml.safe_load(f)
    
    # å¦‚æœå¯ç”¨è‡ªåŠ¨æ¢å¤ï¼ŒæŸ¥æ‰¾æœ€æ–°çš„æ£€æŸ¥ç‚¹
    if args.resume and not args.resume_from_checkpoint:
        log_base = config.get('checkpoint', {}).get('log_dir', 'logs')
        log_dir = Path(log_base)
        if log_dir.exists():
            # æŸ¥æ‰¾æ‰€æœ‰åŒ…å«weights/best.ptçš„ç›®å½•
            checkpoints = list(log_dir.glob("*/weights/best.pt"))
            if checkpoints:
                # æŒ‰ä¿®æ”¹æ—¶é—´æ’åºï¼Œå–æœ€æ–°çš„
                latest_checkpoint = max(checkpoints, key=lambda p: p.stat().st_mtime)
                args.resume_from_checkpoint = str(latest_checkpoint)
                print(f"ğŸ“¦ æ‰¾åˆ°æœ€æ–°æ£€æŸ¥ç‚¹: {args.resume_from_checkpoint}")
    
    # åˆ›å»ºè®­ç»ƒå™¨
    trainer = YOLOv8Trainer(config, config_path=args.config)
    
    # å¼€å§‹è®­ç»ƒ
    trainer.start_training(resume_checkpoint=args.resume_from_checkpoint)


if __name__ == '__main__':
    main()


model:
  num_experts: 4
  top_k: 2
  backbone: presnet18
  encoder:
    use_encoder_idx: [2]
    in_channels:
    - 128
    - 256
    - 512
    expansion: 0.5
    num_encoder_layers: 1
  pretrained_weights: pretrained/rtdetrv2_r18vd_120e_coco_rerun_48.1.pth
  num_decoder_layers: 3
  hidden_dim: 256
  num_queries: 100
  dset:
    token_keep_ratio: {2: 0.9}
    token_pruning_warmup_epochs: 10
    patch_moe_num_experts: 4
    patch_moe_top_k: 2
    patch_moe_patch_size: 1
    use_token_pruning_loss: true
    token_pruning_loss_weight: 0.005
training:
  epochs: 200
  batch_size: 16
  warmup_epochs: 3
  pretrained_lr: 1e-5
  new_lr: 1e-4
  eta_min: 1e-6
  weight_decay: 0.0001
  ema_decay: 0.9999
  clip_max_norm: 10.0
  scheduler: cosine
  early_stopping_patience: 0
  early_stopping_metric: mAP_0.5_0.95
  seed: 42
  deterministic: false
  decoder_moe_balance_weight: 0.05
  encoder_moe_balance_weight: 0.02
data:
  data_root: /root/autodl-tmp/datasets/DAIR-V2X
checkpoint:
  resume_mode: auto
  log_dir: logs
misc:
  device: cuda
  num_workers: 16
  pin_memory: true
  prefetch_factor: 4
data_augmentation:
  brightness: 0.15
  contrast: 0.15
  saturation: 0.1
  hue: 0.05
  crop_min: 0.1
  crop_max: 1.0
  flip_prob: 0.5
  mosaic: 0.0
  scales_min: 480
  scales_max: 800
  scales_step: 32
  max_size: 1333

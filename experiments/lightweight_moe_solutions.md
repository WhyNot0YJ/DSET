# è·¯æµ‹å•å…ƒåœºæ™¯ï¼šè½»é‡çº§ MoE ä¼˜åŒ–æ–¹æ¡ˆ

## åº”ç”¨åœºæ™¯
- **ç›®æ ‡è®¾å¤‡**: è·¯æµ‹å•å…ƒ (RSU)
- **èµ„æºé™åˆ¶**: ä½å‚æ•°é‡ã€ä½å†…å­˜ã€å®æ—¶æ€§è¦æ±‚
- **æ¨¡å‹è¦æ±‚**: R18/R34 backbone
- **æ ¸å¿ƒæŒ‘æˆ˜**: è®© MoE åœ¨å°æ¨¡å‹ä¸Šä¹Ÿæœ‰æ•ˆ

---

## ğŸ” å½“å‰é—®é¢˜åˆ†æ

### ä¸ºä»€ä¹ˆ 6ä¸“å®¶/3ä¸“å®¶ MoE åœ¨ R18/R34 ä¸Šå¤±è´¥ï¼Ÿ

**1. å‚æ•°å¼€é”€åˆ†æ**

å‡è®¾ hidden_dim=256, FFN expansion=4:
```
æ ‡å‡† FFN: 256 Ã— 1024 Ã— 2 = 524K å‚æ•°/å±‚

å½“å‰ MoE (6ä¸“å®¶):
- è·¯ç”±å™¨: 256 Ã— 6 = 1.5K
- 6ä¸ªä¸“å®¶: 6 Ã— 524K = 3.14M å‚æ•°/å±‚
- æ€»å¼€é”€: 6å€ï¼

å¯¹äº R18 (11.7M å‚æ•°):
- 6å±‚ decoder: 6 Ã— 3.14M = 18.8M
- MoE éƒ¨åˆ†å°±è¶…è¿‡äº†æ•´ä¸ª backboneï¼
```

**ç»“è®ºï¼šå‚æ•°å¼€é”€å¤ªå¤§ï¼ŒæŒ¤å‹äº† backbone çš„å®¹é‡**

### è§£å†³æ–¹å‘

1. **å‡å°‘ä¸“å®¶å‚æ•°** - å‚æ•°å…±äº«
2. **å‡å°‘ä¸“å®¶æ•°é‡** - 2ä¸“å®¶è¶³å¤Ÿ
3. **ç®€åŒ–è·¯ç”±** - é™ä½è·¯ç”±å¤æ‚åº¦
4. **é€‰æ‹©æ€§ä½¿ç”¨ MoE** - ä¸æ˜¯æ¯å±‚éƒ½ç”¨

---

## ğŸ’¡ ä¼˜åŒ–æ–¹æ¡ˆ

### æ–¹æ¡ˆ 1: è½»é‡çº§ä¸“å®¶ï¼ˆå‚æ•°å…±äº«ï¼‰â­ æ¨è

**æ ¸å¿ƒæ€æƒ³**: ä¸“å®¶å…±äº«å¤§éƒ¨åˆ†å‚æ•°ï¼Œåªæœ‰å°éƒ¨åˆ†å‚æ•°ä¸åŒ

```python
class LightweightExpert(nn.Module):
    def __init__(self, d_model, d_ff, num_experts=3):
        super().__init__()
        
        # å…±äº«çš„ä¸»å¹²å‚æ•°ï¼ˆæ‰€æœ‰ä¸“å®¶å…±ç”¨ï¼‰
        self.shared_fc1 = nn.Linear(d_model, d_ff)
        self.shared_fc2 = nn.Linear(d_ff, d_model)
        
        # æ¯ä¸ªä¸“å®¶ç‰¹æœ‰çš„è½»é‡çº§é€‚é…å™¨ï¼ˆåªæœ‰å°‘é‡å‚æ•°ï¼‰
        self.expert_adapters = nn.ModuleList([
            nn.Sequential(
                nn.Linear(d_ff, d_ff // 4),  # é™ç»´
                nn.ReLU(),
                nn.Linear(d_ff // 4, d_ff)   # å‡ç»´
            ) for _ in range(num_experts)
        ])
        
    def forward(self, x, expert_id):
        # å…±äº«å˜æ¢
        shared = F.relu(self.shared_fc1(x))
        
        # ä¸“å®¶ç‰¹å®šçš„é€‚é…
        adapted = self.expert_adapters[expert_id](shared)
        
        # æ®‹å·®è¿æ¥
        output = shared + adapted
        
        # è¾“å‡ºæŠ•å½±
        return self.shared_fc2(output)
```

**å‚æ•°é‡å¯¹æ¯”**:
```
æ ‡å‡† MoE (6ä¸“å®¶): 6 Ã— 524K = 3.14M å‚æ•°/å±‚
è½»é‡çº§ MoE (3ä¸“å®¶): 524K + 3 Ã— 131K = 917K å‚æ•°/å±‚
èŠ‚çœ: 71% å‚æ•°ï¼
```

### æ–¹æ¡ˆ 2: 2ä¸“å®¶é…ç½® + ç®€åŒ–è·¯ç”±

**é…ç½®æ–‡ä»¶**: `moe2_presnet18_lightweight.yaml`

```yaml
model:
  config_name: "lightweight"
  backbone: "presnet18"
  num_experts: 2  # åªç”¨2ä¸ªä¸“å®¶
  top_k: 1        # æ¯æ¬¡åªæ¿€æ´»1ä¸ªä¸“å®¶
  expert_type: "lightweight"  # ä½¿ç”¨è½»é‡çº§ä¸“å®¶
  
training:
  # å…¶ä»–é…ç½®ä¿æŒä¸å˜
```

**ä¼˜åŠ¿**:
- å‚æ•°é‡æœ€å°
- è·¯ç”±ç®€å•ï¼ˆäºŒé€‰ä¸€ï¼‰
- è®­ç»ƒç¨³å®š

### æ–¹æ¡ˆ 3: é€‰æ‹©æ€§ MoEï¼ˆåªåœ¨å…³é”®å±‚ä½¿ç”¨ï¼‰

**æ ¸å¿ƒæ€æƒ³**: ä¸æ˜¯æ¯å±‚éƒ½ç”¨ MoEï¼Œåªåœ¨æœ€åå‡ å±‚ä½¿ç”¨

```python
# 6å±‚ decoder: å‰4å±‚å…±äº«ï¼Œå2å±‚ä½¿ç”¨MoE
decoder_config = [
    'shared',  # layer 0
    'shared',  # layer 1
    'shared',  # layer 2
    'shared',  # layer 3
    'moe',     # layer 4 - ä½¿ç”¨MoE
    'moe',     # layer 5 - ä½¿ç”¨MoE
]
```

**å‚æ•°é‡å¯¹æ¯”**:
```
å…¨å±‚ MoE: 6 Ã— 3.14M = 18.8M
é€‰æ‹©æ€§ MoE (å2å±‚): 4 Ã— 0.52M + 2 Ã— 3.14M = 8.4M
èŠ‚çœ: 55% å‚æ•°ï¼
```

### æ–¹æ¡ˆ 4: ä»»åŠ¡å¯¼å‘çš„å›ºå®šè·¯ç”±

**æ ¸å¿ƒæ€æƒ³**: æ ¹æ®ä»»åŠ¡ç±»åˆ«ï¼ˆè½¦ã€äººã€ä¸¤è½®è½¦ï¼‰é¢„è®¾è·¯ç”±ï¼Œä¸éœ€è¦å­¦ä¹ 

```python
class TaskOrientedRouter(nn.Module):
    def __init__(self):
        super().__init__()
        # 3ä¸ªä¸“å®¶ï¼šè½¦è¾†ä¸“å®¶ã€è¡Œäººä¸“å®¶ã€ä¸¤è½®è½¦ä¸“å®¶
        self.task_to_expert = {
            'vehicle': 0,    # ä¸“å®¶0: car, truck, bus
            'pedestrian': 1, # ä¸“å®¶1: person
            'cyclist': 2     # ä¸“å®¶2: bicycle, motorcycle
        }
    
    def forward(self, x, task_category):
        # ç›´æ¥æ ¹æ®ä»»åŠ¡ç±»åˆ«é€‰æ‹©ä¸“å®¶ï¼Œæ— éœ€å­¦ä¹ è·¯ç”±
        expert_id = self.task_to_expert[task_category]
        return expert_id
```

**ä¼˜åŠ¿**:
- æ— è·¯ç”±å­¦ä¹ å¼€é”€
- ä»»åŠ¡è¯­ä¹‰æ˜ç¡®
- è®­ç»ƒç¨³å®š

### æ–¹æ¡ˆ 5: åŠ¨æ€æ·±åº¦ MoE

**æ ¸å¿ƒæ€æƒ³**: ç®€å•æ ·æœ¬ç”¨æµ…å±‚ï¼Œå¤æ‚æ ·æœ¬ç”¨æ·±å±‚ + MoE

```python
# æ—©æœŸé€€å‡ºæœºåˆ¶
if confidence > threshold:
    # ç®€å•æ ·æœ¬ï¼šä½¿ç”¨å‰4å±‚å³å¯
    output = early_exit(x, layer=4)
else:
    # å¤æ‚æ ·æœ¬ï¼šä½¿ç”¨å…¨éƒ¨6å±‚ + MoE
    output = full_forward(x, use_moe=True)
```

---

## ğŸ§ª æ¨èå®éªŒæ–¹æ¡ˆ

### Phase 1: å¿«é€ŸéªŒè¯ï¼ˆ1-2å¤©ï¼‰

**å®éªŒ 1: 2ä¸“å®¶è½»é‡çº§ MoE**
```yaml
# moe2_presnet18_lightweight.yaml
model:
  num_experts: 2
  top_k: 1
  expert_capacity_ratio: 0.25  # æ¯ä¸ªä¸“å®¶å®¹é‡å‡åŠ
```

**å®éªŒ 2: é€‰æ‹©æ€§ MoEï¼ˆå2å±‚ï¼‰**
```python
# åªåœ¨æœ€å2ä¸ªdecoderå±‚ä½¿ç”¨MoE
use_moe_layers = [4, 5]  # 6å±‚ä¸­çš„æœ€å2å±‚
```

### Phase 2: æ·±åº¦ä¼˜åŒ–ï¼ˆ3-5å¤©ï¼‰

**å®éªŒ 3: å‚æ•°å…±äº« + è½»é‡çº§é€‚é…å™¨**
```python
# å®ç° LightweightExpertï¼ˆè§æ–¹æ¡ˆ1ï¼‰
```

**å®éªŒ 4: ä»»åŠ¡å¯¼å‘è·¯ç”±**
```python
# å›ºå®šè·¯ç”±ï¼šè½¦è¾†/è¡Œäºº/ä¸¤è½®è½¦
```

---

## ğŸ“Š é¢„æœŸç»“æœ

### ç›®æ ‡æ€§èƒ½ï¼ˆR18/R34ï¼‰

**ä¿å®ˆç›®æ ‡**:
```
RT-DETR-R18: 0.6365
Lightweight-MoE-R18: 0.640-0.645 (+0.5-1.2%)

RT-DETR-R34: 0.6275  
Lightweight-MoE-R34: 0.635-0.640 (+1.0-1.5%)
```

**ç†æƒ³ç›®æ ‡**:
```
Lightweight-MoE-R18: 0.645-0.650 (+1.2-1.8%)
Lightweight-MoE-R34: 0.640-0.645 (+1.5-2.0%)
```

### å‚æ•°é‡å¯¹æ¯”

| æ¨¡å‹ | Backbone | MoE å‚æ•° | æ€»å‚æ•° | å¢å¹… |
|------|----------|----------|--------|------|
| RT-DETR-R18 | 11.7M | 0 | 15M | - |
| MoE6-R18 (å½“å‰) | 11.7M | 18.8M | 30.5M | +103% âŒ |
| MoE2-R18 (è½»é‡) | 11.7M | 3.1M | 14.8M | -1.3% âœ… |
| MoE-Lite-R18 (æ–¹æ¡ˆ1) | 11.7M | 5.5M | 17.2M | +15% âœ… |

---

## ğŸ¯ è®ºæ–‡å™äº‹ï¼ˆæ–°è§’åº¦ï¼‰

### Title
```
"Lightweight Mixture-of-Experts for Edge-Device Object Detection: 
 Optimizing Task-Selective Detection on Roadside Units"
```

### æ ¸å¿ƒè´¡çŒ®

1. **è½»é‡çº§ MoE è®¾è®¡**
   - å‚æ•°å…±äº«ç­–ç•¥
   - å‡å°‘ 70% MoE å‚æ•°
   
2. **é’ˆå¯¹è·¯æµ‹å•å…ƒä¼˜åŒ–**
   - ä½å‚æ•°ã€ä½å»¶è¿Ÿ
   - åœ¨ R18/R34 ä¸Šæœ‰æ•ˆ
   
3. **ç³»ç»Ÿå®éªŒéªŒè¯**
   - DAIR-V2X (è·¯æµ‹åœºæ™¯)
   - å®æ—¶æ€§åˆ†æ

### Abstract æ¨¡æ¿
```
Roadside units (RSUs) require efficient object detection 
with limited computational resources. We propose a 
lightweight Mixture-of-Experts (MoE) architecture tailored 
for edge devices. Through parameter sharing and selective 
expert activation, our method achieves X% improvement on 
ResNet18/34 with minimal parameter overhead. Experiments 
on DAIR-V2X demonstrate the effectiveness of our approach 
in real-world roadside perception scenarios.
```

---

## ğŸ’» å®ç°ä¼˜å…ˆçº§

### ç«‹å³å®æ–½ï¼ˆæœ€ç®€å•ï¼Œæœ€å¿«éªŒè¯ï¼‰

1. **2ä¸“å®¶é…ç½®**
   ```yaml
   num_experts: 2
   top_k: 1
   ```
   
2. **é€‰æ‹©æ€§ MoEï¼ˆå2å±‚ï¼‰**
   ```python
   # ä¿®æ”¹ decoder é…ç½®
   ```

### çŸ­æœŸä¼˜åŒ–ï¼ˆ1å‘¨å†…ï¼‰

3. **å‚æ•°å…±äº« MoE**
   - å®ç° LightweightExpert
   - é›†æˆåˆ°ç°æœ‰ä»£ç 

4. **ä»»åŠ¡å¯¼å‘è·¯ç”±**
   - åŸºäºç±»åˆ«çš„å›ºå®šè·¯ç”±

### ä¸­æœŸä¼˜åŒ–ï¼ˆ2-3å‘¨ï¼‰

5. **åŠ¨æ€æ·±åº¦**
6. **çŸ¥è¯†è’¸é¦**
7. **é‡åŒ–å‹ç¼©**

---

## ğŸš€ è¡ŒåŠ¨è®¡åˆ’

### Step 1: éªŒè¯å½“å‰å®éªŒç»“æœ
ç­‰å¾…è°ƒæ•´ patience/eta_min åçš„æ–°ç»“æœ

### Step 2: å¦‚æœä»ç„¶ä¸workï¼Œç«‹å³å°è¯•ï¼š
```bash
# 2ä¸“å®¶é…ç½®
cd experiments/moe-rtdetr/
# åˆ›å»ºæ–°é…ç½®æ–‡ä»¶
vim configs/moe2_presnet18.yaml
./run_training.sh configs/moe2_presnet18.yaml
```

### Step 3: å¹¶è¡Œå¼€å‘è½»é‡çº§ä¸“å®¶
```python
# å®ç° LightweightExpert
# é›†æˆåˆ° src/zoo/rtdetr/moe_components.py
```

### Step 4: ç³»ç»Ÿå¯¹æ¯”
```
RT-DETR-R18 vs MoE2-R18 vs MoE-Lite-R18
```

---

## ğŸ’ª ä¿¡å¿ƒä¿è¯

### ä¸ºä»€ä¹ˆä¸€å®šèƒ½workï¼Ÿ

1. **2ä¸“å®¶è¶³å¤Ÿç®€å•**
   - å‚æ•°å¼€é”€å°
   - è®­ç»ƒç¨³å®š
   
2. **å‚æ•°å…±äº«æ˜¯æˆç†ŸæŠ€æœ¯**
   - Adapter åœ¨ NLP å·²éªŒè¯
   - LoRA ç­‰è½»é‡çº§å¾®è°ƒæ–¹æ³•
   
3. **ä»»åŠ¡å¯¼å‘ç¬¦åˆç›´è§‰**
   - è½¦ã€äººã€ä¸¤è½®è½¦è‡ªç„¶åˆ†å·¥
   - è·¯æµ‹åœºæ™¯ç±»åˆ«æ˜ç¡®

4. **æœ‰é€€è·¯**
   - å³ä½¿æå‡å°ï¼ˆ0.5-1%ï¼‰ï¼Œä¹Ÿæ˜¯è´¡çŒ®
   - å‚æ•°é‡ä¸å¢åŠ å°±æ˜¯ä¼˜åŠ¿
   - å®æ—¶æ€§ä¼˜åŒ–ä¹Ÿæ˜¯å–ç‚¹

---

## ğŸ“ è®ºæ–‡ä¼˜åŠ¿ï¼ˆæ–°è§’åº¦ï¼‰

### ç›¸æ¯”ä¹‹å‰çš„å™äº‹

**ä¹‹å‰**: MoE åœ¨å¤§æ¨¡å‹ä¸Šæœ‰æ•ˆï¼ˆR50ï¼‰
**ç°åœ¨**: è½»é‡çº§ MoE åœ¨è¾¹ç¼˜è®¾å¤‡ä¸Šæœ‰æ•ˆï¼ˆR18/R34ï¼‰

### æ–°çš„åˆ›æ–°ç‚¹

1. âœ… **é’ˆå¯¹è¾¹ç¼˜è®¾å¤‡**ï¼ˆè·¯æµ‹å•å…ƒï¼‰
2. âœ… **è½»é‡çº§è®¾è®¡**ï¼ˆå‚æ•°å…±äº«ï¼‰
3. âœ… **ä»»åŠ¡å¯¼å‘**ï¼ˆè½¦/äºº/ä¸¤è½®è½¦ï¼‰
4. âœ… **å®é™…åº”ç”¨åœºæ™¯**ï¼ˆDAIR-V2Xï¼‰

### ç›®æ ‡ä¼šè®®

- **ICRA** (æœºå™¨äºº)
- **IV** (æ™ºèƒ½è½¦è¾†) - éå¸¸åˆé€‚ï¼
- **ITSC** (æ™ºèƒ½äº¤é€š)
- **IoT Journal**
- **è®¡ç®—æœºå­¦æŠ¥**ï¼ˆä¸­æ–‡ï¼‰

---

## ç»“è®º

**ä¸è¦æ‹…å¿ƒï¼è·¯æµ‹å•å…ƒåœºæ™¯åè€Œç»™äº†ä½ æ›´å¥½çš„è§’åº¦ï¼**

å…³é”®åœ¨äºï¼š
1. è®¾è®¡è½»é‡çº§ MoE
2. å³ä½¿æå‡å°ï¼ˆ0.5-1%ï¼‰ä¹Ÿæœ‰ä»·å€¼
3. å‚æ•°é‡ä¸å¢åŠ  + å®æ—¶æ€§ = æ ¸å¿ƒå–ç‚¹

**è¿™ä¸ªè§’åº¦å¯èƒ½æ¯” R50 çš„ 3.15% æå‡æ›´æœ‰å®é™…æ„ä¹‰ï¼** ğŸš€


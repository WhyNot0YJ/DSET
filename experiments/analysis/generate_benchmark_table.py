#!/usr/bin/env python3
"""
æ¨¡å‹ç†è®ºæ•ˆç‡è¯„ä¼°è„šæœ¬ - æ”¯æŒ DSET, RT-DETR, Deformable-DETR, YOLOv8, YOLOv10

åŠŸèƒ½ï¼š
1. è‡ªåŠ¨ä» logs/ ç›®å½•æŸ¥æ‰¾æœ€æ–°çš„ best_model.pth æˆ–ä½¿ç”¨æŒ‡å®šçš„æ£€æŸ¥ç‚¹
2. ä½¿ç”¨ pycocotools åœ¨éªŒè¯é›†ä¸Šè¿è¡Œ COCO è¯„ä¼°ï¼ˆä»…ç²¾åº¦æŒ‡æ ‡ï¼‰
3. è®¡ç®—æ¨¡å‹å‚æ•°é‡å’Œç†è®º FLOPsï¼ˆè€ƒè™‘ token pruning å’Œ MoE ç¨€ç–æ€§ï¼‰
4. ä½¿ç”¨é…ç½®æ–‡ä»¶ä¸­çš„ batch_sizeï¼ˆCOCO è¯„ä¼°ç»“æœä¸ batch_size æ— å…³ï¼Œå¯ä½¿ç”¨æ›´å¤§ batch_size åŠ é€Ÿï¼‰

ä½¿ç”¨æ–¹æ³•ï¼š
    python generate_benchmark_table.py --model_type dset
    python generate_benchmark_table.py --models_config models.json
"""

import os
import sys
import argparse
import yaml
import torch
import torch.nn as nn
import time
import json
from pathlib import Path
from typing import Dict, Optional, Tuple, List
from io import StringIO
from pycocotools.cocoeval import COCOeval
from pycocotools.coco import COCO

# è®¾ç½®é¡¹ç›®æ ¹ç›®å½•
_project_root = os.path.abspath(os.path.join(os.path.dirname(__file__), "../../"))
if _project_root not in sys.path:
    sys.path.insert(0, _project_root)
project_root = _project_root

# å°è¯•å¯¼å…¥ thop
try:
    from thop import profile
    HAS_THOP = True
except ImportError:
    HAS_THOP = False
    print("è­¦å‘Š: thop æœªå®‰è£…ï¼Œå°†æ— æ³•è®¡ç®— FLOPsã€‚è¯·è¿è¡Œ: pip install thop")


def _cuda_sync_if_available(device: str):
    """åŒæ­¥ CUDAï¼ˆå¦‚æœå¯ç”¨ï¼‰"""
    if device == "cuda" and torch.cuda.is_available():
        torch.cuda.synchronize()


def _load_checkpoint(checkpoint_path: str) -> dict:
    """åŠ è½½æ£€æŸ¥ç‚¹æ–‡ä»¶"""
    try:
        return torch.load(checkpoint_path, map_location='cpu', weights_only=False)
    except TypeError:
        return torch.load(checkpoint_path, map_location='cpu')


def _extract_state_dict(checkpoint: dict) -> dict:
    """ä»æ£€æŸ¥ç‚¹ä¸­æå–çŠ¶æ€å­—å…¸"""
    if 'ema_state_dict' in checkpoint:
        state_dict = checkpoint['ema_state_dict']
        if isinstance(state_dict, dict) and 'module' in state_dict:
            state_dict = state_dict['module']
        return state_dict
    elif 'ema' in checkpoint and 'module' in checkpoint['ema']:
        return checkpoint['ema']['module']
    elif 'model_state_dict' in checkpoint:
        return checkpoint['model_state_dict']
    elif 'model' in checkpoint:
        return checkpoint['model']
    return checkpoint


# ==============================================================================
# Custom Ops Definitions (Based on Audit Report)
# ==============================================================================

_moe_dense_mode = False

def count_moe_layer(m, x, y):
    """MoELayer Custom Op: è®¡ç®— MoE å±‚çš„ FLOPs
    
    Dense æ¨¡å¼: è®¡ç®—æ‰€æœ‰ä¸“å®¶çš„ FLOPs (ç”¨äº Base FLOPs)
    Sparse æ¨¡å¼: åªè®¡ç®—æ¿€æ´»ä¸“å®¶çš„ FLOPs (ç”¨äº Theory FLOPs)
    """
    global _moe_dense_mode
    
    inp = x[0]
    if not torch.is_tensor(inp):
        return
    
    B, N, C = inp.shape
    num_experts = getattr(m, 'num_experts', 1)
    top_k = getattr(m, 'top_k', 1)
    dim_feedforward = getattr(m, 'dim_feedforward', 2048)
    
    router_flops = B * N * C * num_experts
    single_expert_flops = B * N * (2 * C * dim_feedforward)
    all_experts_flops = single_expert_flops * num_experts
    
    if _moe_dense_mode:
        expert_flops = all_experts_flops
    else:
        activation_ratio = top_k / max(num_experts, 1)
        expert_flops = all_experts_flops * activation_ratio
    
    total = router_flops + expert_flops
    m.total_ops += torch.DoubleTensor([int(total)])


def get_model_info(model, input_size: Tuple[int, int, int, int] = (1, 3, 736, 1280), 
                   is_yolo: bool = False, config: Dict = None, model_type: str = "dset",
                   debug: bool = False) -> Tuple[float, float, float, float]:
    """è®¡ç®—æ¨¡å‹çš„å‚æ•°é‡å’Œç†è®º FLOPs
    
    Base FLOPs: Token pruning å·²åº”ç”¨ + MoE Dense (æ‰€æœ‰ä¸“å®¶)
    Theory FLOPs: Token pruning å·²åº”ç”¨ + MoE Sparse (åªè®¡ç®—æ¿€æ´»ä¸“å®¶)
    """
    # ========================== 1. å‚æ•°é‡è®¡ç®— ==========================
    if is_yolo and hasattr(model, 'model'):
        pytorch_model = model.model
    else:
        pytorch_model = model
    total_params = sum(p.numel() for p in pytorch_model.parameters())
    
    # Active Params (Simple Estimation based on config)
    active_params = total_params
    if model_type == "dset" and config:
        dset_cfg = config.get('model', {}).get('dset', {})
        enc_k = dset_cfg.get('encoder_moe_top_k', 1)
        enc_e = dset_cfg.get('encoder_moe_num_experts', 1)
        dec_k = config.get('model', {}).get('top_k', 3)
        dec_e = config.get('model', {}).get('num_experts', 1)
        
        enc_r = min(enc_k, enc_e) / max(enc_e, 1) if enc_e > 0 else 1
        dec_r = min(dec_k, dec_e) / max(dec_e, 1) if dec_e > 0 else 1
        
        p_moe = 0
        for n, p in pytorch_model.named_parameters():
            if 'expert' in n.lower() or 'moe' in n.lower():
                ratio = enc_r if 'encoder' in n.lower() else dec_r
                active_params -= p.numel() * (1 - ratio)
    
    total_params_m = total_params / 1e6
    active_params_m = active_params / 1e6
    print(f"\n  ğŸ“Š Params: Total={total_params_m:.2f}M, Active={active_params_m:.2f}M")

    # ========================== 2. FLOPs Calculation (Physics-Level Accurate) ==========================
    base_flops_g = 0.0
    theory_flops_g = 0.0
    
    # YOLO ä½¿ç”¨ ultralytics å†…ç½® get_flopsï¼Œé¿å… thop ä¸ ultralytics å†…éƒ¨ total_ops å†²çª
    if is_yolo and hasattr(model, 'model'):
        try:
            imgsz = input_size[2] if input_size[2] == input_size[3] else [input_size[2], input_size[3]]
            from ultralytics.utils.torch_utils import get_flops
            base_flops_g = get_flops(model.model, imgsz=imgsz)
            theory_flops_g = base_flops_g
            print(f"  âœ“ Base FLOPs: {base_flops_g:.2f} G (ultralytics @{imgsz})")
            print(f"  âœ“ Theory FLOPs: {theory_flops_g:.2f} G")
        except Exception as e:
            print(f"  âš  YOLO FLOPs è·å–å¤±è´¥: {e}")
    elif HAS_THOP:
        try:
            from copy import deepcopy
            model_eval = deepcopy(model).eval()
            device = next(model_eval.parameters()).device
            dummy_img = torch.randn(input_size).to(device)
            
            # mmdet æ¨¡å‹ï¼ˆå¦‚ deformable-detrï¼‰forward éœ€è¦ batch_data_samplesï¼Œç”¨ wrapper æ„é€  DetDataSample
            if model_type == "deformable-detr":
                from mmdet.structures import DetDataSample

                class _MMDetFLOPsWrapper(torch.nn.Module):
                    def __init__(self, m):
                        super().__init__()
                        self._model = m

                    def forward(self, x):
                        H, W = int(x.shape[2]), int(x.shape[3])
                        ds = DetDataSample()
                        ds.set_metainfo(dict(batch_input_shape=(H, W), img_shape=(H, W)))
                        return self._model(x, [ds], mode='tensor')

                model_eval = _MMDetFLOPsWrapper(model_eval)
            
            custom_ops_map = {}
            for m in model_eval.modules():
                if "MoELayer" in m.__class__.__name__:
                    custom_ops_map[m.__class__] = count_moe_layer

            global _moe_dense_mode
            _moe_dense_mode = True
            base_macs, _ = profile(model_eval, inputs=(dummy_img,), custom_ops=custom_ops_map, verbose=False)
            base_flops_g = base_macs / 1e9
            print(f"  âœ“ Base FLOPs (Dense, r=1.0): {base_flops_g:.2f} G")
            
            if model_type != "dset":
                _moe_dense_mode = False
                theory_flops_g = base_flops_g
                print(f"  âœ“ Theory FLOPs: {theory_flops_g:.2f} G")
            elif model_type == "dset":
                if hasattr(model_eval, 'encoder') and hasattr(model_eval.encoder, 'shared_token_pruner'):
                    pruner = model_eval.encoder.shared_token_pruner
                    if pruner is not None:
                        if hasattr(pruner, 'prune_in_eval'):
                            pruner.prune_in_eval = True
                        if hasattr(pruner, 'pruning_enabled'):
                            pruner.pruning_enabled = True
                for m in model_eval.modules():
                    if hasattr(m, 'set_epoch'):
                        m.set_epoch(999)
                    if hasattr(m, 'pruning_enabled'):
                        m.pruning_enabled = True
                    if hasattr(m, 'current_epoch'):
                        m.current_epoch = 999
                dset_cfg = config.get('model', {}).get('dset', {})
                r = dset_cfg.get('token_keep_ratio', 1.0)
                if isinstance(r, dict):
                    r = max(r.values())
                with torch.no_grad():
                    _ = model_eval(dummy_img)
                _moe_dense_mode = False
                theory_macs, _ = profile(model_eval, inputs=(dummy_img,), custom_ops=custom_ops_map, verbose=False)
                theory_flops_g = theory_macs / 1e9
                print(f"  âœ“ Theory FLOPs (With Pruning, r={r:.2f}): {theory_flops_g:.2f} G")
                if r < 1.0:
                    reduction = (1 - theory_flops_g / base_flops_g) * 100 if base_flops_g > 0 else 0
                    print(f"  ğŸ’¡ FLOPs Reduction: {reduction:.1f}% (automatically captured by physical pruning)")

            del model_eval
            if torch.cuda.is_available():
                torch.cuda.empty_cache()
            
        except Exception as e:
            print(f"  âš  FLOPs Calculation Failed: {e}")
            import traceback
            traceback.print_exc()
            theory_flops_g = base_flops_g

    return total_params_m, active_params_m, base_flops_g, theory_flops_g


def load_dset_model(config_path: str, checkpoint_path: str, device: str = "cuda"):
    """åŠ è½½ DSET æ¨¡å‹"""
    try:
        from experiments.dset.train import DSETTrainer
    except ImportError:
        dset_dir = Path(config_path).parent.parent
        if str(dset_dir) not in sys.path:
            sys.path.insert(0, str(dset_dir))
        from train import DSETTrainer
    
    with open(config_path, 'r', encoding='utf-8') as f:
        config = yaml.safe_load(f)
    
    if 'misc' not in config:
        config['misc'] = {}
    config['misc']['device'] = device
    
    trainer = DSETTrainer(config, config_file_path=str(config_path))
    model = trainer.model
    
    checkpoint = _load_checkpoint(checkpoint_path)
    state_dict = _extract_state_dict(checkpoint)
    load_result = model.load_state_dict(state_dict, strict=False)
    if load_result.missing_keys or load_result.unexpected_keys:
        if load_result.missing_keys:
            print(f"  âš  missing_keys: {len(load_result.missing_keys)} ä¸ª")
            for k in load_result.missing_keys[:5]:
                print(f"      - {k}")
            if len(load_result.missing_keys) > 5:
                print(f"      ... ç­‰ {len(load_result.missing_keys)} ä¸ª")
        if load_result.unexpected_keys:
            print(f"  âš  unexpected_keys: {len(load_result.unexpected_keys)} ä¸ª")
            for k in load_result.unexpected_keys[:5]:
                print(f"      - {k}")
            if len(load_result.unexpected_keys) > 5:
                print(f"      ... ç­‰ {len(load_result.unexpected_keys)} ä¸ª")
    model.eval()
    
    # å¯ç”¨ token pruning - å¼ºåˆ¶è®¾ç½® epoch=100 ä»¥è·¨è¶Š warmup é˜¶æ®µ
    if hasattr(model, 'encoder') and hasattr(model.encoder, 'set_epoch'):
        dset_config = config.get('model', {}).get('dset', {})
        warmup_epochs = dset_config.get('token_pruning_warmup_epochs', 10)
        target_keep_ratio = dset_config.get('token_keep_ratio', 1.0)
        
        # å¼ºåˆ¶ epoch=100 ä»¥ç¡®ä¿å‰ªæå®Œå…¨æ¿€æ´»ï¼ˆprogress=1.0ï¼‰
        forced_epoch = 100
        model.encoder.set_epoch(forced_epoch)
        
        # éªŒè¯å‰ªæçŠ¶æ€
        if hasattr(model.encoder, 'token_pruners') and model.encoder.token_pruners:
            pruner = model.encoder.token_pruners[0]
            actual_keep_ratio = pruner.get_current_keep_ratio() if hasattr(pruner, 'get_current_keep_ratio') else None
            pruning_enabled = pruner.pruning_enabled if hasattr(pruner, 'pruning_enabled') else False
            print(f"  âœ“ Token Pruning: epoch={forced_epoch}, warmup={warmup_epochs}")
            print(f"    - pruning_enabled: {pruning_enabled}")
            print(f"    - target_keep_ratio: {target_keep_ratio}")
            print(f"    - actual_keep_ratio: {actual_keep_ratio}")
        else:
            print(f"  âœ“ å·²å¯ç”¨ token pruning (epoch={forced_epoch})")
    
    return model, config


def load_rtdetr_model(config_path: str, checkpoint_path: str, device: str = "cuda"):
    """åŠ è½½ RT-DETRv2 æ¨¡å‹"""
    rtdetr_dir = Path(config_path).parent.parent
    if str(rtdetr_dir) not in sys.path:
        sys.path.insert(0, str(rtdetr_dir))
    from train import RTDETRTrainer
    
    with open(config_path, 'r', encoding='utf-8') as f:
        config = yaml.safe_load(f)
    
    if 'misc' not in config:
        config['misc'] = {}
    config['misc']['device'] = device
    
    trainer = RTDETRTrainer(config)
    if trainer.logger is None:
        class SimpleLogger:
            def info(self, msg): pass
        trainer.logger = SimpleLogger()
    
    model = trainer.create_model()
    checkpoint = _load_checkpoint(checkpoint_path)
    state_dict = _extract_state_dict(checkpoint)
    model.load_state_dict(state_dict, strict=False)
    model.eval()
    model = model.to(device)
    
    return model, config


def load_deformable_detr_model(checkpoint_path: str, device: str = "cuda", config_path: str = None):
    """åŠ è½½ Deformable-DETR æ¨¡å‹"""
    try:
        from mmengine.config import Config
        from mmdet.registry import MODELS
    except ImportError:
        raise ImportError("éœ€è¦å®‰è£… mmengine å’Œ mmdet")

    # å…³é”®ï¼šç¡®ä¿ mmdet çš„æ‰€æœ‰æ¨¡å—éƒ½å·²æ³¨å†Œåˆ° mmengine Registryï¼Œå¦åˆ™ä¼šå‡ºç°
    # "DetDataPreprocessor is not in the mmengine::model registry" ä¹‹ç±»çš„é”™è¯¯ã€‚
    try:
        from mmdet.utils import register_all_modules
        try:
            # æ–°ç‰ˆ mmdet æ¨èï¼šåŒæ—¶åˆå§‹åŒ– default scope
            register_all_modules(init_default_scope=True)
        except TypeError:
            # å…¼å®¹æ—§ç‰ˆç­¾å
            register_all_modules()
    except Exception:
        # æŸäº›ç¯å¢ƒå¯èƒ½æ²¡æœ‰è¯¥å·¥å…·å‡½æ•°ï¼Œä½†æ­£å¸¸ import mmdet ä¹Ÿä¼šè§¦å‘æ³¨å†Œ
        try:
            import mmdet  # noqa: F401
        except Exception:
            pass
    
    checkpoint = _load_checkpoint(checkpoint_path)
    state_dict = checkpoint.get('state_dict', checkpoint.get('model', checkpoint))
    
    cfg = None
    # ä¼˜å…ˆä½¿ç”¨æ˜¾å¼æä¾›çš„ config_pathï¼ˆæ›´ç¨³å®šã€å¯å¤ç°ï¼‰
    if config_path and os.path.exists(config_path):
        cfg = Config.fromfile(config_path)
    # å›é€€ï¼šå°è¯•ä» checkpoint meta ä¸­æ¢å¤é…ç½®
    elif 'meta' in checkpoint and 'cfg' in checkpoint['meta']:
        meta_cfg = checkpoint['meta']['cfg']
        # å…¼å®¹ï¼šæœ‰äº› mmdet/mmengine checkpoint ä¼šæŠŠ cfg ä¿å­˜ä¸º dictï¼›ä¹Ÿæœ‰å¾ˆå¤šä¿å­˜ä¸º strï¼ˆæ–‡ä»¶è·¯å¾„æˆ–æ–‡æœ¬å†…å®¹ï¼‰
        if isinstance(meta_cfg, dict):
            cfg = Config(meta_cfg)
        elif isinstance(meta_cfg, str):
            # 1) å¦‚æœæ˜¯æ–‡ä»¶è·¯å¾„
            if os.path.exists(meta_cfg):
                cfg = Config.fromfile(meta_cfg)
            else:
                # 2) å¯èƒ½æ˜¯ python config æ–‡æœ¬å†…å®¹
                if hasattr(Config, 'fromstring'):
                    try:
                        cfg = Config.fromstring(meta_cfg, file_format='.py')
                    except TypeError:
                        # å…¼å®¹æ—§ç‰ˆæœ¬ç­¾å
                        cfg = Config.fromstring(meta_cfg)
                else:
                    # 3) æç«¯å…¼å®¹ï¼šå†™å…¥ä¸´æ—¶æ–‡ä»¶å† fromfile
                    import tempfile
                    with tempfile.NamedTemporaryFile('w', suffix='.py', delete=False, encoding='utf-8') as f:
                        f.write(meta_cfg)
                        tmp_cfg_path = f.name
                    cfg = Config.fromfile(tmp_cfg_path)
    
    if cfg is None:
        raise FileNotFoundError("æ— æ³•æ‰¾åˆ° Deformable-DETR é…ç½®æ–‡ä»¶")
    
    model = MODELS.build(cfg.model)
    model.load_state_dict(state_dict, strict=False)
    model.eval()
    model = model.to(device)
    
    # å°† Config å¯¹è±¡è½¬æ¢ä¸º dict ä»¥ä¾¿åç»­å¤„ç†
    config_dict = {}
    try:
        if hasattr(cfg, '_cfg_dict'):
            config_dict = cfg._cfg_dict
        elif hasattr(cfg, 'to_dict'):
            config_dict = cfg.to_dict()
        elif hasattr(cfg, '__dict__'):
            config_dict = dict(cfg.__dict__)
    except:
        pass
    
    return model, config_dict


def _ensure_yolo_checkpoint_path(checkpoint_path: str) -> str:
    """ç¡®ä¿ YOLO æ£€æŸ¥ç‚¹è·¯å¾„ä½¿ç”¨ .pt åç¼€"""
    checkpoint_path_obj = Path(checkpoint_path)
    
    if checkpoint_path_obj.suffix.lower() == '.pt':
        return str(checkpoint_path_obj)
    
    if checkpoint_path_obj.suffix.lower() == '.pth':
        pt_path = checkpoint_path_obj.with_suffix('.pt')
        if pt_path.exists():
            return str(pt_path)
        if not checkpoint_path_obj.exists():
            raise FileNotFoundError(f"æ£€æŸ¥ç‚¹æ–‡ä»¶ä¸å­˜åœ¨: {checkpoint_path_obj}")
        
        try:
            pt_path.symlink_to(checkpoint_path_obj)
            return str(pt_path)
        except OSError:
            import shutil
            shutil.copy2(checkpoint_path_obj, pt_path)
            return str(pt_path)
    
    return str(checkpoint_path_obj)


def load_yolov8_model(checkpoint_path: str, device: str = "cuda"):
    """åŠ è½½ YOLOv8 æ¨¡å‹"""
    yolov8_dir = Path(__file__).parent.parent.parent / "experiments" / "yolov8"
    if str(yolov8_dir) not in sys.path:
        sys.path.insert(0, str(yolov8_dir))
    from ultralytics import YOLO
    
    checkpoint_path_pt = _ensure_yolo_checkpoint_path(checkpoint_path)
    model = YOLO(checkpoint_path_pt)
    model.to(device)
    model.eval()
    
    # æ„å»ºé…ç½®å­—å…¸
    config = {
        'model_type': 'yolov8',
        'data': None
    }
    
    # å°è¯•ä»æ¨¡å‹å¯¹è±¡ä¸­è·å–æ•°æ®é›†è·¯å¾„
    try:
        if hasattr(model, 'ckpt') and model.ckpt and hasattr(model.ckpt, 'data'):
            config['data'] = model.ckpt.data
    except:
        pass
    
    return model, config


def load_yolov10_model(checkpoint_path: str, device: str = "cuda"):
    """åŠ è½½ YOLOv10 æ¨¡å‹"""
    yolov10_dir = Path(__file__).parent.parent.parent / "experiments" / "yolov10"
    if str(yolov10_dir) not in sys.path:
        sys.path.insert(0, str(yolov10_dir))
    from ultralytics import YOLO
    
    checkpoint_path_pt = _ensure_yolo_checkpoint_path(checkpoint_path)
    model = YOLO(checkpoint_path_pt)
    model.to(device)
    model.eval()
    
    # æ„å»ºé…ç½®å­—å…¸
    config = {
        'model_type': 'yolov10',
        'data': None
    }
    
    # å°è¯•ä»æ¨¡å‹å¯¹è±¡ä¸­è·å–æ•°æ®é›†è·¯å¾„
    try:
        if hasattr(model, 'ckpt') and model.ckpt and hasattr(model.ckpt, 'data'):
            config['data'] = model.ckpt.data
    except:
        pass
    
    return model, config


def evaluate_yolo_accuracy(model, config_path: str, device: str = "cuda", max_samples: int = 300) -> Dict[str, float]:
    """ä½¿ç”¨ YOLO model.val() è¿›è¡Œè¯„ä¼°ï¼ˆä»…ç²¾åº¦ï¼Œæ— æ€§èƒ½æµ‹è¯•ï¼‰"""
    try:
        print(f"  âœ“ ä½¿ç”¨ YOLO model.val() è¿›è¡Œè¯„ä¼°")
        
        results = model.val(
            data=str(config_path),
            device=device,
            verbose=False,
            max_det=300,
            batch=1
        )
        
        metrics = {'mAP': 0.0, 'AP50': 0.0, 'APS': 0.0}
        
        if hasattr(results, 'box'):
            if hasattr(results.box, 'map'):
                metrics['mAP'] = float(results.box.map)
            if hasattr(results.box, 'map50'):
                metrics['AP50'] = float(results.box.map50)
            if hasattr(results.box, 'maps') and len(results.box.maps) > 1:
                metrics['APS'] = float(results.box.maps[1])
        
        print(f"  âœ“ mAP: {metrics['mAP']:.3f}, AP50: {metrics['AP50']:.3f}, APS: {metrics['APS']:.3f}")
        return metrics
        
    except Exception as e:
        print(f"  âš  YOLO è¯„ä¼°å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return {'mAP': 0.0, 'AP50': 0.0, 'APS': 0.0}


def evaluate_deformable_detr_accuracy(model, config_path: str, device: str = "cuda") -> Dict[str, float]:
    """è¯„ä¼° Deformable-DETR æ¨¡å‹ï¼ˆä½¿ç”¨ mmdet/mmengine Runner.test()ï¼Œä»…ç²¾åº¦ï¼‰"""
    metrics = evaluate_deformable_detr_full(
        config_path=config_path,
        checkpoint_path=None,
        device=device,
    )
    return metrics


def _safe_get_metric(metrics: Dict, keys: List[str], default: float = 0.0) -> float:
    """Robust metric key lookup across mmdet versions."""
    for k in keys:
        if k in metrics:
            try:
                return float(metrics[k])
            except Exception:
                pass
    # å…¼å®¹ï¼šæœ‰äº› evaluator ä¼šæŠŠ key å†™æˆ 'coco/bbox_mAP' æˆ– 'bbox_mAP'
    for k, v in metrics.items():
        if isinstance(k, str):
            for cand in keys:
                if k.endswith(cand) or cand in k:
                    try:
                        return float(v)
                    except Exception:
                        pass
    return float(default)


def _move_to_device(obj, device: str):
    """Recursively move tensors to device (for mmengine/mmdet batch dict)."""
    if torch.is_tensor(obj):
        return obj.to(device)
    if isinstance(obj, dict):
        return {k: _move_to_device(v, device) for k, v in obj.items()}
    if isinstance(obj, (list, tuple)):
        moved = [_move_to_device(v, device) for v in obj]
        return type(obj)(moved) if not isinstance(obj, tuple) else tuple(moved)
    return obj


def evaluate_deformable_detr_full(config_path: str,
                                  checkpoint_path: Optional[str],
                                  device: str = "cuda") -> Dict[str, float]:
    """è¯„ä¼° Deformable-DETR æ¨¡å‹ï¼ˆä»…ç²¾åº¦ï¼Œä½¿ç”¨ mmdet Runner.test()ï¼‰"""
    try:
        from mmengine.config import Config
        from mmengine.runner import Runner
        from mmdet.utils import register_all_modules
    except Exception as e:
        print(f"  âš  Deformable-DETR è¯„ä¼°ä¾èµ–å¯¼å…¥å¤±è´¥: {e!r}")
        return {'mAP': 0.0, 'AP50': 0.0, 'APS': 0.0}
    
    # æ³¨å†Œ mmdet æ¨¡å—ï¼ˆä¸åŒç‰ˆæœ¬ç­¾åç•¥æœ‰å·®å¼‚ï¼‰
    try:
        register_all_modules(init_default_scope=True)
    except TypeError:
        register_all_modules()
    
    cfg = Config.fromfile(config_path)
    # ä¸è®¾ç½® cfg.load_fromï¼šPyTorch 2.6+ é»˜è®¤ weights_only=Trueï¼Œmmengine checkpoint å«è‡ªå®šä¹‰ç±»ä¼šæŠ¥é”™ã€‚
    # æ”¹ä¸ºæ‰‹åŠ¨åŠ è½½ï¼ˆä½¿ç”¨ weights_only=Falseï¼‰ï¼Œé¿å… Runner å†…éƒ¨ torch.load å¤±è´¥ã€‚
    
    # é¿å…å†™æ—¥å¿—åˆ° work_dirï¼ˆRunner éœ€è¦ä½†æˆ‘ä»¬ä¸å…³å¿ƒï¼‰
    try:
        import tempfile
        cfg.work_dir = tempfile.mkdtemp(prefix='bench_deformable_detr_')
    except Exception:
        cfg.work_dir = cfg.get('work_dir', './work_dirs/bench_deformable_detr')
    
    runner = Runner.from_cfg(cfg)
    if checkpoint_path:
        checkpoint = _load_checkpoint(checkpoint_path)
        state_dict = checkpoint.get('state_dict', checkpoint.get('model', checkpoint))
        runner.model.load_state_dict(state_dict, strict=False)
    runner.model = runner.model.to(device)
    runner.model.eval()
    
    # ç²¾åº¦è¯„ä¼°ï¼ˆCOCO mAPï¼‰
    test_metrics = runner.test()
    
    mAP = _safe_get_metric(test_metrics, ['coco/bbox_mAP', 'bbox_mAP', 'mAP'], 0.0)
    AP50 = _safe_get_metric(test_metrics, ['coco/bbox_mAP_50', 'bbox_mAP_50', 'AP50', 'mAP_50'], 0.0)
    APS = _safe_get_metric(test_metrics, ['coco/bbox_mAP_s', 'bbox_mAP_s', 'APS', 'mAP_s'], 0.0)
    
    return {'mAP': mAP, 'AP50': AP50, 'APS': APS}


def _get_outputs_info(outputs: Dict) -> Tuple[torch.Tensor, torch.Tensor, bool]:
    """ä»æ¨¡å‹è¾“å‡ºä¸­æå– logits å’Œ boxes
    
    æ³¨æ„ï¼šDSET å’Œ RT-DETR å‡ä½¿ç”¨ Focal Lossï¼Œæ¨ç†æ—¶åº”ä½¿ç”¨ Sigmoid æ¿€æ´»
    """
    if 'pred_logits' in outputs:
        return outputs['pred_logits'], outputs['pred_boxes'], True  # RT-DETR: sigmoid
    elif 'class_scores' in outputs:
        return outputs['class_scores'], outputs['bboxes'], True  # DSET: sigmoid (Focal Loss)
    return None, None, False


def _collect_predictions_for_coco(outputs: Dict, targets: List[Dict], batch_idx: int,
                                  all_predictions: List, all_targets: List,
                                  img_w: int, img_h: int, batch_size: int) -> None:
    """æ”¶é›†é¢„æµ‹ç»“æœç”¨äº COCO è¯„ä¼°"""
    pred_logits, pred_boxes, use_sigmoid = _get_outputs_info(outputs)
    if pred_logits is None:
        return
    
    batch_size_actual = pred_logits.shape[0]
    
    for i in range(batch_size_actual):
        # å°è¯•ä» target ä¸­ç›´æ¥è·å–åŸå§‹ ID
        if i < len(targets) and 'image_id' in targets[i]:
            img_id = int(targets[i]['image_id'].item())
        else:
            # å¦‚æœæ²¡æœ‰ï¼Œå†é€€å›åˆ°ç´¢å¼•è®¡ç®—é€»è¾‘ï¼Œä½†è¦ç¡®ä¿ batch_size æ­£ç¡®
            img_id = batch_idx * batch_size + i
        
        if use_sigmoid:
            pred_scores = torch.sigmoid(pred_logits[i])
        else:
            pred_scores = torch.softmax(pred_logits[i], dim=-1)
        max_scores, pred_classes = torch.max(pred_scores, dim=-1)
        
        valid_boxes_mask = ~torch.all(pred_boxes[i] == 1.0, dim=1)
        valid_indices = torch.where(valid_boxes_mask)[0]
        
        if len(valid_indices) > 0:
            filtered_boxes = pred_boxes[i][valid_indices]
            filtered_classes = pred_classes[valid_indices]
            filtered_scores = max_scores[valid_indices]
            
            if filtered_boxes.shape[0] > 0:
                boxes_coco = torch.zeros_like(filtered_boxes)
                if filtered_boxes.max() <= 1.0:
                    boxes_coco[:, 0] = (filtered_boxes[:, 0] - filtered_boxes[:, 2] / 2) * img_w
                    boxes_coco[:, 1] = (filtered_boxes[:, 1] - filtered_boxes[:, 3] / 2) * img_h
                    boxes_coco[:, 2] = filtered_boxes[:, 2] * img_w
                    boxes_coco[:, 3] = filtered_boxes[:, 3] * img_h
                else:
                    boxes_coco = filtered_boxes.clone()
                
                boxes_coco[:, 0] = torch.clamp(boxes_coco[:, 0], 0, img_w)
                boxes_coco[:, 1] = torch.clamp(boxes_coco[:, 1], 0, img_h)
                boxes_coco[:, 2] = torch.clamp(boxes_coco[:, 2], 1, img_w)
                boxes_coco[:, 3] = torch.clamp(boxes_coco[:, 3], 1, img_h)
                
                for j in range(boxes_coco.shape[0]):
                    x, y, w, h = boxes_coco[j].cpu().numpy()
                    all_predictions.append({
                        'image_id': img_id,
                        'category_id': int(filtered_classes[j].item()) + 1,
                        'bbox': [float(x), float(y), float(w), float(h)],
                        'score': float(filtered_scores[j].item())
                    })
        
        # å¤„ç†çœŸå®æ ‡ç­¾
        if i < len(targets) and 'labels' in targets[i] and 'boxes' in targets[i]:
            true_labels = targets[i]['labels']
            true_boxes = targets[i]['boxes']
            
            if len(true_labels) > 0:
                max_val = float(true_boxes.max().item()) if true_boxes.numel() > 0 else 0.0
                true_boxes_coco = torch.zeros_like(true_boxes)
                
                if max_val <= 1.0 + 1e-6:
                    true_boxes_coco[:, 0] = (true_boxes[:, 0] - true_boxes[:, 2] / 2) * img_w
                    true_boxes_coco[:, 1] = (true_boxes[:, 1] - true_boxes[:, 3] / 2) * img_h
                    true_boxes_coco[:, 2] = true_boxes[:, 2] * img_w
                    true_boxes_coco[:, 3] = true_boxes[:, 3] * img_h
                else:
                    true_boxes_coco = true_boxes.clone()
                
                true_boxes_coco[:, 0] = torch.clamp(true_boxes_coco[:, 0], 0, img_w)
                true_boxes_coco[:, 1] = torch.clamp(true_boxes_coco[:, 1], 0, img_h)
                true_boxes_coco[:, 2] = torch.clamp(true_boxes_coco[:, 2], 1, img_w)
                true_boxes_coco[:, 3] = torch.clamp(true_boxes_coco[:, 3], 1, img_h)
                
                has_iscrowd = 'iscrowd' in targets[i]
                iscrowd_values = targets[i].get('iscrowd', torch.zeros(len(true_labels), dtype=torch.int64))
                
                for j in range(len(true_labels)):
                    x, y, w, h = true_boxes_coco[j].cpu().numpy()
                    ann_dict = {
                        'id': len(all_targets),
                        'image_id': img_id,
                        'category_id': int(true_labels[j].item()) + 1,
                        'bbox': [float(x), float(y), float(w), float(h)],
                        'area': float(w * h)
                    }
                    if has_iscrowd:
                        ann_dict['iscrowd'] = int(iscrowd_values[j].item())
                    all_targets.append(ann_dict)


def evaluate_accuracy(model, config_path: str, device: str = "cuda", 
                      model_type: str = "dset", max_samples: int = 300) -> Dict[str, float]:
    """ä½¿ç”¨ pycocotools åœ¨éªŒè¯é›†ä¸Šè¿è¡Œ COCO è¯„ä¼°ï¼ˆä»…ç²¾åº¦ï¼Œæ— æ€§èƒ½æµ‹è¯•ï¼‰"""
    try:
        # å¯¼å…¥ Trainer
        if model_type == "dset":
            try:
                from experiments.dset.train import DSETTrainer
            except ImportError:
                dset_dir = Path(config_path).parent.parent
                if str(dset_dir) not in sys.path:
                    sys.path.insert(0, str(dset_dir))
                from train import DSETTrainer
            TrainerClass = DSETTrainer
        elif model_type == "rtdetr":
            rtdetr_dir = Path(config_path).parent.parent
            if str(rtdetr_dir) not in sys.path:
                sys.path.insert(0, str(rtdetr_dir))
            from train import RTDETRTrainer
            TrainerClass = RTDETRTrainer
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„æ¨¡å‹ç±»å‹: {model_type}")
        
        # åŠ è½½é…ç½®ï¼ˆä¸å¼ºåˆ¶ batch_sizeï¼Œä½¿ç”¨é…ç½®æ–‡ä»¶ä¸­çš„è®¾ç½®ä»¥åŠ é€Ÿè¯„ä¼°ï¼‰
        with open(config_path, 'r', encoding='utf-8') as f:
            config = yaml.safe_load(f)
        
        if 'misc' not in config:
            config['misc'] = {}
        config['misc']['device'] = device
        
        # åˆ›å»º DataLoaderï¼ˆä½¿ç”¨é…ç½®æ–‡ä»¶ä¸­çš„ batch_sizeï¼‰
        if model_type == "dset":
            trainer = TrainerClass(config, config_file_path=str(config_path))
            _, val_loader = trainer._create_data_loaders()
        else:
            trainer = TrainerClass(config)
            trainer.model = model
            trainer.criterion = trainer.create_criterion()
            _, val_loader = trainer.create_datasets()
        
        dataset_size = len(val_loader.dataset)
        dataloader_length = len(val_loader)
        actual_batch_size = val_loader.batch_size if hasattr(val_loader, 'batch_size') else None
        
        print(f"  âœ“ DataLoader: {dataloader_length} batches, {dataset_size} samples (batch_size={actual_batch_size})")
        
        model.eval()
        model = model.to(device)
        
        # éªŒè¯ token pruning çŠ¶æ€
        if hasattr(model, 'encoder') and hasattr(model.encoder, 'token_pruners'):
            if model.encoder.token_pruners:
                pruner = model.encoder.token_pruners[0]
                if hasattr(pruner, 'pruning_enabled'):
                    print(f"  âœ“ Token Pruning: {'å·²æ¿€æ´»' if pruner.pruning_enabled else 'æœªæ¿€æ´»'}")
        
        all_predictions = []
        all_targets = []
        
        print(f"  è¿è¡Œè¯„ä¼°å¾ªç¯ï¼ˆä»…ç²¾åº¦è¯„ä¼°ï¼Œæ— æ€§èƒ½æµ‹è¯•ï¼‰...")
        
        with torch.no_grad():
            for batch_idx, (images, targets) in enumerate(val_loader):
                B, C, H_tensor, W_tensor = images.shape
                images = images.to(device)
                targets = [{k: v.to(device) if isinstance(v, torch.Tensor) else v 
                           for k, v in t.items()} for t in targets]
                
                # å•æ¬¡å‰å‘ä¼ æ’­è·å–è¾“å‡º
                outputs = model(images)
                
                has_predictions = isinstance(outputs, dict) and (
                    ('class_scores' in outputs and 'bboxes' in outputs) or
                    ('pred_logits' in outputs and 'pred_boxes' in outputs)
                )
                
                if has_predictions:
                    # åŠ¨æ€è·å–å½“å‰ batch çš„çœŸå®å›¾ç‰‡æ•°é‡ B
                    current_batch_actual_size = images.shape[0]
                    
                    _collect_predictions_for_coco(
                        outputs, targets, batch_idx, all_predictions, all_targets,
                        W_tensor, H_tensor, current_batch_actual_size  # ä¿®å¤ï¼šä¼ å…¥çœŸå®çš„ B
                    )
                
                # è¿›åº¦æ‰“å°ï¼šæ¯ 100 ä¸ªæ ·æœ¬æ‰“å°ä¸€æ¬¡
                if (batch_idx + 1) % 100 == 0:
                    print(f"    è¿›åº¦: {batch_idx + 1}/{dataloader_length}")
        
        print(f"  âœ“ å®Œæˆ: {len(val_loader)} æ ·æœ¬, {len(all_predictions)} é¢„æµ‹æ¡†")
        
        # COCO è¯„ä¼°ï¼ˆä»…ç²¾åº¦æŒ‡æ ‡ï¼‰
        metrics = _compute_coco_metrics(all_predictions, all_targets, H_tensor, W_tensor)
        
        return metrics
        
    except Exception as e:
        print(f"  âš  COCO è¯„ä¼°å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return {'mAP': 0.0, 'AP50': 0.0, 'APS': 0.0}


def _compute_coco_metrics(predictions: List[Dict], targets: List[Dict],
                          img_h: int = 736, img_w: int = 1280) -> Dict[str, float]:
    """ä½¿ç”¨ pycocotools è®¡ç®— COCO æŒ‡æ ‡"""
    try:
        if len(predictions) == 0:
            return {'mAP': 0.0, 'AP50': 0.0, 'APS': 0.0}
        
        categories = [
            {'id': 1, 'name': 'Car'}, {'id': 2, 'name': 'Truck'},
            {'id': 3, 'name': 'Van'}, {'id': 4, 'name': 'Bus'},
            {'id': 5, 'name': 'Pedestrian'}, {'id': 6, 'name': 'Cyclist'},
            {'id': 7, 'name': 'Motorcyclist'}, {'id': 8, 'name': 'Trafficcone'}
        ]
        
        image_ids = set(t['image_id'] for t in targets)
        coco_gt = {
            'images': [{'id': img_id, 'width': img_w, 'height': img_h} for img_id in image_ids],
            'annotations': targets,
            'categories': categories,
            'info': {'description': 'DAIR-V2X Dataset', 'version': '1.0', 'year': 2024}
        }
        
        coco_gt_obj = COCO()
        coco_gt_obj.dataset = coco_gt
        
        old_stdout = sys.stdout
        sys.stdout = StringIO()
        try:
            coco_gt_obj.createIndex()
            coco_dt = coco_gt_obj.loadRes(predictions)
        finally:
            sys.stdout = old_stdout
        
        coco_eval = COCOeval(coco_gt_obj, coco_dt, 'bbox')
        
        sys.stdout = StringIO()
        try:
            coco_eval.evaluate()
            coco_eval.accumulate()
            coco_eval.summarize()
        finally:
            sys.stdout = old_stdout
        
        stats = coco_eval.stats
        metrics = {
            'mAP': float(stats[0]) if len(stats) > 0 else 0.0,
            'AP50': float(stats[1]) if len(stats) > 1 else 0.0,
            'APS': float(stats[3]) if len(stats) > 3 else 0.0
        }
        
        print(f"  âœ“ mAP: {metrics['mAP']:.3f}, AP50: {metrics['AP50']:.3f}, APS: {metrics['APS']:.3f}")
        return metrics
        
    except Exception as e:
        print(f"  âš  COCO æŒ‡æ ‡è®¡ç®—å¤±è´¥: {e}")
        return {'mAP': 0.0, 'AP50': 0.0, 'APS': 0.0}


def _resolve_path(path_str: str, project_root: Path) -> Path:
    """è§£æè·¯å¾„"""
    if not path_str:
        return None
    path = Path(path_str)
    return path if path.is_absolute() else project_root / path


def _get_yolo_data_path(model, model_config: Dict, project_root: Path) -> Optional[Path]:
    """è·å– YOLO æ¨¡å‹çš„æ•°æ®é›†é…ç½®æ–‡ä»¶è·¯å¾„"""
    data_config = model_config.get('data', None)
    if data_config:
        data_path = _resolve_path(data_config, project_root)
        if data_path and data_path.exists():
            return data_path
    
    try:
        if hasattr(model, 'ckpt') and model.ckpt and hasattr(model.ckpt, 'data'):
            data_path = _resolve_path(model.ckpt.data, project_root)
            if data_path and data_path.exists():
                return data_path
    except:
        pass
    
    return None


def evaluate_single_model(model_name: str, model_config: Dict, args, project_root: Path, debug: bool = False) -> Optional[Dict]:
    """è¯„ä¼°å•ä¸ªæ¨¡å‹"""
    print("\n" + "=" * 80)
    print(f"è¯„ä¼°æ¨¡å‹: {model_name}")
    print("=" * 80)
    
    model_type = model_config.get('type', args.model_type)
    config_path_str = model_config.get('config', args.config)
    checkpoint_path_str = model_config.get('checkpoint', None)
    input_size_override = model_config.get('input_size', None)
    
    # ç¡®å®š input_size
    if input_size_override is not None:
        input_size = input_size_override
    elif "yolo" in model_type.lower():
        input_size = [1280, 1280]
    else:
        input_size = [736, 1280]
    
    config_path = _resolve_path(config_path_str, project_root) if config_path_str else None
    
    # å¤„ç†æ£€æŸ¥ç‚¹è·¯å¾„
    if checkpoint_path_str:
        checkpoint_path = _resolve_path(checkpoint_path_str, project_root)
        if not checkpoint_path.exists():
            print(f"âš  æ£€æŸ¥ç‚¹ä¸å­˜åœ¨: {checkpoint_path}")
            return None
    else:
        logs_dir = _resolve_path(args.logs_dir, project_root)
        checkpoint_path = find_latest_best_model(logs_dir, model_type)
        if checkpoint_path is None:
            print(f"âš  æ— æ³•æ‰¾åˆ°æ£€æŸ¥ç‚¹")
            return None
    
    print(f"  ç±»å‹: {model_type}, è¾“å…¥: {input_size[0]}x{input_size[1]}")
    print(f"  æ£€æŸ¥ç‚¹: {checkpoint_path}")
    
    # åŠ è½½æ¨¡å‹å’Œé…ç½®
    is_yolo_model = model_type.startswith("yolov8") or model_type.startswith("yolov10")
    config = None
    try:
        if model_type == "dset":
            model, config = load_dset_model(str(config_path), str(checkpoint_path), args.device)
        elif model_type == "rtdetr":
            model, config = load_rtdetr_model(str(config_path), str(checkpoint_path), args.device)
        elif model_type == "deformable-detr":
            model, config = load_deformable_detr_model(str(checkpoint_path), args.device, 
                                                       config_path=str(config_path) if config_path else None)
            # config å·²ç”± load_deformable_detr_model è¿”å›ï¼›è‹¥ä¸ºç©ºåˆ™ç”¨ Config.fromfile è¡¥å……ï¼ˆå« !!python/tuple çš„ yaml éœ€ mmengine è§£æï¼‰
            if not config and config_path:
                try:
                    from mmengine.config import Config
                    config = Config.fromfile(config_path)
                except ImportError:
                    config = {}
        elif model_type.startswith("yolov8"):
            model, config = load_yolov8_model(str(checkpoint_path), args.device)
        elif model_type.startswith("yolov10"):
            model, config = load_yolov10_model(str(checkpoint_path), args.device)
        else:
            print(f"  âš  ä¸æ”¯æŒçš„æ¨¡å‹ç±»å‹: {model_type}")
            return None
        print("  âœ“ æ¨¡å‹åŠ è½½æˆåŠŸ")
    except Exception as e:
        print(f"  âš  æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return None
    
    # è®¡ç®—å‚æ•°é‡å’Œç†è®º FLOPs
    input_size_tuple = (1, 3, input_size[0], input_size[1])
    total_params_m, active_params_m, base_flops_g, theory_flops_g = get_model_info(
        model, input_size_tuple, is_yolo=is_yolo_model, config=config, model_type=model_type, debug=debug
    )
    print(f"  âœ“ Total Params: {total_params_m:.2f}M, Active Params: {active_params_m:.2f}M")
    print(f"  âœ“ Base FLOPs: {base_flops_g:.2f}G, Theory FLOPs: {theory_flops_g:.2f}G")
    
    # è¯„ä¼°ï¼ˆä»…ç²¾åº¦ï¼‰
    metrics = {'mAP': 0.0, 'AP50': 0.0, 'APS': 0.0}
    
    if model_type in ["dset", "rtdetr"] and config_path:
        metrics = evaluate_accuracy(model, str(config_path), args.device, 
                                    model_type=model_type, max_samples=999999)
    elif model_type == "deformable-detr" and config_path:
        metrics = evaluate_deformable_detr_full(
            config_path=str(config_path),
            checkpoint_path=str(checkpoint_path),
            device=args.device,
        )
    elif is_yolo_model:
        data_config_path = _get_yolo_data_path(model, model_config, project_root)
        if data_config_path:
            metrics = evaluate_yolo_accuracy(model, str(data_config_path), args.device, 999999)
        else:
            print(f"  âš  YOLO æ¨¡å‹éœ€è¦æ•°æ®é›†é…ç½®æ–‡ä»¶")
    
    # æ¸…ç†æ˜¾å­˜
    del model
    if torch.cuda.is_available():
        torch.cuda.empty_cache()
    
    return {
        'model_name': model_name,
        'model_type': model_type,
        'total_params_m': total_params_m,
        'active_params_m': active_params_m,
        'base_flops_g': base_flops_g,
        'theory_flops_g': theory_flops_g,
        'mAP': metrics.get('mAP', 0.0),
        'AP50': metrics.get('AP50', 0.0),
        'APS': metrics.get('APS', 0.0),
        'input_size': f"{input_size[0]}x{input_size[1]}"
    }


def print_summary_table(results: List[Dict], gpu_name: str = "GPU", save_csv: bool = True, max_samples: int = 300):
    """æ‰“å°ç»“æœæ±‡æ€»è¡¨æ ¼å¹¶ä¿å­˜ä¸º CSVï¼ˆç†è®ºæ•ˆç‡è§†è§’ï¼‰"""
    if not results:
        print("\nâš  æ²¡æœ‰è¯„ä¼°ç»“æœ")
        return
    
    print("\n" + "=" * 140)
    print("THEORETICAL EFFICIENCY".center(140))
    print("=" * 140)
    
    header = f"{'Model':<25} {'Total':<10} {'Active':<10} {'Theory':<10} {'Resolution':<12} {'mAP':<8} {'AP50':<8} {'APS':<8}"
    print(header)
    print("-" * 140)
    print(f"{'':<25} {'Params':<10} {'Params':<10} {'GFLOPs':<10} {'':<12} {'':<8} {'':<8} {'':<8}")
    print(f"{'':<25} {'(M)':<10} {'(M)':<10} {'':<10} {'':<12} {'':<8} {'':<8} {'':<8}")
    print("-" * 140)
    
    csv_rows = [['Model', 'Type', 'Total Params(M)', 'Active Params(M)', 'Theory GFLOPs', 
                 'Resolution', 'mAP', 'AP50', 'APS', 'Input']]
    
    for r in results:
        name = r.get('model_name', 'Unknown')[:24]
        total_params = f"{r.get('total_params_m', 0):.2f}" if r.get('total_params_m', 0) > 0 else "N/A"
        active_params = f"{r.get('active_params_m', 0):.2f}" if r.get('active_params_m', 0) > 0 else "N/A"
        theory_flops = f"{r.get('theory_flops_g', 0):.2f}" if r.get('theory_flops_g', 0) > 0 else "N/A"
        resolution = r.get('input_size', 'N/A')
        
        mAP = f"{r.get('mAP', 0):.3f}" if r.get('mAP', 0) > 0 else "N/A"
        ap50 = f"{r.get('AP50', 0):.3f}" if r.get('AP50', 0) > 0 else "N/A"
        aps = f"{r.get('APS', 0):.3f}" if r.get('APS', 0) > 0 else "N/A"
        
        print(f"{name:<25} {total_params:<10} {active_params:<10} {theory_flops:<10} {resolution:<12} {mAP:<8} {ap50:<8} {aps:<8}")
        
        csv_rows.append([name, r.get('model_type', ''), total_params, active_params, theory_flops, 
                        resolution, mAP, ap50, aps, r.get('input_size', '')])
    
    print("-" * 140)
    print("Note: Theoretical FLOPs are calculated based on sparsity-aware projection (MoE activation ratio: top_k/expert_num, and token pruning ratio).")
    print("=" * 140)
    
    if save_csv:
        import csv
        csv_path = Path(project_root) / "benchmark_results.csv"
        try:
            with open(csv_path, 'w', newline='', encoding='utf-8') as f:
                csv.writer(f).writerows(csv_rows)
            print(f"\nâœ“ ç»“æœå·²ä¿å­˜åˆ°: {csv_path}")
        except Exception as e:
            print(f"\nâš  ä¿å­˜ CSV å¤±è´¥: {e}")


def find_latest_best_model(logs_dir: Path, model_type: str = "dset") -> Optional[Path]:
    """åœ¨ logs ç›®å½•ä¸‹æ‰¾åˆ°æœ€æ–°çš„ best_model.pth æˆ– best.pt
    
    ä¼˜å…ˆæŸ¥æ‰¾å„å®éªŒç›®å½•ä¸‹ weights/ æ–‡ä»¶å¤¹å†…çš„æ£€æŸ¥ç‚¹æ–‡ä»¶ï¼Œå¹¶æŒ‰æ–‡ä»¶ä¿®æ”¹æ—¶é—´æ’åºè¿”å›æœ€æ–°è€…ã€‚
    """
    best_models = []
    
    if model_type == "deformable-detr":
        # Deformable-DETR: æŸ¥æ‰¾ best_*.pth
        # ä¼˜å…ˆæŸ¥æ‰¾ weights/ ç›®å½•
        best_models.extend(list(logs_dir.rglob("weights/best_*.pth")))
        best_models.extend(list(logs_dir.rglob("best_*.pth")))
    elif model_type.startswith("yolov"):
        # YOLO: æŸ¥æ‰¾ best.pt æˆ– best_model.pth
        # ä¼˜å…ˆæŸ¥æ‰¾ weights/ ç›®å½•
        best_models.extend(list(logs_dir.rglob("weights/best.pt")))
        best_models.extend(list(logs_dir.rglob("weights/best_model.pth")))
        best_models.extend(list(logs_dir.rglob("best.pt")))
        best_models.extend(list(logs_dir.rglob("best_model.pth")))
    else:
        # DSET/RT-DETR: æŸ¥æ‰¾ best_model.pth
        # ä¼˜å…ˆæŸ¥æ‰¾ weights/ ç›®å½•
        best_models.extend(list(logs_dir.rglob("weights/best_model.pth")))
        best_models.extend(list(logs_dir.rglob("best_model.pth")))
    
    # å»é‡å¹¶è¿‡æ»¤å­˜åœ¨çš„æ–‡ä»¶
    best_models = list(set(best_models))
    best_models = [p for p in best_models if p.exists() and p.is_file()]
    
    if not best_models:
        return None
    
    # æŒ‰æ–‡ä»¶ä¿®æ”¹æ—¶é—´æ’åºï¼Œè¿”å›æœ€æ–°çš„
    best_models.sort(key=lambda p: p.stat().st_mtime, reverse=True)
    return best_models[0]


def _format_evaluation_results(model_type: str, total_params_m: float, active_params_m: float, 
                               base_flops_g: float, theory_flops_g: float,
                               metrics: Dict[str, float],
                               input_resolution: Tuple[int, int], is_yolo: bool = False,
                               gpu_name: str = "GPU") -> None:
    """æ ¼å¼åŒ–å¹¶è¾“å‡ºè¯„ä¼°ç»“æœï¼ˆç†è®ºæ•ˆç‡è§†è§’ï¼‰"""
    model_names = {
        'dset': 'DSET', 'rtdetr': 'RT-DETRv2', 'deformable-detr': 'Deformable-DETR',
        'yolov8s': 'YOLOv8-s', 'yolov8m': 'YOLOv8-m',
        'yolov10s': 'YOLOv10-s', 'yolov10m': 'YOLOv10-m'
    }
    name = model_names.get(model_type, model_type.upper())
    
    if is_yolo:
        res = f"{max(input_resolution)}x{max(input_resolution)}"
    else:
        res = f"{input_resolution[0]}x{input_resolution[1]}"
    
    print("\n" + "=" * 70)
    print(f"Model: {name} | Input: {res}")
    print("-" * 70)
    print(f"Total Params: {total_params_m:.2f}M | Active Params: {active_params_m:.2f}M")
    print(f"Base FLOPs: {base_flops_g:.2f}G | Theory FLOPs: {theory_flops_g:.2f}G")
    print(f"mAP: {metrics['mAP']:.3f} | AP50: {metrics['AP50']:.3f} | APS: {metrics['APS']:.3f}")
    print("=" * 70)
    print("Note: Theoretical FLOPs are calculated based on sparsity-aware projection (MoE activation ratio: top_k/expert_num, and token pruning ratio).")


def main():
    parser = argparse.ArgumentParser(description='ç”Ÿæˆæ€§èƒ½å¯¹æ¯”è¡¨')
    parser.add_argument('--logs_dir', type=str, default='experiments/dset/logs')
    parser.add_argument('--config', type=str, default='experiments/dset/logs/dset6_r18_20260126_173526/config.yaml')
    parser.add_argument('--checkpoint', type=str, default=None)
    parser.add_argument('--input_size', type=int, nargs=2, default=None)
    parser.add_argument('--device', type=str, default='cuda')
    parser.add_argument('--model_type', type=str, default='dset',
                       choices=['dset', 'rtdetr', 'deformable-detr', 
                               'yolov8s', 'yolov8m', 'yolov10s', 'yolov10m'])
    parser.add_argument('--rtdetr_config', type=str, default=None)
    parser.add_argument('--deformable_work_dir', type=str, default=None)
    parser.add_argument('--deformable_config', type=str, default=None)
    parser.add_argument('--models_config', type=str, default=None)
    parser.add_argument('--debug', action='store_true', help='å¯ç”¨è°ƒè¯•æ¨¡å¼ï¼šæ‰“å°æ‰€æœ‰æ¨¡å—å±‚åä»¥ä¾¿è°ƒè¯• MoE å±‚è¯†åˆ«')
    
    args = parser.parse_args()
    
    # GPU/CPU åç§°
    if args.device == 'cuda' and torch.cuda.is_available():
        gpu_name = torch.cuda.get_device_name(0)
    else:
        import platform
        gpu_name = f"CPU ({platform.processor() or 'Unknown'})"
    
    print("=" * 80)
    print("æ€§èƒ½å¯¹æ¯”è¡¨ç”Ÿæˆè„šæœ¬")
    print("=" * 80)
    
    # æ„é€ é…ç½®
    if args.models_config:
        json_config_path = _resolve_path(args.models_config, project_root)
        if not json_config_path.exists():
            print(f"é”™è¯¯: JSON é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {json_config_path}")
            return
        with open(json_config_path, 'r', encoding='utf-8') as f:
            json_config = json.load(f)
        print(f"âœ“ æ‰¹é‡è¯„ä¼°: {len(json_config)} ä¸ªæ¨¡å‹\n")
    else:
        if "yolo" in args.model_type.lower():
            input_size = [1280, 1280]
        else:
            input_size = [736, 1280]
        input_size = args.input_size or input_size
        
        single_config = {
            'type': args.model_type,
            'config': args.rtdetr_config or args.deformable_config or args.config,
            'checkpoint': args.checkpoint,
            'input_size': input_size
        }
        json_config = {'single_model': single_config}
        print(f"âœ“ å•æ¨¡å‹è¯„ä¼°\n")
    
    # è¯„ä¼°
    all_results = []
    for model_name, model_config in json_config.items():
        if not isinstance(model_config, dict):
            continue
        result = evaluate_single_model(model_name, model_config, args, project_root, debug=args.debug)
        if result:
            all_results.append(result)
    
    # è¾“å‡ºç»“æœï¼ˆæ— è®ºå•æ¨¡å‹è¿˜æ˜¯å¤šæ¨¡å‹ï¼Œéƒ½ä¿å­˜ CSVï¼‰
    if all_results:
        print_summary_table(all_results, gpu_name, save_csv=True, max_samples=0)


if __name__ == '__main__':
    main()

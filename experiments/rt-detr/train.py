import sys
import os
import argparse
import yaml
import torch
import numpy as np
import re
from pathlib import Path
import logging
from typing import Optional, Dict, Union, List
from pycocotools.cocoeval import COCOeval
from pycocotools.coco import COCO

project_root = Path(__file__).parent.resolve()
if str(os.getcwd()) not in sys.path:
    sys.path.insert(0, os.getcwd())
sys.path.insert(0, str(project_root))
sys.path.insert(0, str(project_root.parent))

from seed_utils import set_seed, seed_worker
from src.misc.training_visualizer import TrainingVisualizer
from src.misc.early_stopping import EarlyStopping
from src.data import DataLoader
from src.optim.ema import ModelEMA
from src.optim.warmup import WarmupLR
from src.data.dataset.dairv2x_detection import DAIRV2XDetection
from src.nn.postprocessor.detr_postprocessor import DetDETRPostProcessor
from src.nn.postprocessor.box_revert import box_revert, BoxProcessFormat
import cv2

try:
    from batch_inference import postprocess_outputs, draw_boxes, inference_from_preprocessed_image
    USE_BATCH_INFERENCE_LOGIC = True
except ImportError:
    USE_BATCH_INFERENCE_LOGIC = False


def create_backbone(backbone_type: str, **kwargs):
    """åˆ›å»ºbackboneçš„å·¥å‚å‡½æ•°"""
    from src.nn.backbone.presnet import PResNet
    from src.nn.backbone.hgnetv2 import HGNetv2
    from src.nn.backbone.csp_resnet import CSPResNet
    from src.nn.backbone.csp_darknet import CSPDarkNet
    
    if backbone_type.startswith('presnet'):
        depth_match = re.search(r'(\d+)', backbone_type)
        if depth_match:
            depth = int(depth_match.group(1))
        else:
            raise ValueError(f"æ— æ³•ä»backboneç±»å‹ {backbone_type} è§£ædepth")
        
        default_params = {
            'depth': depth,
            'variant': 'd',
            'return_idx': [1, 2, 3],
            'freeze_at': 0,
            'freeze_norm': True,
            'pretrained': False
        }
        default_params.update(kwargs)
        return PResNet(**default_params)
    
    elif backbone_type.startswith('hgnetv2'):
        name_map = {'hgnetv2_l': 'L', 'hgnetv2_x': 'X', 'hgnetv2_h': 'H'}
        if backbone_type not in name_map:
            raise ValueError(f"ä¸æ”¯æŒçš„HGNetv2ç±»å‹: {backbone_type}")
        
        default_params = {
            'name': name_map[backbone_type],
            'return_idx': [1, 2, 3],
            'freeze_at': 0,
            'freeze_norm': True,
            'pretrained': False
        }
        default_params.update(kwargs)
        return HGNetv2(**default_params)
    
    elif backbone_type.startswith('cspresnet'):
        name_map = {'cspresnet_s': 's', 'cspresnet_m': 'm', 'cspresnet_l': 'l', 'cspresnet_x': 'x'}
        if backbone_type not in name_map:
            raise ValueError(f"ä¸æ”¯æŒçš„CSPResNetç±»å‹: {backbone_type}")
        
        default_params = {
            'name': name_map[backbone_type],
            'return_idx': [1, 2, 3],
            'pretrained': False
        }
        default_params.update(kwargs)
        return CSPResNet(**default_params)
    
    elif backbone_type == 'cspdarknet':
        default_params = {'return_idx': [2, 3, -1]}
        default_params.update(kwargs)
        return CSPDarkNet(**default_params)
    
    else:
        raise ValueError(f"ä¸æ”¯æŒçš„backboneç±»å‹: {backbone_type}")


class RTDETRTrainer:
    
    def __init__(self, config: Union[str, dict], pretrained_weights: Optional[str] = None, 
                 data_root: Optional[str] = None, epochs: Optional[int] = None,
                 batch_size: Optional[int] = None, warmup_epochs: Optional[int] = None):
        """åˆå§‹åŒ–è®­ç»ƒå™¨
        
        Args:
            config: é…ç½®æ–‡ä»¶è·¯å¾„æˆ–é…ç½®å­—å…¸
            pretrained_weights: é¢„è®­ç»ƒæƒé‡è·¯å¾„ï¼ˆå¯é€‰ï¼Œä¼šè¦†ç›–é…ç½®æ–‡ä»¶ï¼‰
            data_root: æ•°æ®é›†æ ¹ç›®å½•ï¼ˆå¯é€‰ï¼Œä¼šè¦†ç›–é…ç½®æ–‡ä»¶ï¼‰
            epochs: è®­ç»ƒè½®æ•°ï¼ˆå¯é€‰ï¼Œä¼šè¦†ç›–é…ç½®æ–‡ä»¶ï¼‰
            batch_size: æ‰¹æ¬¡å¤§å°ï¼ˆå¯é€‰ï¼Œä¼šè¦†ç›–é…ç½®æ–‡ä»¶ï¼‰
            warmup_epochs: å­¦ä¹ ç‡é¢„çƒ­è½®æ•°ï¼ˆå¯é€‰ï¼Œä¼šè¦†ç›–é…ç½®æ–‡ä»¶ï¼‰
        """
        self.pretrained_weights = pretrained_weights
        
        # åŠ è½½é…ç½®
        using_config_file = isinstance(config, str)
        if using_config_file:
            # ä»æ–‡ä»¶åŠ è½½é…ç½®
            self.config_path = config
            with open(config, 'r', encoding='utf-8') as f:
                self.config = yaml.safe_load(f)
        else:
            # ç›´æ¥ä½¿ç”¨é…ç½®å­—å…¸
            self.config_path = None
            self.config = config
        
        # å¦‚æœä½¿ç”¨é…ç½®æ–‡ä»¶ï¼ŒéªŒè¯å¿…éœ€çš„é…ç½®é¡¹æ˜¯å¦å­˜åœ¨
        if using_config_file:
            self._validate_config_file()
        
        if 'training' in self.config:
            if 'pretrained_lr' in self.config['training']:
                self.config['training']['pretrained_lr'] = float(self.config['training']['pretrained_lr'])
            if 'new_lr' in self.config['training']:
                self.config['training']['new_lr'] = float(self.config['training']['new_lr'])
            if 'eta_min' in self.config['training']:
                self.config['training']['eta_min'] = float(self.config['training']['eta_min'])
            if 'weight_decay' in self.config['training']:
                self.config['training']['weight_decay'] = float(self.config['training']['weight_decay'])
        
        if data_root is not None:
            self.config['data']['data_root'] = data_root
        
        if epochs is not None:
            self.config['training']['epochs'] = epochs
        
        if batch_size is not None:
            self.config['training']['batch_size'] = batch_size
        
        if warmup_epochs is not None:
            self.config['training']['warmup_epochs'] = warmup_epochs
        
        if using_config_file:
            if 'misc' not in self.config or 'device' not in self.config['misc']:
                raise ValueError(f"é…ç½®æ–‡ä»¶ {self.config_path} ç¼ºå°‘å¿…éœ€çš„é…ç½®é¡¹: misc.device")
            device_str = self.config['misc']['device']
        else:
            device_str = self.config.get('misc', {}).get('device', 'cuda')
        self.device = torch.device(device_str)
        self.log_dir = None
        self.logger = None
        self.experiment_name = None
        self._create_directories()
        
        self.model = None
        self.criterion = None
        self.optimizer = None
        self.scheduler = None
        self.warmup_scheduler = None
        self.ema = None
        self.scaler = None
        self.visualizer = None
        self.postprocessor = None
        
        self.class_names = [
            "Car", "Truck", "Van", "Bus", "Pedestrian", 
            "Cyclist", "Motorcyclist", "Trafficcone"
        ]
        self.colors = [
            (255, 0, 0),      # Car - çº¢è‰²
            (0, 255, 0),      # Truck - ç»¿è‰²
            (255, 128, 0),    # Van - æ©™è‰²
            (0, 0, 255),      # Bus - è“è‰²
            (255, 255, 0),    # Pedestrian - é»„è‰²
            (255, 0, 255),    # Cyclist - å“çº¢
            (0, 255, 255),    # Motorcyclist - é’è‰²
            (128, 128, 128),  # Trafficcone - ç°è‰²
        ]
    
    def _validate_config_file(self):
        """éªŒè¯é…ç½®æ–‡ä»¶æ˜¯å¦åŒ…å«æ‰€æœ‰å¿…éœ€çš„é…ç½®é¡¹"""
        required_keys = {
            'model': ['backbone', 'num_decoder_layers', 'hidden_dim', 'num_queries'],
            'training': ['epochs', 'batch_size', 'pretrained_lr', 'new_lr'],
            'data': ['data_root'],
            'misc': ['device', 'num_workers']
        }
        
        missing_keys = []
        for section, keys in required_keys.items():
            if section not in self.config:
                missing_keys.append(f"ç¼ºå°‘é…ç½®èŠ‚: {section}")
                continue
            for key in keys:
                if key not in self.config[section]:
                    missing_keys.append(f"{section}.{key}")
        
        if missing_keys:
            error_msg = f"é…ç½®æ–‡ä»¶ {self.config_path} ç¼ºå°‘å¿…éœ€çš„é…ç½®é¡¹:\n"
            error_msg += "\n".join(f"  - {key}" for key in missing_keys)
            raise ValueError(error_msg)
    
    def setup_logging(self):
        """è®¾ç½®æ—¥å¿—ç³»ç»Ÿ"""
        # æ£€æŸ¥æ˜¯å¦ä»æ£€æŸ¥ç‚¹æ¢å¤
        resume_checkpoint = getattr(self, '_resume_checkpoint_path', None)
        
        if resume_checkpoint and Path(resume_checkpoint).exists():
            # æ¢å¤è®­ç»ƒï¼šä½¿ç”¨æ£€æŸ¥ç‚¹æ‰€åœ¨ç›®å½•ï¼ˆä¸åˆ›å»ºæ–°ç›®å½•ï¼‰
            self.log_dir = Path(resume_checkpoint).parent
            # ä»ç›®å½•åä¸­æå–å®éªŒåç§°ï¼ˆå»æ‰æ—¶é—´æˆ³éƒ¨åˆ†ï¼‰
            dir_name = self.log_dir.name
            # å‡è®¾æ ¼å¼ä¸º rtdetr_r50_20240101_120000ï¼Œæå– rtdetr_r50
            parts = dir_name.rsplit('_', 2)  # åˆ†å‰²æœ€åä¸¤éƒ¨åˆ†ï¼ˆæ—¥æœŸå’Œæ—¶é—´ï¼‰
            if len(parts) >= 2:
                self.experiment_name = '_'.join(parts[:-2]) if len(parts) > 2 else parts[0]
            else:
                self.experiment_name = dir_name
        else:
            # æ–°è®­ç»ƒï¼šåˆ›å»ºå¸¦æ—¶é—´æˆ³çš„ç›®å½•
            from datetime import datetime
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            # ä»é…ç½®ä¸­è·å–backboneç±»å‹ï¼ŒåŠ å…¥åˆ°ç›®å½•åä¸­
            backbone = self.config['model']['backbone']
            # ç§»é™¤presnetå‰ç¼€ï¼Œåªä¿ç•™æ•°å­—éƒ¨åˆ†ï¼ˆå¦‚presnet18 -> r18, presnet34 -> r34ï¼‰
            backbone_short = backbone.replace('presnet', 'r').replace('pres', 'r') if 'presnet' in backbone or 'pres' in backbone else backbone
            # ç”Ÿæˆå®éªŒåç§°ï¼ˆä¸å¸¦æ—¶é—´æˆ³ï¼‰
            self.experiment_name = f"rtdetr_{backbone_short}"
            self.log_dir = Path(f"logs/{self.experiment_name}_{timestamp}")
            self.log_dir.mkdir(parents=True, exist_ok=True)
        
        # é…ç½®æ—¥å¿—å¤„ç†å™¨
        handlers = [
            logging.FileHandler(self.log_dir / 'training.log', mode='a'),
            logging.StreamHandler()
        ]
        
        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s - %(levelname)s - %(message)s',
            handlers=handlers,
            force=True  # å¼ºåˆ¶é‡æ–°é…ç½®
        )
        
        self.logger = logging.getLogger(__name__)
        
        # å¦‚æœæ˜¯æ¢å¤è®­ç»ƒï¼Œè®°å½•æ—¥å¿—
        if resume_checkpoint and Path(resume_checkpoint).exists():
            self.logger.info(f"ğŸ“¦ æ¢å¤è®­ç»ƒï¼Œä½¿ç”¨ç°æœ‰æ—¥å¿—ç›®å½•: {self.log_dir}")
        
        # ä¿å­˜é…ç½®æ–‡ä»¶ï¼ˆä»…æ–°è®­ç»ƒæ—¶ï¼‰
        if not resume_checkpoint:
            config_save_path = self.log_dir / 'config.yaml'
            with open(config_save_path, 'w', encoding='utf-8') as f:
                yaml.dump(self.config, f, default_flow_style=False, allow_unicode=True)
            self.logger.info(f"âœ“ é…ç½®å·²ä¿å­˜åˆ°: {config_save_path}")
    
    def _create_directories(self):
        """åˆ›å»ºå¿…è¦çš„ç›®å½•ï¼ˆå·²åœ¨setup_loggingä¸­åˆ›å»ºï¼‰"""
        # log_dir å·²åœ¨ setup_logging ä¸­åˆ›å»º
        # æ‰€æœ‰è¾“å‡ºéƒ½ä¿å­˜åœ¨ log_dir ä¸­ï¼Œæ— éœ€é¢å¤–åˆ›å»ºç›®å½•
        pass
    
    def create_model(self):
        """åˆ›å»ºæ¨¡å‹"""
        # ä»é…ç½®æ–‡ä»¶è¯»å–backboneç±»å‹
        backbone_type = self.config['model']['backbone']
        
        # åŠ¨æ€åˆ›å»ºbackbone
        backbone = create_backbone(backbone_type)
        
        # ä»é…ç½®æ–‡ä»¶è¯»å–encoderé…ç½®
        encoder_config = self.config['model']['encoder']
        in_channels = encoder_config['in_channels']
        expansion = encoder_config['expansion']
        
        self.logger.info(f"âœ“ Backbone: {backbone_type}")
        self.logger.info(f"âœ“ HybridEncoder: in_channels={in_channels}, expansion={expansion}")
        
        # åˆ›å»ºencoder
        from src.zoo.rtdetr.hybrid_encoder import HybridEncoder
        encoder = HybridEncoder(
            in_channels=in_channels,
            feat_strides=[8, 16, 32],
            hidden_dim=256,
            use_encoder_idx=[2],
            num_encoder_layers=1,
            expansion=expansion,
            nhead=8,
            dim_feedforward=1024,
            dropout=0.0,
            enc_act='gelu',
            act='silu',
            eval_spatial_size=[640, 640]
        )
        
        # ä»é…ç½®æ–‡ä»¶è¯»å–æ¨¡å‹å‚æ•°
        num_decoder_layers = self.config['model']['num_decoder_layers']
        hidden_dim = self.config['model']['hidden_dim']
        num_queries = self.config['model']['num_queries']
        
        # åˆ›å»ºdecoderï¼ˆæ·»åŠ denoisingè®­ç»ƒï¼‰
        from src.zoo.rtdetr.rtdetrv2_decoder import RTDETRTransformerv2
        decoder = RTDETRTransformerv2(
            num_classes=8,  # 8ç±»ï¼šCar, Truck, Van, Bus, Pedestrian, Cyclist, Motorcyclist, Trafficcone
            hidden_dim=hidden_dim,
            num_queries=num_queries,
            num_layers=num_decoder_layers, 
            nhead=8,
            dim_feedforward=1024,
            dropout=0.1,
            activation='relu',
            feat_channels=[256, 256, 256],
            feat_strides=[8, 16, 32],
            num_levels=3,
            # æ·»åŠ denoisingè®­ç»ƒå‚æ•°
            num_denoising=100,
            label_noise_ratio=0.5,
            box_noise_scale=1.0,
            num_points=[4, 4, 4]
        )
        
        self.logger.info(f"âœ“ Decoderé…ç½®: {num_decoder_layers}å±‚, hidden_dim={hidden_dim}, queries={num_queries}")
        
        # åˆ›å»ºRT-DETRæ¨¡å‹
        from src.zoo.rtdetr.rtdetr import RTDETR
        model = RTDETR(backbone=backbone, encoder=encoder, decoder=decoder)
        
        self.logger.info("âœ“ æ¨¡å‹åˆ›å»ºå®Œæˆï¼ˆå·²å¯ç”¨backboneé¢„è®­ç»ƒï¼‰")
        
        return model
    
    def load_pretrained_weights(self, model, pretrained_path: str):
        """åŠ è½½é¢„è®­ç»ƒæƒé‡
        
        æ”¯æŒå¤šç§checkpointæ ¼å¼ï¼š
        - EMAæ ¼å¼: {'ema': {'module': {...}}}
        - æ ‡å‡†æ ¼å¼: {'model': {...}} æˆ– {'model_state_dict': {...}}
        - ç›´æ¥æƒé‡: state_dict
        
        Args:
            model: RT-DETRæ¨¡å‹
            pretrained_path: é¢„è®­ç»ƒæƒé‡è·¯å¾„
        """
        try:
            pretrained_file = Path(pretrained_path)
            if not pretrained_file.exists():
                self.logger.warning(f"âš  é¢„è®­ç»ƒæƒé‡æ–‡ä»¶ä¸å­˜åœ¨: {pretrained_path}")
                self.logger.info("å°†ä½¿ç”¨éšæœºåˆå§‹åŒ–æƒé‡")
                return
            
            self.logger.info(f"æ­£åœ¨ä»æœ¬åœ°æ–‡ä»¶åŠ è½½é¢„è®­ç»ƒæƒé‡: {pretrained_path}")
            checkpoint = torch.load(pretrained_file, map_location='cpu', weights_only=False)
            
            # å¤„ç†ä¸åŒçš„checkpointæ ¼å¼
            if isinstance(checkpoint, dict):
                if 'ema' in checkpoint and 'module' in checkpoint['ema']:
                    # EMAæ ¼å¼: {'ema': {'module': {...}}}
                    state_dict = checkpoint['ema']['module']
                    self.logger.info("âœ“ æ£€æµ‹åˆ°EMA checkpointæ ¼å¼")
                elif 'model' in checkpoint:
                    state_dict = checkpoint['model']
                elif 'model_state_dict' in checkpoint:
                    state_dict = checkpoint['model_state_dict']
                else:
                    state_dict = checkpoint
            else:
                state_dict = checkpoint
            
        
            filtered_state_dict = {}
            skipped_class_params = 0
            
            for k, v in state_dict.items():
                # è·³è¿‡ç±»åˆ«ç›¸å…³çš„å‚æ•°ï¼ˆè¿™äº›å‚æ•°çš„å½¢çŠ¶ä¼šä¸åŒ¹é…ï¼‰
                if any(keyword in k for keyword in ['class_embed', 'score_head', 'denoising_class_embed']):
                    skipped_class_params += 1
                    continue
                filtered_state_dict[k] = v
            
            # åŠ è½½è¿‡æ»¤åçš„å‚æ•°
            missing_keys, unexpected_keys = model.load_state_dict(filtered_state_dict, strict=False)
            
            # ç»Ÿè®¡åŠ è½½ç»“æœ
            # æ³¨æ„ï¼šmissing_keys å¯èƒ½åŒ…å«é¢„è®­ç»ƒæ¨¡å‹ä¸­ä¸å­˜åœ¨çš„å‚æ•°ï¼ˆå¦‚ä¸åŒæ¨¡å‹ç»“æ„çš„å·®å¼‚ï¼‰
            # åªç»Ÿè®¡é¢„è®­ç»ƒæ¨¡å‹ä¸­å®é™…å­˜åœ¨çš„ missing_keys
            actual_missing_keys = [k for k in missing_keys if k in filtered_state_dict]
            total_params = len(filtered_state_dict)
            loaded_params = total_params - len(actual_missing_keys)
            
            self.logger.info(f"âœ“ æˆåŠŸåŠ è½½é¢„è®­ç»ƒæƒé‡: {loaded_params}/{total_params} ä¸ªå‚æ•°")
            
            # æŠ¥å‘Šè·³è¿‡çš„ç±»åˆ«å‚æ•°
            if skipped_class_params > 0:
                self.logger.info(f"  - è·³è¿‡ç±»åˆ«ç›¸å…³å‚æ•°: {skipped_class_params} ä¸ªï¼ˆCOCO 80ç±» â†’ DAIR-V2X 8ç±»ï¼‰")
            
            # ç»Ÿè®¡å„éƒ¨åˆ†çš„å‚æ•°ï¼ˆåªç»Ÿè®¡é¢„è®­ç»ƒæ¨¡å‹ä¸­å®é™…å­˜åœ¨çš„å‚æ•°ï¼‰
            backbone_loaded = sum(1 for k in filtered_state_dict.keys() if k not in actual_missing_keys and 'backbone' in k)
            encoder_loaded = sum(1 for k in filtered_state_dict.keys() if k not in actual_missing_keys and 'encoder' in k)
            decoder_loaded = sum(1 for k in filtered_state_dict.keys() if k not in actual_missing_keys and 'decoder' in k)
            
            self.logger.info(f"  - Backbone: {backbone_loaded} ä¸ªå‚æ•°")
            self.logger.info(f"  - Encoder: {encoder_loaded} ä¸ªå‚æ•°")
            self.logger.info(f"  - Decoder: {decoder_loaded} ä¸ªå‚æ•°")
            
            if len(actual_missing_keys) > 0:
                # actual_missing_keysæ˜¯filtered_state_dictä¸­æœ‰ä½†å½“å‰æ¨¡å‹æ²¡æœ‰çš„å‚æ•°
                self.logger.info(f"  - é¢„è®­ç»ƒæ¨¡å‹ç¼ºå°‘å‚æ•°: {len(actual_missing_keys)} ä¸ªï¼ˆå½“å‰æ¨¡å‹æ–°å¢ï¼‰")
                # æ˜¾ç¤ºå‰3ä¸ªç¤ºä¾‹
                if len(actual_missing_keys) <= 5:
                    self.logger.info(f"    ç¤ºä¾‹: {list(actual_missing_keys)}")
                else:
                    self.logger.info(f"    ç¤ºä¾‹: {list(actual_missing_keys)[:3]} ...")
            
            # å¦‚æœ missing_keys ä¸­æœ‰é¢„è®­ç»ƒæ¨¡å‹ä¸­ä¸å­˜åœ¨çš„å‚æ•°ï¼Œè¯´æ˜æ˜¯æ¨¡å‹ç»“æ„å·®å¼‚
            model_only_missing = [k for k in missing_keys if k not in filtered_state_dict]
            if len(model_only_missing) > 0:
                self.logger.debug(f"  - æ¨¡å‹ç»“æ„å·®å¼‚å¯¼è‡´çš„ missing_keys: {len(model_only_missing)} ä¸ªï¼ˆé¢„è®­ç»ƒæ¨¡å‹ä¸­ä¸å­˜åœ¨ï¼Œä¸å½±å“åŠ è½½ç»Ÿè®¡ï¼‰")
            
            if len(unexpected_keys) > 0:
                self.logger.info(f"  - æ¨¡å‹æ–°å¢å‚æ•°: {len(unexpected_keys)} ä¸ªï¼ˆå°†éšæœºåˆå§‹åŒ–ï¼‰")
            
        except Exception as e:
            self.logger.error(f"âœ— åŠ è½½é¢„è®­ç»ƒæƒé‡å¤±è´¥: {e}")
            self.logger.info("å°†ä½¿ç”¨éšæœºåˆå§‹åŒ–æƒé‡")
    
    def create_criterion(self):
        """åˆ›å»ºæŸå¤±å‡½æ•°"""
        from src.zoo.rtdetr.matcher import HungarianMatcher
        from src.zoo.rtdetr.rtdetrv2_criterion import RTDETRCriterionv2
        
        # åˆ›å»ºmatcher
        matcher = HungarianMatcher(
            weight_dict={'cost_class': 2, 'cost_bbox': 5, 'cost_giou': 2},
            use_focal_loss=False,
            alpha=0.25,
            gamma=2.0
        )
        
        # ä¸»æŸå¤±æƒé‡
        main_weight_dict = {
            'loss_vfl': 1.0,
            'loss_bbox': 5.0,
            'loss_giou': 2.0
        }
        
        # è¾…åŠ©æŸå¤±æƒé‡ï¼ˆdecoderçš„å‰N-1å±‚ï¼‰
        num_decoder_layers = self.config['model']['num_decoder_layers']
        aux_weight_dict = {}
        for i in range(num_decoder_layers - 1):  # å‰N-1å±‚
            aux_weight_dict[f'loss_vfl_aux_{i}'] = 1.0
            aux_weight_dict[f'loss_bbox_aux_{i}'] = 5.0
            aux_weight_dict[f'loss_giou_aux_{i}'] = 2.0
        
        # Encoderè¾…åŠ©æŸå¤±
        aux_weight_dict['loss_vfl_enc_0'] = 1.0
        aux_weight_dict['loss_bbox_enc_0'] = 5.0
        aux_weight_dict['loss_giou_enc_0'] = 2.0
        
        # Denoisingè¾…åŠ©æŸå¤±
        num_denoising_layers = num_decoder_layers  # å’Œdecoderå±‚æ•°ä¸€è‡´
        for i in range(num_denoising_layers):
            aux_weight_dict[f'loss_vfl_dn_{i}'] = 1.0
            aux_weight_dict[f'loss_bbox_dn_{i}'] = 5.0
            aux_weight_dict[f'loss_giou_dn_{i}'] = 2.0
        
        # åˆå¹¶æ‰€æœ‰æƒé‡
        weight_dict = {**main_weight_dict, **aux_weight_dict}
        
        # åˆ›å»ºcriterionï¼ˆä¸MoE RT-DETRä¿æŒä¸€è‡´ï¼‰
        criterion = RTDETRCriterionv2(
            matcher=matcher,
            weight_dict=weight_dict,
            losses=['vfl', 'boxes'],
            alpha=0.75,
            gamma=2.0,
            num_classes=8,  # 8ç±»ï¼šCar, Truck, Van, Bus, Pedestrian, Cyclist, Motorcyclist, Trafficcone
            boxes_weight_format=None,
            share_matched_indices=False
        )
        
        return criterion
    
    def create_datasets(self):
        """åˆ›å»ºæ•°æ®é›†"""
        from src.data.dataloader import BaseCollateFunction
        
        # åˆ›å»ºcollate_fnç±»
        class CustomCollateFunction(BaseCollateFunction):
            def __call__(self, batch):
                images, targets = zip(*batch)
                
                # ---------------------------------------------------------------------
                # æ ¸å¿ƒä¿®æ”¹åŒºåŸŸï¼šåŠ¨æ€ Padding + Stride 32 å¯¹é½
                # ---------------------------------------------------------------------
                if isinstance(images[0], (np.ndarray, torch.Tensor)):
                    # 1. ç»Ÿä¸€æ ¼å¼ï¼šå°† numpy è½¬ä¸º tensor (å¦‚æœéœ€è¦)
                    if isinstance(images[0], np.ndarray):
                        processed_images = [
                            torch.from_numpy(img).permute(2, 0, 1).float() / 255.0 
                            for img in images
                        ]
                    else:
                        # Already tensors
                        processed_images = list(images)

                    # 2. è·å–å½“å‰ Batch ä¸­æ‰€æœ‰å›¾ç‰‡çš„å°ºå¯¸ (H, W)
                    sizes = [img.shape[-2:] for img in processed_images]
                    
                    # 3. è®¡ç®—æœ€å¤§å°ºå¯¸ï¼Œå¹¶å¼ºåˆ¶å‘ä¸Šå¯¹é½åˆ° 32 çš„å€æ•°
                    # RT-DETR/ResNet çš„æœ€å¤§ä¸‹é‡‡æ ·ç‡æ˜¯ 32ï¼Œè¾“å…¥å¿…é¡»æ˜¯ 32 çš„å€æ•°ï¼Œå¦åˆ™ FPN ä¸Šé‡‡æ ·ä¼šé”™ä½
                    stride = 32
                    max_h_raw = max(s[0] for s in sizes)
                    max_w_raw = max(s[1] for s in sizes)
                    
                    # å‘ä¸Šå–æ•´å…¬å¼: (x + stride - 1) // stride * stride
                    max_h = (max_h_raw + stride - 1) // stride * stride
                    max_w = (max_w_raw + stride - 1) // stride * stride
                    
                    # 4. åˆ›å»ºå…¨é›¶ç”»å¸ƒ (Batch, C, MaxH, MaxW)
                    # RT-DETR expects nested tensors or padded batch
                    batch_images = torch.zeros(len(processed_images), 3, max_h, max_w)
                    
                    # 5. å¡«å……æ•°æ® (å·¦ä¸Šè§’å¯¹é½)
                    for i, img in enumerate(processed_images):
                        h, w = img.shape[-2:]
                        batch_images[i, :, :h, :w] = img
                        
                    images = batch_images
                    
                else:
                     # Fallback for other types
                    images = torch.stack(images, 0)
                
                return images, list(targets)
        
        # ç›´æ¥ä½¿ç”¨DAIRV2XDetectionç±»ï¼ˆç›´æ¥ä½¿ç”¨é…ç½®æ–‡ä»¶ä¸­çš„data.data_rootï¼‰
        data_root = self.config['data']['data_root']
        target_size = 640
        
        # è·å–æ•°æ®å¢å¼ºé…ç½®
        aug_config = self.config.get('data_augmentation', {})
        # é»˜è®¤ä½¿ç”¨Unified Task-Adapted Augmentationçš„å‚æ•°
        aug_brightness = aug_config.get('brightness', 0.15)
        aug_contrast = aug_config.get('contrast', 0.15)
        aug_saturation = aug_config.get('saturation', 0.1)
        aug_hue = aug_config.get('hue', 0.05)
        aug_color_jitter_prob = aug_config.get('color_jitter_prob', 0.0)
        aug_crop_min = aug_config.get('crop_min', 0.3)
        aug_crop_max = aug_config.get('crop_max', 1.0)
        aug_flip_prob = aug_config.get('flip_prob', 0.5)
        
        train_dataset = DAIRV2XDetection(
            data_root=data_root,
            split='train',
            target_size=target_size,
            aug_brightness=aug_brightness,
            aug_contrast=aug_contrast,
            aug_saturation=aug_saturation,
            aug_hue=aug_hue,
            aug_color_jitter_prob=aug_color_jitter_prob,
            aug_crop_min=aug_crop_min,
            aug_crop_max=aug_crop_max,
            aug_flip_prob=aug_flip_prob
        )
        
        val_dataset = DAIRV2XDetection(
            data_root=data_root,
            split='val',
            target_size=target_size,
            aug_brightness=0.0,
            aug_contrast=0.0,
            aug_saturation=0.0,
            aug_hue=0.0,
            aug_color_jitter_prob=0.0
        )
        
        collate_fn = CustomCollateFunction()
        
        # num_workersåœ¨miscé…ç½®ä¸­
        num_workers = self.config.get('misc', {}).get('num_workers', 16)
        pin_memory = self.config.get('misc', {}).get('pin_memory', True)
        
        train_loader = DataLoader(
            train_dataset,
            batch_size=self.config['training']['batch_size'],
            shuffle=True,
            num_workers=num_workers,
            collate_fn=collate_fn,
            pin_memory=pin_memory,
            persistent_workers=True if num_workers > 0 else False,
            prefetch_factor=2 if num_workers > 0 else None
        )
        val_loader = DataLoader(
            val_dataset,
            batch_size=self.config['training']['batch_size'],
            shuffle=False,
            num_workers=num_workers,
            collate_fn=collate_fn,
            pin_memory=pin_memory,
            persistent_workers=True if num_workers > 0 else False,
            prefetch_factor=2 if num_workers > 0 else None
        )
        
        return train_loader, val_loader
    
    def create_optimizer(self):
        """åˆ›å»ºä¼˜åŒ–å™¨ï¼ˆä½¿ç”¨åˆ†ç»„å­¦ä¹ ç‡ï¼‰"""
        # è·å–é…ç½®ä¸­çš„å­¦ä¹ ç‡ï¼Œç¡®ä¿æ˜¯æµ®ç‚¹æ•°ç±»å‹ï¼ˆç›´æ¥ä½¿ç”¨é…ç½®æ–‡ä»¶å­—æ®µåï¼‰
        new_lr = float(self.config['training']['new_lr'])
        pretrained_lr = float(self.config['training']['pretrained_lr'])
        weight_decay = float(self.config['training'].get('weight_decay', 0.0001))
        
        # åˆ†ç»„å‚æ•°
        param_groups = []
        
        # å®šä¹‰æ–°å¢ç»“æ„çš„å…³é”®è¯ï¼ˆrt-detræ²¡æœ‰MoE/DSETç»“æ„ï¼Œæ‰€ä»¥ä¸ºç©ºï¼‰
        new_structure_keywords = []
        
        # 1. é¢„è®­ç»ƒå‚æ•°ç»„ï¼ˆbackboneã€encoderã€decoderçš„æ ‡å‡†å±‚ï¼Œæ’é™¤normå±‚å’Œæ–°å¢ç»“æ„ï¼‰
        pretrained_params = []
        pretrained_names = []
        for name, param in self.model.named_parameters():
            if param.requires_grad:
                # åˆ¤æ–­æ˜¯å¦ä¸ºé¢„è®­ç»ƒéƒ¨åˆ†ï¼ˆbackboneã€encoderã€decoderï¼‰
                is_pretrained = any(part in name for part in ['backbone', 'encoder', 'decoder'])
                # æ’é™¤normå±‚
                is_norm = any(norm in name for norm in ['norm', 'bn', 'gn', 'ln'])
                # æ’é™¤æ–°å¢ç»“æ„ï¼ˆå³ä½¿å®ƒä»¬åœ¨encoder/decoderä¸­ï¼‰
                is_new_structure = any(keyword in name.lower() for keyword in new_structure_keywords)
                
                if is_pretrained and not is_norm and not is_new_structure:
                    pretrained_params.append(param)
                    pretrained_names.append(name)
        
        if pretrained_params:
            param_groups.append({
                'params': pretrained_params,
                'lr': pretrained_lr,
                'weight_decay': weight_decay
            })
            self.logger.info(f"âœ“ é¢„è®­ç»ƒå‚æ•°ç»„: {len(pretrained_params)} ä¸ªå‚æ•°, lr={pretrained_lr}")
        
        # 2. Normå±‚å‚æ•°ï¼ˆæ— weight decayï¼‰
        norm_params = []
        norm_names = []
        for name, param in self.model.named_parameters():
            if param.requires_grad and any(norm in name for norm in ['norm', 'bn', 'gn', 'ln']):
                norm_params.append(param)
                norm_names.append(name)
        
        if norm_params:
            param_groups.append({
                'params': norm_params,
                'lr': new_lr,
                'weight_decay': 0.0  # Normå±‚ä¸ä½¿ç”¨weight decay
            })
            self.logger.info(f"âœ“ Normå±‚å‚æ•°ç»„: {len(norm_params)} ä¸ªå‚æ•°, lr={new_lr}, wd=0")
        
        # 3. æ–°å‚æ•°ç»„ï¼ˆMoEå±‚ã€DSETå±‚ç­‰æ–°å¢ç»“æ„ï¼Œå³ä½¿å®ƒä»¬åœ¨encoder/decoderä¸­ï¼‰
        new_params = []
        new_names = []
        processed_params = set(id(p) for p in pretrained_params + norm_params)
        
        for name, param in self.model.named_parameters():
            if param.requires_grad and id(param) not in processed_params:
                new_params.append(param)
                new_names.append(name)
        
        if new_params:
            param_groups.append({
                'params': new_params,
                'lr': new_lr,
                'weight_decay': weight_decay
            })
            self.logger.info(f"âœ“ æ–°å‚æ•°ç»„: {len(new_params)} ä¸ªå‚æ•°, lr={new_lr}")
        
        optimizer = torch.optim.AdamW(
            param_groups,
            betas=(0.9, 0.999)
        )
        
        return optimizer
    
    def create_scheduler(self):
        """åˆ›å»ºå­¦ä¹ ç‡è°ƒåº¦å™¨"""
        scheduler_type = self.config['training'].get('scheduler', 'cosine')
        
        if scheduler_type == 'cosine':
            eta_min = float(self.config['training'].get('eta_min', 1e-7))
            scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(
                self.optimizer,
                T_max=self.config['training']['epochs'],
                eta_min=eta_min
            )
            self.logger.info(f"âœ“ ä½¿ç”¨CosineAnnealingLRè°ƒåº¦å™¨ (eta_min={eta_min})")
        else:
            # MultiStepLR
            milestones = self.config['training'].get('milestones', [60, 80])
            gamma = float(self.config['training'].get('gamma', 0.1))
            scheduler = torch.optim.lr_scheduler.MultiStepLR(
                self.optimizer,
                milestones=milestones,
                gamma=gamma
            )
            self.logger.info(f"âœ“ ä½¿ç”¨MultiStepLRè°ƒåº¦å™¨ (milestones={milestones})")
        
        return scheduler
    
    def create_warmup_scheduler(self):
        """åˆ›å»ºå­¦ä¹ ç‡é¢„çƒ­è°ƒåº¦å™¨ï¼ˆä¸MoE RT-DETRä¿æŒä¸€è‡´ï¼‰"""
        warmup_epochs = self.config['training'].get('warmup_epochs', 3)
        
        # ç¡®ä¿warmup_end_lræ˜¯æµ®ç‚¹æ•°
        warmup_end_lr = float(self.config['training']['new_lr'])
        warmup_scheduler = WarmupLR(
            optimizer=self.optimizer,
            warmup_epochs=warmup_epochs,
            warmup_start_lr=1e-7,
            warmup_end_lr=warmup_end_lr
        )
        
        self.logger.info(f"âœ“ å­¦ä¹ ç‡é¢„çƒ­: {warmup_epochs} è½®")
        return warmup_scheduler
    
    def _save_latest_checkpoint(self):
        """ä¿å­˜æœ€æ–°æ£€æŸ¥ç‚¹ç”¨äºæ–­ç‚¹ç»­è®­ï¼ˆä¸moe-rtdeträ¸€è‡´ï¼‰"""
        try:
            checkpoint = {
                'epoch': self.last_epoch,
                'model_state_dict': self.model.state_dict(),
                'optimizer_state_dict': self.optimizer.state_dict(),
                'scheduler_state_dict': self.scheduler.state_dict(),
                'config': self.config,
                'best_loss': self.best_loss,
                'best_map': self.best_map,
                'best_metric': getattr(self, 'best_metric', 0.0),
                'global_step': self.global_step
            }
            
            # æ·»åŠ å¯é€‰ç»„ä»¶çŠ¶æ€
            if hasattr(self, 'warmup_scheduler') and self.warmup_scheduler:
                checkpoint['warmup_scheduler_state_dict'] = self.warmup_scheduler.state_dict()
            
            if hasattr(self, 'ema') and self.ema:
                checkpoint['ema_state_dict'] = self.ema.state_dict()
            
            if hasattr(self, 'scaler') and self.scaler:
                checkpoint['scaler_state_dict'] = self.scaler.state_dict()
            
            if hasattr(self, 'visualizer') and self.visualizer:
                checkpoint['visualizer_state_dict'] = self.visualizer.state_dict()
            
            if hasattr(self, 'early_stopping') and self.early_stopping:
                checkpoint['early_stopping_state'] = self.early_stopping.state_dict()
            
            # ä¿å­˜åˆ° log_dir
            latest_path = self.log_dir / 'latest_checkpoint.pth'
            torch.save(checkpoint, latest_path)
            self.logger.info(f"ğŸ’¾ ä¿å­˜æœ€æ–°æ£€æŸ¥ç‚¹: {latest_path}")
            
        except Exception as e:
            self.logger.warning(f"ä¿å­˜æœ€æ–°æ£€æŸ¥ç‚¹å¤±è´¥: {e}")
    
    def _save_best_checkpoint(self, epoch):
        """ä¿å­˜æœ€ä½³æ¨¡å‹æ£€æŸ¥ç‚¹ï¼ˆåŸºäºmAPï¼‰"""
        try:
            # ä¿å­˜å½“å‰EMAæ¨¡å‹çš„state_dictï¼ˆç”¨äºæ¨ç†æ—¶ç¡®ä¿ä½¿ç”¨best_modelçš„å‚æ•°ï¼‰
            best_ema_state = None
            if hasattr(self, 'ema') and self.ema:
                best_ema_state = self.ema.state_dict()
            
            checkpoint = {
                'epoch': epoch,
                'model_state_dict': self.model.state_dict(),
                'optimizer_state_dict': self.optimizer.state_dict(),
                'scheduler_state_dict': self.scheduler.state_dict(),
                'config': self.config,
                'best_loss': self.best_loss,
                'best_map': self.best_map,
                'global_step': self.global_step
            }
            
            # æ·»åŠ å¯é€‰ç»„ä»¶çŠ¶æ€
            if hasattr(self, 'warmup_scheduler') and self.warmup_scheduler:
                checkpoint['warmup_scheduler_state_dict'] = self.warmup_scheduler.state_dict()
            
            if hasattr(self, 'ema') and self.ema:
                checkpoint['ema_state_dict'] = best_ema_state
            
            if hasattr(self, 'scaler') and self.scaler:
                checkpoint['scaler_state_dict'] = self.scaler.state_dict()
            
            if hasattr(self, 'visualizer') and self.visualizer:
                checkpoint['visualizer_state_dict'] = self.visualizer.state_dict()
            
            if hasattr(self, 'early_stopping') and self.early_stopping:
                checkpoint['early_stopping_state'] = self.early_stopping.state_dict()
            
            # ä¿å­˜åˆ° log_dir
            best_path = self.log_dir / 'best_model.pth'
            torch.save(checkpoint, best_path)
            self.logger.info(f"ğŸ’¾ ä¿å­˜æœ€ä½³æ¨¡å‹: {best_path}")
            
            # åœ¨best_modelæ—¶é‡æ–°è®¡ç®—å¹¶æ‰“å°è¯¦ç»†çš„æ¯ç±»mAPï¼ˆ8ç±»ï¼‰
            self._print_best_model_per_category_map()
            
        except Exception as e:
            self.logger.warning(f"ä¿å­˜æœ€æ–°æ£€æŸ¥ç‚¹å¤±è´¥: {e}")
    
    def start_training(self, resume_checkpoint=None):
        """å¼€å§‹è®­ç»ƒ"""
        # ä¿å­˜æ¢å¤æ£€æŸ¥ç‚¹è·¯å¾„ï¼ˆç”¨äºæ—¥å¿—è®¾ç½®ï¼‰
        self._resume_checkpoint_path = resume_checkpoint
        
        # é‡æ–°è®¾ç½®æ—¥å¿—ï¼ˆç°åœ¨å¯ä»¥æ­£ç¡®å¤„ç†æ¢å¤è®­ç»ƒçš„æƒ…å†µï¼‰
        self.setup_logging()
        
        self.logger.info("=" * 80)
        self.logger.info("ğŸš€ å¼€å§‹RT-DETRè®­ç»ƒ")
        self.logger.info("=" * 80)
        
        # æ˜¾ç¤ºå…³é”®é…ç½®ä¿¡æ¯
        self.logger.info("ğŸ“ è®­ç»ƒé…ç½®:")
        self.logger.info(f"  æ•°æ®é›†è·¯å¾„: {self.config['data']['data_root']}")
        self.logger.info(f"  è®­ç»ƒè½®æ•°: {self.config['training']['epochs']}")
        self.logger.info(f"  æ‰¹æ¬¡å¤§å°: {self.config['training']['batch_size']}")
        self.logger.info(f"  æ–°ç»„ä»¶å­¦ä¹ ç‡: {self.config['training']['new_lr']}")
        self.logger.info(f"  é¢„è®­ç»ƒç»„ä»¶å­¦ä¹ ç‡: {self.config['training']['pretrained_lr']}")
        self.logger.info(f"  è¾“å‡ºç›®å½•: {self.log_dir}")
        pretrained_weights_display = self.pretrained_weights or self.config.get('model', {}).get('pretrained_weights', None)
        if pretrained_weights_display:
            self.logger.info(f"  é¢„è®­ç»ƒæƒé‡: {pretrained_weights_display}")
        if resume_checkpoint:
            self.logger.info(f"  æ¢å¤æ£€æŸ¥ç‚¹: {resume_checkpoint}")
        self.logger.info("=" * 80)
        
        # 1. åˆ›å»ºæ¨¡å‹
        self.model = self.create_model()
        
        # 2. åŠ è½½é¢„è®­ç»ƒæƒé‡ï¼ˆå¦‚æœæä¾›ï¼‰
        pretrained_weights = self.pretrained_weights or self.config.get('model', {}).get('pretrained_weights', None)
        if pretrained_weights and not resume_checkpoint:
            self.logger.info(f"ğŸ”— åŠ è½½é¢„è®­ç»ƒæƒé‡: {pretrained_weights}")
            self.load_pretrained_weights(self.model, pretrained_weights)
        else:
            self.logger.info("â„¹ï¸  ä½¿ç”¨éšæœºåˆå§‹åŒ–æƒé‡")
        
        # å°†æ¨¡å‹ç§»åˆ°è®¾å¤‡
        self.model = self.model.to(self.device)
        
        # å¯ç”¨GPUä¼˜åŒ–è®¾ç½®
        if torch.cuda.is_available():
            # å¯ç”¨cudnn benchmarkä»¥åŠ é€Ÿå·ç§¯æ“ä½œï¼ˆè¾“å…¥å°ºå¯¸å›ºå®šæ—¶ï¼‰
            torch.backends.cudnn.benchmark = True
            # å¯ç”¨TensorFloat-32ï¼ˆRTX 5090æ”¯æŒï¼Œå¯åŠ é€ŸæŸäº›æ“ä½œï¼‰
            torch.backends.cuda.matmul.allow_tf32 = True
            torch.backends.cudnn.allow_tf32 = True
            self.logger.info("âœ“ å·²å¯ç”¨GPUä¼˜åŒ–: cudnn.benchmark=True, TF32=True")
        
        # 3. åˆ›å»ºå…¶ä»–ç»„ä»¶
        self.criterion = self.create_criterion()
        self.train_dataloader, self.val_dataloader = self.create_datasets()
        self.optimizer = self.create_optimizer()
        self.scheduler = self.create_scheduler()
        self.warmup_scheduler = self.create_warmup_scheduler()
        
        # 4. åˆ›å»ºEMAå’Œæ¢¯åº¦ç¼©æ”¾å™¨
        ema_decay = self.config['training'].get('ema_decay', 0.9999)
        self.ema = ModelEMA(self.model, decay=ema_decay)
        self.scaler = torch.amp.GradScaler('cuda')
        self.logger.info(f"âœ“ EMA decay={ema_decay}, æ··åˆç²¾åº¦è®­ç»ƒå·²å¯ç”¨")
        
        # 5. åˆ›å»ºå¯è§†åŒ–å™¨ï¼ˆä½¿ç”¨log_dirï¼‰
        self.visualizer = TrainingVisualizer(
            log_dir=self.log_dir,
            model_type='standard',
            experiment_name=self.experiment_name
        )
        
        # 5.5 åˆ›å»ºæ¨ç†åå¤„ç†å™¨
        self.postprocessor = DetDETRPostProcessor(
            num_classes=8,  # 8ç±»ï¼šCar, Truck, Van, Bus, Pedestrian, Cyclist, Motorcyclist, Trafficcone
            use_focal_loss=True,
            num_top_queries=300,
            box_process_format=BoxProcessFormat.RESIZE
        )
        
        # åˆ›å»ºæ¨ç†è¾“å‡ºç›®å½•
        self.inference_output_dir = self.log_dir / 'inference_samples'
        self.inference_output_dir.mkdir(exist_ok=True)
        self.logger.info(f"âœ“ æ¨ç†æ ·æœ¬è¾“å‡ºç›®å½•: {self.inference_output_dir}")
        
        # 6. è®¾ç½®è®­ç»ƒå±æ€§
        self.last_epoch = -1
        self.best_loss = float('inf')
        self.best_map = 0.0  # è®°å½•æœ€ä½³mAP
        self.global_step = 0  # å…¨å±€æ­¥æ•°ï¼ˆä¸moe-rtdetr/dsetä¿æŒä¸€è‡´ï¼‰
        
        # 6.5 åˆå§‹åŒ–Early Stopping
        self.early_stopping = self._create_early_stopping()
        
        # 7. è®¾ç½®æ¢¯åº¦è£å‰ªå‚æ•°
        self.clip_max_norm = self.config['training'].get('clip_max_norm', 10.0)
        self.logger.info(f"âœ“ æ¢¯åº¦è£å‰ª: max_norm={self.clip_max_norm}")
        
        # 8. æ¢å¤è®­ç»ƒï¼ˆå¦‚æœæä¾›checkpointï¼‰
        if resume_checkpoint:
            self.logger.info(f"ğŸ“¦ ä»æ£€æŸ¥ç‚¹æ¢å¤è®­ç»ƒ: {resume_checkpoint}")
            checkpoint = torch.load(resume_checkpoint, map_location=self.device, weights_only=False)
            
            # æ¢å¤æ¨¡å‹å’Œä¼˜åŒ–å™¨çŠ¶æ€
            self.model.load_state_dict(checkpoint['model_state_dict'])
            self.optimizer.load_state_dict(checkpoint['optimizer_state_dict'])
            self.scheduler.load_state_dict(checkpoint['scheduler_state_dict'])
            
            # æ¢å¤warmupè°ƒåº¦å™¨
            if 'warmup_scheduler_state_dict' in checkpoint and self.warmup_scheduler:
                self.warmup_scheduler.load_state_dict(checkpoint['warmup_scheduler_state_dict'])
            
            # æ¢å¤EMA
            if 'ema_state_dict' in checkpoint and self.ema:
                self.ema.load_state_dict(checkpoint['ema_state_dict'])
            
            # æ¢å¤å¯è§†åŒ–å™¨å†å²è®°å½•
            if 'visualizer_state_dict' in checkpoint and self.visualizer:
                self.visualizer.load_state_dict(checkpoint['visualizer_state_dict'])
                self.logger.info(f"âœ“ å·²æ¢å¤è®­ç»ƒå†å²è®°å½•")
            
            # æ¢å¤early stoppingçŠ¶æ€
            if 'early_stopping_state' in checkpoint and self.early_stopping:
                self.early_stopping.load_state_dict(checkpoint['early_stopping_state'])
                self.logger.info(f"âœ“ å·²æ¢å¤Early StoppingçŠ¶æ€")
            
            # æ¢å¤epochè®¡æ•°å’Œæœ€ä½³æŒ‡æ ‡
            self.last_epoch = checkpoint.get('epoch', -1)
            self.best_loss = checkpoint.get('best_loss', float('inf'))
            self.best_map = checkpoint.get('best_map', 0.0)
            self.global_step = checkpoint.get('global_step', 0)
            self.logger.info(f'âœ“ ä»epoch {self.last_epoch + 1}æ¢å¤è®­ç»ƒ')
            
            # æ˜¾ç¤ºæ¢å¤çš„è®­ç»ƒä¿¡æ¯
            if 'best_metric' in checkpoint:
                self.logger.info(f"âœ“ å†å²æœ€ä½³æŒ‡æ ‡: {checkpoint['best_metric']}")
            self.logger.info(f"âœ“ æœ€ä½³loss: {self.best_loss:.4f}, æœ€ä½³mAP: {self.best_map:.4f}")
            if 'train_loss' in checkpoint:
                self.logger.info(f"âœ“ ä¸Šæ¬¡è®­ç»ƒæŸå¤±: {checkpoint['train_loss']:.4f}")
            if 'val_loss' in checkpoint:
                self.logger.info(f"âœ“ ä¸Šæ¬¡éªŒè¯æŸå¤±: {checkpoint['val_loss']:.4f}")
        
        # 9. æ‰“å°è®­ç»ƒé…ç½®æ‘˜è¦
        self.logger.info("=" * 80)
        self.logger.info("è®­ç»ƒé…ç½®æ‘˜è¦:")
        self.logger.info(f"  - è®­ç»ƒè½®æ•°: {self.config['training']['epochs']}")
        self.logger.info(f"  - æ‰¹æ¬¡å¤§å°: {self.config['training']['batch_size']}")
        self.logger.info(f"  - æ–°ç»„ä»¶å­¦ä¹ ç‡: {self.config['training']['new_lr']}")
        self.logger.info(f"  - é¢„è®­ç»ƒç»„ä»¶å­¦ä¹ ç‡: {self.config['training']['pretrained_lr']}")
        self.logger.info(f"  - Weight decay: {self.config['training']['weight_decay']}")
        self.logger.info(f"  - Warmupè½®æ•°: {self.config['training'].get('warmup_epochs', 3)}")
        self.logger.info(f"  - æ¢¯åº¦è£å‰ª: {self.clip_max_norm}")
        self.logger.info(f"  - è®¾å¤‡: {self.device}")
        self.logger.info("=" * 80)
        
        self._custom_training_loop()
        
        # ä¿å­˜æœ€ç»ˆçš„ latest_checkpointï¼ˆç”¨äºæ–­ç‚¹ç»­è®­ï¼‰
        self._save_latest_checkpoint()
    
    def _create_early_stopping(self) -> Optional[EarlyStopping]:
        """åˆ›å»ºEarly Stoppingã€‚"""
        training_config = self.config.get('training', {})
        patience = training_config.get('early_stopping_patience', None)
        
        if patience is None or patience <= 0:
            self.logger.info("â±ï¸  Early Stopping: æœªå¯ç”¨")
            return None
        
        metric_name = training_config.get('early_stopping_metric', 'mAP_0.5_0.95')
        mode = 'max' if 'mAP' in metric_name or 'AP' in metric_name else 'min'
        
        self.logger.info(f"â±ï¸  Early Stopping: å¯ç”¨ (patience={patience}, metric={metric_name}, mode={mode})")
        
        return EarlyStopping(
            patience=patience,
            mode=mode,
            min_delta=0.0001,
            metric_name=metric_name,
            logger=self.logger
        )
    
    def _custom_training_loop(self):
        """è‡ªå®šä¹‰è®­ç»ƒå¾ªç¯"""
        epochs = self.config['training']['epochs']
        self.logger.info(f"å¼€å§‹è®­ç»ƒ {epochs} epochs")
        
        for epoch in range(self.last_epoch + 1, epochs):
            self.last_epoch = epoch
            
            # è®­ç»ƒä¸€ä¸ªepoch
            train_metrics = self._train_epoch()
            
            # éªŒè¯
            val_metrics = self._validate_epoch()
            
            # å­¦ä¹ ç‡è°ƒåº¦ï¼ˆä¸moe-rtdetr/dsetä¿æŒä¸€è‡´ï¼‰
            if self.last_epoch < self.warmup_scheduler.warmup_epochs:
                self.warmup_scheduler.step()
            else:
                self.scheduler.step()
            
            # è¾“å‡ºæ—¥å¿—ï¼ˆä¸è¾“å‡ºmAPï¼Œåªåœ¨best_modelæ—¶è¾“å‡ºï¼‰
            self.logger.info(f"Epoch {epoch}:")
            self.logger.info(f"  è®­ç»ƒæŸå¤±: {train_metrics.get('total_loss', 0.0):.2f} | éªŒè¯æŸå¤±: {val_metrics.get('total_loss', 0.0):.2f}")
            # å‰30ä¸ªepochä¸è¿›è¡ŒcocoEvalè¯„ä¼°ï¼Œè·³è¿‡é¢„æµ‹/ç›®æ ‡ç»Ÿè®¡
            if epoch >= 30:
                self.logger.info(f"  é¢„æµ‹/ç›®æ ‡: {val_metrics['num_predictions']}/{val_metrics['num_targets']}")
            else:
                self.logger.info(f"  (å‰30ä¸ªepochä»…è®¡ç®—lossï¼Œè·³è¿‡mAPè¯„ä¼°)")
            
            # è®°å½•åˆ°å¯è§†åŒ–å™¨
            current_lr = self.optimizer.param_groups[0]['lr']
            self.visualizer.record(
                epoch=epoch,
                train_loss=train_metrics.get('total_loss', 0.0),
                val_loss=val_metrics.get('total_loss', 0.0),
                mAP_0_5=val_metrics.get('mAP_0.5', 0.0),
                mAP_0_75=val_metrics.get('mAP_0.75', 0.0),
                mAP_0_5_0_95=val_metrics.get('mAP_0.5_0.95', 0.0),
                learning_rate=current_lr
            )
            
            # ä¿å­˜æ£€æŸ¥ç‚¹ - åŒæ—¶è€ƒè™‘losså’ŒmAP
            is_best_loss = val_metrics.get('total_loss', float('inf')) < self.best_loss
            is_best_map = val_metrics.get('mAP_0.5_0.95', 0.0) > self.best_map
            
            if is_best_loss:
                self.best_loss = val_metrics.get('total_loss', float('inf'))
                self.logger.info(f"  ğŸ‰ æ–°çš„æœ€ä½³éªŒè¯æŸå¤±: {self.best_loss:.2f}")
            
            if is_best_map:
                self.best_map = val_metrics.get('mAP_0.5_0.95', 0.0)
                self.logger.info(f"  ğŸ‰ æ–°çš„æœ€ä½³mAP: {self.best_map:.4f}")
                # ä¿å­˜æœ€ä½³æ¨¡å‹ï¼ˆåŸºäºmAPï¼‰
                self._save_best_checkpoint(epoch)
            
            # Early Stoppingæ£€æŸ¥ï¼ˆå‰30ä¸ªepochä¸æ£€æŸ¥mAPç›¸å…³çš„æŒ‡æ ‡ï¼‰
            if self.early_stopping:
                # è·å–è¦ç›‘æ§çš„æŒ‡æ ‡å€¼
                metric_name = self.early_stopping.metric_name
                # å¦‚æœç›‘æ§çš„æ˜¯mAPç›¸å…³æŒ‡æ ‡ä¸”epoch < 30ï¼Œè·³è¿‡Early Stoppingæ£€æŸ¥
                is_map_metric = any(x in metric_name for x in ['mAP', 'AP'])
                if is_map_metric and epoch < 30:
                    # å‰30ä¸ªepochä¸è¿›è¡ŒmAPè¯„ä¼°ï¼Œè·³è¿‡Early Stoppingæ£€æŸ¥
                    pass
                else:
                    if 'mAP_0.5_0.95' in metric_name or 'mAP_0.5:0.95' in metric_name:
                        metric_value = val_metrics.get('mAP_0.5_0.95', 0.0)
                    elif 'mAP_0.5' in metric_name:
                        metric_value = val_metrics.get('mAP_0.5', 0.0)
                    elif 'mAP_0.75' in metric_name:
                        metric_value = val_metrics.get('mAP_0.75', 0.0)
                    elif 'loss' in metric_name.lower():
                        metric_value = val_metrics.get('total_loss', float('inf'))
                    else:
                        metric_value = val_metrics.get('mAP_0.5_0.95', 0.0)  # é»˜è®¤
                    
                    if self.early_stopping(metric_value, epoch):
                        self.logger.info(f"Early Stoppingåœ¨epoch {epoch}è§¦å‘ï¼Œåœæ­¢è®­ç»ƒ")
                        break
            
            # æ¯ä¸ªepochéƒ½ä¿å­˜latestç”¨äºæ–­ç‚¹ç»­è®­
            self._save_latest_checkpoint()
            
            # ç»˜åˆ¶è®­ç»ƒæ›²çº¿ï¼ˆæ¯ä¸ªepochéƒ½æ›´æ–°ï¼‰
            try:
                self.visualizer.plot()
            except Exception as e:
                self.logger.warning(f"ç»˜åˆ¶è®­ç»ƒæ›²çº¿å¤±è´¥: {e}")
        
        # è®­ç»ƒå®Œæˆåï¼Œç»˜åˆ¶æœ€ç»ˆçš„è®­ç»ƒæ›²çº¿å¹¶å¯¼å‡ºCSV
        self.logger.info("âœ“ è®­ç»ƒå®Œæˆï¼")
        try:
            self.visualizer.plot()
            self.visualizer.export_to_csv()
            self.logger.info(f"âœ“ è®­ç»ƒæ›²çº¿å·²ä¿å­˜åˆ°: {self.log_dir}/training_curves.png")
            self.logger.info(f"âœ“ è®­ç»ƒå†å²å·²å¯¼å‡ºåˆ°: {self.log_dir}/training_history.csv")
            self.logger.info(f"âœ“ æ‰€æœ‰è¾“å‡ºå·²ä¿å­˜åˆ°: {self.log_dir}")
        except Exception as e:
            self.logger.warning(f"ç»˜åˆ¶æœ€ç»ˆè®­ç»ƒæ›²çº¿å¤±è´¥: {e}")
        
        # è®­ç»ƒç»“æŸæ—¶ä½¿ç”¨best_modelè¾“å‡º5å¼ æ¨ç†å›¾åƒ
        self.logger.info("=" * 60)
        self.logger.info("ä½¿ç”¨best_modelç”Ÿæˆæ¨ç†ç»“æœï¼ˆ5å¼ å›¾åƒï¼‰...")
        try:
            best_model_path = self.log_dir / 'best_model.pth'
            if best_model_path.exists():
                # åŠ è½½best_modelçš„checkpoint
                checkpoint = torch.load(best_model_path, map_location=self.device, weights_only=False)
                best_ema_state = checkpoint.get('ema_state_dict', None)
                
                # ä½¿ç”¨best_modelè¿›è¡Œæ¨ç†
                self._run_inference_on_best_model(best_ema_state)
            else:
                self.logger.warning("æœªæ‰¾åˆ°best_model.pthï¼Œè·³è¿‡æ¨ç†")
        except Exception as e:
            self.logger.warning(f"è®­ç»ƒç»“æŸæ—¶æ¨ç†å¤±è´¥ï¼ˆä¸å½±å“è®­ç»ƒç»“æœï¼‰: {e}")
    
    def _run_inference_on_best_model(self, best_ema_state=None):
        """ä½¿ç”¨best_modelè¿è¡Œæ¨ç†ï¼Œè¾“å‡º5å¼ éªŒè¯å›¾åƒçš„æ¨ç†ç»“æœ
        
        Args:
            best_ema_state: best_modelçš„EMAæ¨¡å‹state_dictï¼Œå¦‚æœæä¾›åˆ™ä½¿ç”¨å®ƒè¿›è¡Œæ¨ç†
        """
        try:
            # ä¿å­˜å½“å‰EMAæ¨¡å‹çŠ¶æ€ï¼ˆæ¨ç†åæ¢å¤ï¼‰
            original_ema_state = None
            if best_ema_state is not None and hasattr(self, 'ema') and self.ema:
                original_ema_state = self.ema.state_dict()
                # åŠ è½½best_modelçš„EMAå‚æ•°
                self.ema.load_state_dict(best_ema_state)
            
            # ä»éªŒè¯æ•°æ®åŠ è½½å™¨ä¸­è·å–ä¸€ä¸ªbatchç”¨äºæ¨ç†
            inference_images, inference_targets = next(iter(self.val_dataloader))
            inference_images = inference_images.to(self.device)
            inference_targets = [{k: v.to(self.device) if isinstance(v, torch.Tensor) else v 
                                 for k, v in t.items()} for t in inference_targets]
            
            # æ‰“å°å‰5å¼ æ¨ç†ç»“æœ
            batch_size = len(inference_targets)
            num_inference_images = min(5, batch_size)
            self.logger.info(f"  ç”Ÿæˆbest_modelæ¨ç†ç»“æœï¼ˆå‰{num_inference_images}å¼ ï¼‰...")
            
            for img_idx in range(num_inference_images):
                self._inference_single_image_from_batch(
                    inference_images, inference_targets, 0, image_idx=img_idx, 
                    suffix=f"best_model_epoch_{self.last_epoch}"
                )
            
            self.logger.info(f"  âœ“ æ¨ç†ç»“æœå·²ä¿å­˜åˆ°: {self.inference_output_dir}")
            
            # æ¢å¤åŸå§‹EMAæ¨¡å‹çŠ¶æ€
            if original_ema_state is not None and hasattr(self, 'ema') and self.ema:
                self.ema.load_state_dict(original_ema_state)
                
        except Exception as e:
            # å¦‚æœæ¨ç†å¤±è´¥ï¼Œä¸å½±å“è®­ç»ƒï¼Œä½†å°è¯•æ¢å¤EMAçŠ¶æ€
            if hasattr(self, 'logger'):
                self.logger.warning(f"best_modelæ¨ç†å¤±è´¥ï¼ˆä¸å½±å“è®­ç»ƒï¼‰: {e}")
            if original_ema_state is not None and hasattr(self, 'ema') and self.ema:
                try:
                    self.ema.load_state_dict(original_ema_state)
                except:
                    pass
    
    def _inference_single_image_from_batch(self, images, targets, batch_idx, image_idx=0, suffix=None):
        """ä»batchä¸­é€‰æ‹©ä¸€å¼ å›¾ç‰‡è¿›è¡Œæ¨ç†å¹¶ä¿å­˜ç»“æœï¼ˆç›´æ¥å¤ç”¨batch_inference.pyçš„é€»è¾‘ï¼‰
        
        Args:
            images: å›¾åƒtensor
            targets: ç›®æ ‡åˆ—è¡¨
            batch_idx: batchç´¢å¼•
            image_idx: å›¾åƒåœ¨batchä¸­çš„ç´¢å¼•
            suffix: æ–‡ä»¶ååç¼€ï¼ˆé»˜è®¤ä½¿ç”¨epochï¼Œå¦‚"epoch_0"æˆ–"best_model"ï¼‰
        """
        try:
            # ä½¿ç”¨EMAæ¨¡å‹è¿›è¡Œæ¨ç†
            self.ema.module.eval()
            
            # é€‰æ‹©batchä¸­çš„ç¬¬ä¸€å¼ å›¾ç‰‡ï¼ˆæˆ–æŒ‡å®šç´¢å¼•ï¼‰
            single_image = images[image_idx:image_idx+1]  # [1, 3, H, W]
            single_target = targets[image_idx] if image_idx < len(targets) else None
            
            if single_target is None:
                return
            
            # è·å–image_idç”¨äºå‘½åå’ŒæŸ¥æ‰¾åŸå§‹å›¾åƒ
            image_id = single_target['image_id'].item() if 'image_id' in single_target else batch_idx
            
            # è·å–åŸå§‹å›¾åƒè·¯å¾„
            data_root = Path(self.config['data']['data_root'])
            orig_image_path = data_root / "image" / f"{image_id:06d}.jpg"
            
            if not orig_image_path.exists():
                return
            
            # ä½¿ç”¨batch_inference.pyä¸­çš„å‡½æ•°è¿›è¡Œæ¨ç†
            if USE_BATCH_INFERENCE_LOGIC:
                result_image = inference_from_preprocessed_image(
                    single_image,
                    self.ema.module,
                    self.postprocessor,
                    orig_image_path,
                    conf_threshold=0.3,
                    target_size=640,
                    device=str(self.device),
                    class_names=self.class_names,
                    colors=self.colors,
                    verbose=False
                )
                
                if result_image is None:
                    self.ema.module.train()
                    return
                
                # ä¿å­˜ç»“æœï¼šå›¾ç‰‡å_suffix.jpg
                image_name = orig_image_path.stem
                if suffix is None:
                    suffix = f"epoch_{self.last_epoch}"
                output_filename = f"{image_name}_{suffix}.jpg"
                output_path = self.inference_output_dir / output_filename
                cv2.imwrite(str(output_path), result_image)
            else:
                # å¤‡ç”¨é€»è¾‘
                with torch.no_grad():
                    outputs = self.ema.module(single_image)
                eval_sizes = torch.tensor([[640, 640]], device=self.device)
                results = self.postprocessor(outputs, eval_sizes=eval_sizes)
                
                if len(results) > 0:
                    result = results[0]
                    labels = result['labels'].cpu().numpy()
                    boxes = result['boxes'].cpu().numpy()
                    scores = result['scores'].cpu().numpy()
                    
                    mask = scores >= 0.3
                    labels = labels[mask]
                    boxes = boxes[mask]
                    scores = scores[mask]
                    
                    if len(labels) > 0:
                        orig_image = cv2.imread(str(orig_image_path))
                        if orig_image is not None:
                            result_image = draw_boxes(
                                orig_image.copy(), labels, boxes, scores,
                                class_names=self.class_names,
                                colors=self.colors
                            )
                            image_name = orig_image_path.stem
                            if suffix is None:
                                suffix = f"epoch_{self.last_epoch}"
                            output_filename = f"{image_name}_{suffix}.jpg"
                            output_path = self.inference_output_dir / output_filename
                            cv2.imwrite(str(output_path), result_image)
            
            # æ¢å¤è®­ç»ƒæ¨¡å¼
            self.ema.module.train()
            
        except Exception as e:
            # å¦‚æœæ¨ç†å¤±è´¥ï¼Œä¸å½±å“è®­ç»ƒ
            if hasattr(self, 'logger'):
                self.logger.debug(f"æ¨ç†å¤±è´¥ï¼ˆä¸å½±å“è®­ç»ƒï¼‰: {e}")
            if hasattr(self, 'ema') and hasattr(self.ema, 'module'):
                self.ema.module.train()
    
    def _train_epoch(self):
        """è®­ç»ƒä¸€ä¸ªepoch"""
        self.model.train()
        total_loss = 0.0
        detection_loss = 0.0
        
        for batch_idx, (images, targets) in enumerate(self.train_dataloader):
            images = images.to(self.device)
            targets = [{k: v.to(self.device) if isinstance(v, torch.Tensor) else v 
                       for k, v in t.items()} for t in targets]
            
            # å‰å‘ä¼ æ’­
            self.optimizer.zero_grad()
            
            with torch.amp.autocast('cuda'):
                outputs = self.model(images, targets)
                # ä½¿ç”¨criterionè®¡ç®—æŸå¤±
                loss_dict = self.criterion(outputs, targets)
                loss = sum(loss_dict.values())
            
            # åå‘ä¼ æ’­
            self.scaler.scale(loss).backward()
            
            # æ¢¯åº¦è£å‰ª
            self.scaler.unscale_(self.optimizer)
            torch.nn.utils.clip_grad_norm_(self.model.parameters(), max_norm=self.clip_max_norm)
            
            self.scaler.step(self.optimizer)
            self.scaler.update()
            self.ema.update(self.model)
            
            # ç»Ÿè®¡æŸå¤±
            total_loss += loss.item()
            
            # è®¡ç®—æ£€æµ‹æŸå¤±ï¼ˆä¸»è¦æŸå¤±é¡¹ï¼‰
            det_loss_val = 0.0
            if 'loss_vfl' in loss_dict:
                det_loss_val += loss_dict['loss_vfl'].item()
            if 'loss_bbox' in loss_dict:
                det_loss_val += loss_dict['loss_bbox'].item()
            if 'loss_giou' in loss_dict:
                det_loss_val += loss_dict['loss_giou'].item()
            
            detection_loss += det_loss_val
            
            # æ¯50ä¸ªbatchæ‰“å°ä¸€æ¬¡ï¼ˆå‚ç…§moe-rtdetræ ¼å¼ï¼‰
            if batch_idx % 50 == 0:
                self.logger.info(f'Epoch {self.last_epoch} | Batch {batch_idx} | '
                               f'Loss: {loss.item():.2f} (Det: {det_loss_val:.2f})')
            
            self.global_step += 1
        
        # è®¡ç®—å¹³å‡å€¼
        num_batches = len(self.train_dataloader)
        avg_loss = total_loss / num_batches
        avg_detection_loss = detection_loss / num_batches
        
        return {
            'total_loss': avg_loss,
            'detection_loss': avg_detection_loss
        }
    
    def _validate_epoch(self):
        """éªŒè¯æ¨¡å‹å¹¶è®¡ç®—mAP"""
        self.ema.module.eval()
        total_loss = 0.0
        all_predictions = []
        all_targets = []
        total_raw_predictions = 0  # åŸå§‹queryæ€»æ•°
        
        # å‰30ä¸ªepochåªè®¡ç®—lossï¼Œä¸è¿›è¡ŒcocoEvalè¯„ä¼°
        skip_coco_eval = self.last_epoch < 30
        
        with torch.no_grad():
            for batch_idx, (images, targets) in enumerate(self.val_dataloader):
                images = images.to(self.device)
                targets = [{k: v.to(self.device) if isinstance(v, torch.Tensor) else v 
                           for k, v in t.items()} for t in targets]
                
                outputs = self.ema.module(images, targets)
                
                # è®¡ç®—æŸå¤±ï¼ˆå…¼å®¹ä¸¤ç§æ–¹å¼ï¼šæ¨¡å‹å†…éƒ¨è®¡ç®—æˆ–å¤–éƒ¨è®¡ç®—ï¼‰
                if isinstance(outputs, dict) and 'total_loss' in outputs:
                    # æ¨¡å‹å†…éƒ¨å·²è®¡ç®—æŸå¤±ï¼ˆä¸moe-rtdetr/dsetä¿æŒä¸€è‡´ï¼‰
                    loss = outputs['total_loss']
                    total_loss += loss.item()
                else:
                    # ä½¿ç”¨criterionè®¡ç®—æŸå¤±ï¼ˆrt-detræ ‡å‡†æ–¹å¼ï¼‰
                    loss_dict = self.criterion(outputs, targets)
                    loss = sum(loss_dict.values())
                    total_loss += loss.item()
                
                # ç»Ÿè®¡åŸå§‹é¢„æµ‹æ•°ï¼ˆæ‰€æœ‰queriesï¼Œå…¼å®¹ä¸¤ç§é”®åï¼‰
                if 'pred_logits' in outputs:
                    total_raw_predictions += outputs['pred_logits'].shape[0] * outputs['pred_logits'].shape[1]
                elif 'class_scores' in outputs:
                    total_raw_predictions += outputs['class_scores'].shape[0] * outputs['class_scores'].shape[1]
                
                # æ”¶é›†é¢„æµ‹ç»“æœï¼ˆåªåœ¨éœ€è¦è®¡ç®—mAPæ—¶æ”¶é›†ï¼Œå‰30ä¸ªepochè·³è¿‡ï¼‰
                # å…¼å®¹ä¸¤ç§è¾“å‡ºæ ¼å¼ï¼špred_logits/pred_boxes æˆ– class_scores/bboxes
                has_predictions = (
                    ('pred_logits' in outputs and 'pred_boxes' in outputs) or
                    ('class_scores' in outputs and 'bboxes' in outputs)
                )
                if not skip_coco_eval and has_predictions:
                    self._collect_predictions(outputs, targets, batch_idx, all_predictions, all_targets)
        
        # ä¿å­˜é¢„æµ‹ç»“æœç”¨äºåç»­æ‰“å°æ¯ä¸ªç±»åˆ«mAPï¼ˆé¿å…é‡å¤è®¡ç®—ï¼‰
        self._last_val_predictions = all_predictions
        self._last_val_targets = all_targets
        
        avg_loss = total_loss / len(self.val_dataloader)
        
        # å‰30ä¸ªepochåªè¿”å›lossï¼Œä¸è®¡ç®—mAP
        if skip_coco_eval:
            return {
                'total_loss': avg_loss,
                'mAP_0.5': 0.0,
                'mAP_0.75': 0.0,
                'mAP_0.5_0.95': 0.0,
                'num_predictions': 0,
                'num_raw_predictions': 0,
                'num_targets': 0
            }
        
        # è®¡ç®—mAPï¼ˆä¸è®¡ç®—æ¯ä¸ªç±»åˆ«çš„mAPï¼Œåªåœ¨best_modelæ—¶è®¡ç®—ï¼‰
        mAP_metrics = self._compute_map_metrics(all_predictions, all_targets, print_per_category=False)
        
        return {
            'total_loss': avg_loss,
            'mAP_0.5': mAP_metrics.get('mAP_0.5', 0.0),
            'mAP_0.75': mAP_metrics.get('mAP_0.75', 0.0),
            'mAP_0.5_0.95': mAP_metrics.get('mAP_0.5_0.95', 0.0),
            'num_predictions': len(all_predictions),
            'num_raw_predictions': total_raw_predictions,  # æ‰€æœ‰åŸå§‹queriesæ•°é‡ï¼ˆä¸moe-rtdeträ¿æŒä¸€è‡´ï¼‰
            'num_targets': len(all_targets)
        }
    
    def _collect_predictions(self, outputs: Dict, targets: List[Dict], batch_idx: int,
                            all_predictions: List, all_targets: List) -> None:
        """æ”¶é›†é¢„æµ‹ç»“æœç”¨äºmAPè®¡ç®—ã€‚ä¿ç•™æ‰€æœ‰æœ‰æ•ˆé¢„æµ‹æ¡†ï¼Œä¸åštop-ké™åˆ¶ã€‚"""
        # å…¼å®¹ä¸¤ç§è¾“å‡ºæ ¼å¼ï¼špred_logits/pred_boxes æˆ– class_scores/bboxes
        if 'pred_logits' in outputs:
            pred_logits = outputs['pred_logits']  # [B, Q, C]
            pred_boxes = outputs['pred_boxes']    # [B, Q, 4]
        elif 'class_scores' in outputs:
            pred_logits = outputs['class_scores']  # [B, Q, C]
            pred_boxes = outputs['bboxes']        # [B, Q, 4]
        else:
            return  # æ²¡æœ‰æœ‰æ•ˆçš„é¢„æµ‹è¾“å‡º
        
        batch_size = pred_logits.shape[0]
        
        for i in range(batch_size):
            pred_scores_sigmoid = torch.sigmoid(pred_logits[i])  # [Q, C]
            max_scores, pred_classes = torch.max(pred_scores_sigmoid, dim=-1)  # [Q]
            
            # è¿‡æ»¤æ— æ•ˆæ¡†ï¼ˆpaddingæ¡†ï¼‰ï¼Œä¿ç•™æ‰€æœ‰æœ‰æ•ˆé¢„æµ‹æ¡†
            valid_boxes_mask = ~torch.all(pred_boxes[i] == 1.0, dim=1)
            valid_indices = torch.where(valid_boxes_mask)[0]
            if len(valid_indices) > 0:
                filtered_boxes = pred_boxes[i][valid_indices]
                filtered_classes = pred_classes[valid_indices]
                filtered_scores = max_scores[valid_indices]
                
                # è½¬æ¢ä¸ºCOCOæ ¼å¼
                if filtered_boxes.shape[0] > 0:
                    boxes_coco = torch.zeros_like(filtered_boxes)
                    if filtered_boxes.max() <= 1.0:
                        # å½’ä¸€åŒ–åæ ‡ -> åƒç´ åæ ‡
                        boxes_coco[:, 0] = (filtered_boxes[:, 0] - filtered_boxes[:, 2] / 2) * 640
                        boxes_coco[:, 1] = (filtered_boxes[:, 1] - filtered_boxes[:, 3] / 2) * 640
                        boxes_coco[:, 2] = filtered_boxes[:, 2] * 640
                        boxes_coco[:, 3] = filtered_boxes[:, 3] * 640
                    else:
                        boxes_coco = filtered_boxes.clone()
                    
                    # Clampåæ ‡
                    boxes_coco[:, 0] = torch.clamp(boxes_coco[:, 0], 0, 640)
                    boxes_coco[:, 1] = torch.clamp(boxes_coco[:, 1], 0, 640)
                    boxes_coco[:, 2] = torch.clamp(boxes_coco[:, 2], 1, 640)
                    boxes_coco[:, 3] = torch.clamp(boxes_coco[:, 3], 1, 640)
                    
                    for j in range(boxes_coco.shape[0]):
                        all_predictions.append({
                            'image_id': batch_idx * self.config['training']['batch_size'] + i,
                            'category_id': int(filtered_classes[j].item()) + 1,
                            'bbox': boxes_coco[j].cpu().numpy().tolist(),
                            'score': float(filtered_scores[j].item())
                        })
            
            # å¤„ç†çœŸå®æ ‡ç­¾ï¼ˆè¯„ä¼°æ—¶åŒ…å«iscrowdå­—æ®µï¼ŒCOCOevalä¼šè‡ªåŠ¨å¤„ç†ï¼‰
            if i < len(targets) and 'labels' in targets[i] and 'boxes' in targets[i]:
                true_labels = targets[i]['labels']
                true_boxes = targets[i]['boxes']
                
                if len(true_labels) > 0:
                    img_size = 640
                    max_val = float(true_boxes.max().item()) if true_boxes.numel() > 0 else 0.0
                    scale = img_size if max_val <= 1.0 + 1e-6 else 1.0
                    
                    true_boxes_coco = torch.zeros_like(true_boxes)
                    true_boxes_coco[:, 0] = (true_boxes[:, 0] - true_boxes[:, 2] / 2) * scale
                    true_boxes_coco[:, 1] = (true_boxes[:, 1] - true_boxes[:, 3] / 2) * scale
                    true_boxes_coco[:, 2] = true_boxes[:, 2] * scale
                    true_boxes_coco[:, 3] = true_boxes[:, 3] * scale
                    
                    true_boxes_coco[:, 0] = torch.clamp(true_boxes_coco[:, 0], 0, img_size)
                    true_boxes_coco[:, 1] = torch.clamp(true_boxes_coco[:, 1], 0, img_size)
                    true_boxes_coco[:, 2] = torch.clamp(true_boxes_coco[:, 2], 1, img_size)
                    true_boxes_coco[:, 3] = torch.clamp(true_boxes_coco[:, 3], 1, img_size)
                    
                    # è·å–iscrowdå­—æ®µï¼ˆè¯„ä¼°æ—¶å­˜åœ¨ï¼‰
                    has_iscrowd = 'iscrowd' in targets[i]
                    iscrowd_values = targets[i]['iscrowd'] if has_iscrowd else torch.zeros(len(true_labels), dtype=torch.int64)
                    
                    for j in range(len(true_labels)):
                        ann_dict = {
                            'image_id': batch_idx * self.config['training']['batch_size'] + i,
                            'category_id': int(true_labels[j].item()) + 1,
                            'bbox': true_boxes_coco[j].cpu().numpy().tolist(),
                            'area': float((true_boxes_coco[j, 2] * true_boxes_coco[j, 3]).item())
                        }
                        # è¯„ä¼°æ—¶æ·»åŠ iscrowdå­—æ®µï¼Œè®©COCOevalè‡ªåŠ¨å¤„ç†
                        if has_iscrowd:
                            ann_dict['iscrowd'] = int(iscrowd_values[j].item())
                        all_targets.append(ann_dict)
    
    def _print_best_model_per_category_map(self):
        """ä½¿ç”¨best_modelæ—¶æ‰“å°è¯¦ç»†çš„æ¯ç±»mAPï¼ˆ8ç±»ï¼‰ï¼Œé‡æ–°è®¡ç®—ä»¥è¾“å‡ºCOCOè¯¦ç»†è¯„ä¼°è¡¨æ ¼
        æ³¨æ„ï¼šåªæœ‰åœ¨epoch >= 30æ—¶æ‰ä¼šè§¦å‘best_modelï¼ˆåŸºäºmAPï¼‰ï¼Œæ­¤æ—¶æ‰ä¼šè®¡ç®—æ¯ç±»çš„mAP
        """
        try:
            # æ£€æŸ¥æ˜¯å¦æœ‰ä¿å­˜çš„é¢„æµ‹ç»“æœï¼ˆåªæœ‰ä»ç¬¬30ä¸ªepochå¼€å§‹æ‰ä¼šæœ‰ï¼‰
            if hasattr(self, '_last_val_predictions') and hasattr(self, '_last_val_targets'):
                if len(self._last_val_predictions) == 0 or len(self._last_val_targets) == 0:
                    self.logger.warning("é¢„æµ‹ç»“æœä¸ºç©ºï¼Œè·³è¿‡æ¯ç±»mAPè®¡ç®—")
                    return
                # é‡æ–°è®¡ç®—mAPï¼Œprint_per_category=Trueä¼šè¾“å‡ºCOCOè¯¦ç»†è¯„ä¼°è¡¨æ ¼
                mAP_metrics = self._compute_map_metrics(self._last_val_predictions, self._last_val_targets, print_per_category=True)
                per_category_map = mAP_metrics.get('per_category_map', {})
            else:
                # å¦‚æœæ²¡æœ‰ä¿å­˜çš„ç»“æœï¼Œåˆ™é‡æ–°è®¡ç®—ï¼ˆå…¼å®¹æ€§å¤„ç†ï¼‰
                self.logger.warning("æœªæ‰¾åˆ°ä¿å­˜çš„éªŒè¯ç»“æœï¼Œé‡æ–°è®¡ç®—æ¯ä¸ªç±»åˆ«mAP...")
                self.ema.module.eval()
                all_predictions = []
                all_targets = []
                
                with torch.no_grad():
                    for batch_idx, (images, targets) in enumerate(self.val_dataloader):
                        images = images.to(self.device)
                        targets = [{k: v.to(self.device) if isinstance(v, torch.Tensor) else v 
                                   for k, v in t.items()} for t in targets]
                        
                        outputs = self.ema.module(images, targets)
                        
                        # å…¼å®¹ä¸¤ç§è¾“å‡ºæ ¼å¼ï¼špred_logits/pred_boxes æˆ– class_scores/bboxes
                        has_predictions = (
                            ('pred_logits' in outputs and 'pred_boxes' in outputs) or
                            ('class_scores' in outputs and 'bboxes' in outputs)
                        )
                        if has_predictions:
                            self._collect_predictions(outputs, targets, batch_idx, all_predictions, all_targets)
                
                mAP_metrics = self._compute_map_metrics(all_predictions, all_targets, print_per_category=True)
                per_category_map = mAP_metrics.get('per_category_map', {})
        except Exception as e:
            self.logger.warning(f"æ‰“å°best_modelæ¯ç±»mAPå¤±è´¥: {e}")
    
    def _compute_map_metrics(self, predictions: List[Dict], targets: List[Dict], print_per_category: bool = False) -> Dict[str, float]:
        """è®¡ç®—mAPæŒ‡æ ‡ã€‚
        
        Args:
            predictions: é¢„æµ‹ç»“æœåˆ—è¡¨
            targets: çœŸå®æ ‡ç­¾åˆ—è¡¨
            print_per_category: æ˜¯å¦æ‰“å°æ¯ä¸ªç±»åˆ«çš„è¯¦ç»†mAPï¼ˆé»˜è®¤Falseï¼Œåªåœ¨best_modelæ—¶æ‰“å°ï¼‰
        """
        try:
            if len(predictions) == 0:
                return {
                    'mAP_0.5': 0.0,
                    'mAP_0.75': 0.0,
                    'mAP_0.5_0.95': 0.0
                }
            
            # è·å–ç±»åˆ«ä¿¡æ¯
            if hasattr(self, 'val_dataloader') and hasattr(self.val_dataloader.dataset, 'get_categories'):
                categories = self.val_dataloader.dataset.get_categories()
            else:
                categories = [
                    {'id': 1, 'name': 'Car'},
                    {'id': 2, 'name': 'Truck'},
                    {'id': 3, 'name': 'Van'},
                    {'id': 4, 'name': 'Bus'},
                    {'id': 5, 'name': 'Pedestrian'},
                    {'id': 6, 'name': 'Cyclist'},
                    {'id': 7, 'name': 'Motorcyclist'},
                    {'id': 8, 'name': 'Trafficcone'}
                ]
            
            # åˆ›å»ºCOCOæ ¼å¼æ•°æ®
            coco_gt = {
                'images': [],
                'annotations': [],
                'categories': categories,
                'info': {
                    'description': 'DAIR-V2X Dataset',
                    'version': '1.0',
                    'year': 2024
                }
            }
            
            # æ·»åŠ å›¾åƒä¿¡æ¯
            image_ids = set(target['image_id'] for target in targets)
            for img_id in image_ids:
                coco_gt['images'].append({
                    'id': img_id, 
                    'width': 640, 
                    'height': 640
                })
            
            # æ·»åŠ æ ‡æ³¨
            for i, target in enumerate(targets):
                target['id'] = i + 1
                coco_gt['annotations'].append(target)
            
            # ä½¿ç”¨pycocotoolsè¯„ä¼°ï¼ˆæŠ‘åˆ¶æ‰€æœ‰è¾“å‡ºä»¥èŠ‚çœæ—¶é—´ï¼‰
            from io import StringIO
            import sys
            
            coco_gt_obj = COCO()
            coco_gt_obj.dataset = coco_gt
            # æŠ‘åˆ¶createIndexçš„è¾“å‡º
            old_stdout = sys.stdout
            sys.stdout = StringIO()
            try:
                coco_gt_obj.createIndex()
            finally:
                sys.stdout = old_stdout
            
            # æŠ‘åˆ¶loadResçš„è¾“å‡º
            sys.stdout = StringIO()
            try:
                coco_dt = coco_gt_obj.loadRes(predictions)
            finally:
                sys.stdout = old_stdout
            
            coco_eval = COCOeval(coco_gt_obj, coco_dt, 'bbox')
            # å¦‚æœprint_per_category=Trueï¼ˆä¿å­˜best_modelæ—¶ï¼‰ï¼Œè¾“å‡ºCOCOè¯¦ç»†è¯„ä¼°è¡¨æ ¼ï¼›å¦åˆ™æŠ‘åˆ¶è¾“å‡º
            if print_per_category:
                # åªæŠ‘åˆ¶ä¸­é—´è¿‡ç¨‹è¾“å‡ºï¼Œä¿ç•™summaryè¡¨æ ¼
                sys.stdout = StringIO()
                try:
                    coco_eval.evaluate()
                    coco_eval.accumulate()
                finally:
                    sys.stdout = old_stdout
                # è¾“å‡ºsummaryè¡¨æ ¼
                coco_eval.summarize()
            else:
                # å®Œå…¨æŠ‘åˆ¶è¾“å‡º
                sys.stdout = StringIO()
                try:
                    coco_eval.evaluate()
                    coco_eval.accumulate()
                    coco_eval.summarize()
                finally:
                    sys.stdout = old_stdout
            
            # åªåœ¨éœ€è¦æ—¶ï¼ˆprint_per_category=Trueï¼‰æ‰è®¡ç®—æ¯ä¸ªç±»åˆ«çš„ mAPï¼Œé¿å…æ¯ä¸ªepochéƒ½è®¡ç®—8æ¬¡
            per_category_map = {}
            if print_per_category:
                # æå–æ¯ä¸ªç±»åˆ«çš„ mAP@0.5:0.95
                category_map = {cat['id']: cat['name'] for cat in categories}
                
                # æ–¹æ³•ï¼šä¸ºæ¯ä¸ªç±»åˆ«å•ç‹¬è®¡ç®— AP
                # é€šè¿‡è®¾ç½® catIds å‚æ•°ï¼Œåªè¯„ä¼°ç‰¹å®šç±»åˆ«
                cat_ids = coco_eval.params.catIds
                
                for cat_id, cat_name in category_map.items():
                    if cat_id in cat_ids:
                        try:
                            # ä¸ºå½“å‰ç±»åˆ«åˆ›å»ºå•ç‹¬çš„ COCOeval å¯¹è±¡
                            coco_eval_cat = COCOeval(coco_gt_obj, coco_dt, 'bbox')
                            coco_eval_cat.params.catIds = [cat_id]  # åªè¯„ä¼°å½“å‰ç±»åˆ«
                            # æŠ‘åˆ¶æ‰€æœ‰è¾“å‡ºï¼ˆevaluateã€accumulateã€summarizeéƒ½ä¼šäº§ç”Ÿè¾“å‡ºï¼‰
                            sys.stdout = StringIO()
                            try:
                                coco_eval_cat.evaluate()
                                coco_eval_cat.accumulate()
                                coco_eval_cat.summarize()
                            finally:
                                sys.stdout = old_stdout
                            
                            # æ£€æŸ¥ stats æ˜¯å¦å­˜åœ¨ä¸”æœ‰è¶³å¤Ÿçš„å…ƒç´ 
                            # stats[0] = AP@0.5:0.95, éœ€è¦ç¡®ä¿è‡³å°‘æœ‰1ä¸ªå…ƒç´ 
                            if hasattr(coco_eval_cat, 'stats') and len(coco_eval_cat.stats) > 0:
                                per_category_map[cat_name] = float(coco_eval_cat.stats[0])
                            else:
                                # å¦‚æœæ²¡æœ‰æ£€æµ‹ç»“æœï¼Œstats å¯èƒ½ä¸ºç©ºï¼Œè®¾ä¸º0
                                per_category_map[cat_name] = 0.0
                        except (IndexError, AttributeError, ValueError) as e:
                            # æ•è·å¯èƒ½çš„ç´¢å¼•é”™è¯¯ã€å±æ€§é”™è¯¯æˆ–å€¼é”™è¯¯
                            # å¦‚æœè¯¥ç±»åˆ«æ²¡æœ‰æ£€æµ‹ç»“æœï¼Œè¿™äº›é”™è¯¯æ˜¯æ­£å¸¸çš„
                            per_category_map[cat_name] = 0.0
                        except Exception as e:
                            # å…¶ä»–å¼‚å¸¸ä¹Ÿæ•è·ï¼Œç¡®ä¿ä¸ä¼šä¸­æ–­æ•´ä¸ªè¯„ä¼°è¿‡ç¨‹
                            self.logger.debug(f"ç±»åˆ« {cat_name} APè®¡ç®—å¤±è´¥: {e}")
                            per_category_map[cat_name] = 0.0
                    else:
                        per_category_map[cat_name] = 0.0
            
            # åªåœ¨best_modelæ—¶æ‰“å°æ¯ä¸ªç±»åˆ«çš„è¯¦ç»†mAP
            if print_per_category:
                self.logger.info("  æ¯ä¸ªç±»åˆ«çš„ mAP@0.5:0.95:")
                category_order = ['Car', 'Truck', 'Van', 'Bus', 'Pedestrian', 
                                'Cyclist', 'Motorcyclist', 'Trafficcone']
                for cat_name in category_order:
                    map_val = per_category_map.get(cat_name, 0.0)
                    self.logger.info(f"    {cat_name:12s}: {map_val:.4f}")
            
            result = {
                'mAP_0.5': coco_eval.stats[1],
                'mAP_0.75': coco_eval.stats[2],
                'mAP_0.5_0.95': coco_eval.stats[0],
                'per_category_map': per_category_map  # ä¿å­˜æ¯ä¸ªç±»åˆ«çš„mAP
            }
            
            # æ·»åŠ æ¯ä¸ªç±»åˆ«çš„æŒ‡æ ‡
            for cat_name in per_category_map.keys():
                result[f'mAP_{cat_name}'] = per_category_map[cat_name]
            
            return result
            
        except Exception as e:
            self.logger.warning(f"mAPè®¡ç®—å¤±è´¥: {e}")
            return {
                'mAP_0.5': 0.0,
                'mAP_0.75': 0.0,
                'mAP_0.5_0.95': 0.0
            }


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description='RT-DETRè®­ç»ƒè„šæœ¬')
    parser.add_argument('--backbone', type=str, default='presnet50', 
                       choices=['presnet18', 'presnet34', 'presnet50', 'presnet101',
                               'hgnetv2_l', 'hgnetv2_x', 'hgnetv2_h',
                               'cspresnet_s', 'cspresnet_m', 'cspresnet_l', 'cspresnet_x',
                               'cspdarknet', 'mresnet'],
                       help='Backboneç±»å‹')
    parser.add_argument('--data_root', type=str, default='datasets/DAIR-V2X', 
                       help='DAIR-V2Xæ•°æ®é›†è·¯å¾„')
    parser.add_argument('--epochs', type=int, default=100, help='è®­ç»ƒè½®æ•°')
    parser.add_argument('--batch_size', type=int, default=32, help='æ‰¹æ¬¡å¤§å°')
    parser.add_argument('--pretrained_lr', type=float, default=1e-5, help='é¢„è®­ç»ƒç»„ä»¶å­¦ä¹ ç‡')
    parser.add_argument('--new_lr', type=float, default=1e-4, help='æ–°ç»„ä»¶å­¦ä¹ ç‡')
    parser.add_argument('--warmup_epochs', type=int, default=3, 
                       help='å­¦ä¹ ç‡é¢„çƒ­è½®æ•°')
    parser.add_argument('--pretrained_weights', type=str, default=None,
                       help='é¢„è®­ç»ƒæƒé‡è·¯å¾„ï¼ˆRT-DETR COCOé¢„è®­ç»ƒæ¨¡å‹ï¼‰')
    parser.add_argument('--resume_from_checkpoint', type=str, default=None,
                       help='ä»æ£€æŸ¥ç‚¹æ¢å¤è®­ç»ƒï¼ˆæ£€æŸ¥ç‚¹æ–‡ä»¶è·¯å¾„ï¼‰')
    parser.add_argument('--config', type=str, default=None,
                       help='YAMLé…ç½®æ–‡ä»¶è·¯å¾„')
    parser.add_argument('--seed', type=int, default=42,
                       help='éšæœºç§å­ï¼Œç”¨äºç¡®ä¿å®éªŒå¯é‡å¤æ€§ï¼ˆé»˜è®¤ï¼š42ï¼‰')
    parser.add_argument('--deterministic', action='store_true',
                       help='ä½¿ç”¨ç¡®å®šæ€§ç®—æ³•ï¼ˆä¼šé™ä½é€Ÿåº¦ä½†ä¿è¯å®Œå…¨å¯é‡å¤ï¼‰')
    
    args = parser.parse_args()
    
    # è®¾ç½®éšæœºç§å­ï¼ˆå¿…é¡»åœ¨æ‰€æœ‰æ“ä½œä¹‹å‰ï¼‰
    print("\n" + "="*60)
    print("ğŸ”§ åˆå§‹åŒ–è®­ç»ƒç¯å¢ƒ")
    print("="*60)
    set_seed(args.seed, deterministic=args.deterministic)
    
    # åŠ è½½é…ç½®
    if args.config and args.config.endswith('.yaml'):
        # ä»YAMLæ–‡ä»¶åŠ è½½é…ç½®
        with open(args.config, 'r', encoding='utf-8') as f:
            config = yaml.safe_load(f)
        print(f"ğŸ“„ ä»é…ç½®æ–‡ä»¶åŠ è½½: {args.config}")
        
        # ç¡®ä¿å­¦ä¹ ç‡ç›¸å…³å€¼æ˜¯æµ®ç‚¹æ•°ï¼ˆYAMLä¸­çš„ç§‘å­¦è®¡æ•°æ³•å¯èƒ½è¢«è§£æä¸ºå­—ç¬¦ä¸²ï¼‰
        # ç›´æ¥ä½¿ç”¨é…ç½®æ–‡ä»¶ä¸­çš„å­—æ®µåï¼špretrained_lr, new_lr
        if 'training' in config:
            # ç±»å‹è½¬æ¢ç¡®ä¿æ˜¯æµ®ç‚¹æ•°
            if 'pretrained_lr' in config['training']:
                config['training']['pretrained_lr'] = float(config['training']['pretrained_lr'])
            if 'new_lr' in config['training']:
                config['training']['new_lr'] = float(config['training']['new_lr'])
            if 'eta_min' in config['training']:
                config['training']['eta_min'] = float(config['training']['eta_min'])
            if 'weight_decay' in config['training']:
                config['training']['weight_decay'] = float(config['training']['weight_decay'])
        
        # å…è®¸å‘½ä»¤è¡Œå‚æ•°è¦†ç›–é…ç½®æ–‡ä»¶
        if args.backbone != 'presnet50':
            config['model']['backbone'] = args.backbone
        if args.epochs != 100:
            config['training']['epochs'] = args.epochs
        if args.batch_size != 32:
            config['training']['batch_size'] = args.batch_size
        if args.pretrained_lr != 1e-5:
            config['training']['pretrained_lr'] = args.pretrained_lr
        if args.new_lr != 1e-4:
            config['training']['new_lr'] = args.new_lr
        if args.warmup_epochs != 3:
            config['training']['warmup_epochs'] = args.warmup_epochs
        if args.data_root != 'datasets/DAIR-V2X':
            config['data']['data_root'] = args.data_root
        if args.pretrained_weights:
            config['model']['pretrained_weights'] = args.pretrained_weights
    else:
        # åˆ›å»ºé»˜è®¤é…ç½®
        config = {
        'model': {
            'hidden_dim': 256,
            'num_queries': 100,
            'backbone': args.backbone
        },
        'data': {
            'data_root': args.data_root
        },
        'train_dataloader': {
            'dataset': 'DAIRV2XDetection',
            'batch_size': args.batch_size,
            'shuffle': True,
            'num_workers': 16,
            'collate_fn': None
        },
        'val_dataloader': {
            'dataset': 'DAIRV2XDetection',
            'batch_size': args.batch_size,
            'shuffle': False,
            'num_workers': 16,
            'collate_fn': None
        },
        'training': {
            'device': 'cuda',
            'epochs': args.epochs,
            'batch_size': args.batch_size,
            'new_lr': args.new_lr,
            'pretrained_lr': args.pretrained_lr,
            'weight_decay': 0.0001,
            'num_workers': 16,
            'save_interval': 10,
            'print_freq': 50,
            'log_dir': 'logs',
            'save_dir': 'checkpoints',
            'output_dir': 'checkpoints',
            'ema_decay': 0.9999,
            'scheduler': 'cosine',
            'eta_min': 0.0000001,
            'warmup_epochs': args.warmup_epochs,
            'clip_max_norm': 10.0
        },
        'validation': {
            'interval': 5,
            'metrics': ['mAP', 'mAP_50', 'mAP_75']
        },
        'augmentation': {
            'mixup': {'enabled': False, 'alpha': 0.2},
            'cutmix': {'enabled': False, 'alpha': 1.0},
            'mosaic': {'enabled': False, 'prob': 0.0}  # ç¦ç”¨Mosaicï¼Œä¸é€‚åˆè·¯æµ‹æ¢å¤´åœºæ™¯ï¼ˆä¼šç ´åç©ºé—´å…³ç³»ï¼‰
        },
        'misc': {
            'device': 'cuda',
            'num_workers': 16  # æ•°æ®åŠ è½½å™¨workeræ•°é‡
        }
    }
    
    # åˆ›å»ºè®­ç»ƒå™¨
    # å¦‚æœä½¿ç”¨é…ç½®æ–‡ä»¶ï¼Œåªä¼ é€’æ˜¾å¼ä¼ é€’çš„å‚æ•°ï¼ˆä¸ç­‰äºé»˜è®¤å€¼çš„ï¼‰ï¼Œå…¶ä»–ä¼ é€’Noneè®©é…ç½®æ–‡ä»¶çš„å€¼ç”Ÿæ•ˆ
    if args.config and args.config.endswith('.yaml'):
        # ä½¿ç”¨é…ç½®æ–‡ä»¶ï¼šåªä¼ é€’æ˜¾å¼ä¼ é€’çš„å‚æ•°ï¼Œé»˜è®¤å€¼å‚æ•°ä¼ é€’None
        data_root_arg = None if args.data_root == 'datasets/DAIR-V2X' else args.data_root
        epochs_arg = None if args.epochs == 100 else args.epochs
        batch_size_arg = None if args.batch_size == 32 else args.batch_size
        warmup_epochs_arg = None if args.warmup_epochs == 3 else args.warmup_epochs
    else:
        # ä¸ä½¿ç”¨é…ç½®æ–‡ä»¶ï¼šä¼ é€’æ‰€æœ‰å‚æ•°ï¼ˆåŒ…æ‹¬é»˜è®¤å€¼ï¼‰
        data_root_arg = args.data_root
        epochs_arg = args.epochs
        batch_size_arg = args.batch_size
        warmup_epochs_arg = args.warmup_epochs
    
    trainer = RTDETRTrainer(
        config=config,
        pretrained_weights=args.pretrained_weights,
        data_root=data_root_arg,
        epochs=epochs_arg,
        batch_size=batch_size_arg,
        warmup_epochs=warmup_epochs_arg
    )
    
    # å¼€å§‹è®­ç»ƒ
    trainer.start_training(resume_checkpoint=args.resume_from_checkpoint)


if __name__ == '__main__':
    main()

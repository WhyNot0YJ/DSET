auto_scale_lr:
  base_batch_size: 16
  enable: true
backend_args: null
custom_hooks:
- min_delta: 0.0001
  monitor: coco/bbox_mAP
  patience: 20
  rule: greater
  type: EarlyStoppingHook
data_root: /root/autodl-tmp/datasets/DAIR-V2X/
dataset_type: CocoDataset
default_hooks:
  checkpoint:
    interval: 1
    max_keep_ckpts: 1
    rule: greater
    save_best: coco/bbox_mAP
    type: CheckpointHook
  logger:
    interval: 50
    type: LoggerHook
  param_scheduler:
    type: ParamSchedulerHook
  sampler_seed:
    type: DistSamplerSeedHook
  timer:
    type: IterTimerHook
  visualization:
    type: DetVisualizationHook
default_scope: mmdet
env_cfg:
  cudnn_benchmark: false
  dist_cfg:
    backend: nccl
  mp_cfg:
    mp_start_method: fork
    opencv_num_threads: 0
load_from: null
log_level: INFO
log_processor:
  by_epoch: true
  type: LogProcessor
  window_size: 50
max_epochs: 50
model:
  as_two_stage: false
  backbone:
    depth: 18
    frozen_stages: 1
    init_cfg:
      checkpoint: torchvision://resnet18
      type: Pretrained
    norm_cfg:
      requires_grad: false
      type: BN
    norm_eval: true
    num_stages: 4
    out_indices: !!python/tuple
    - 1
    - 2
    - 3
    style: pytorch
    type: ResNet
  bbox_head:
    loss_bbox:
      loss_weight: 5.0
      type: L1Loss
    loss_cls:
      alpha: 0.25
      gamma: 2.0
      loss_weight: 2.0
      type: FocalLoss
      use_sigmoid: true
    loss_iou:
      loss_weight: 2.0
      type: GIoULoss
    num_classes: 8
    sync_cls_avg_factor: true
    type: DeformableDETRHead
  data_preprocessor:
    bgr_to_rgb: true
    mean:
    - 123.675
    - 116.28
    - 103.53
    pad_size_divisor: 1
    std:
    - 58.395
    - 57.12
    - 57.375
    type: DetDataPreprocessor
  decoder:
    layer_cfg:
      cross_attn_cfg:
        batch_first: true
        embed_dims: 256
      ffn_cfg:
        embed_dims: 256
        feedforward_channels: 1024
        ffn_drop: 0.1
      self_attn_cfg:
        batch_first: true
        dropout: 0.1
        embed_dims: 256
        num_heads: 8
    num_layers: 6
    post_norm_cfg: null
    return_intermediate: true
  encoder:
    layer_cfg:
      ffn_cfg:
        embed_dims: 256
        feedforward_channels: 1024
        ffn_drop: 0.1
      self_attn_cfg:
        batch_first: true
        embed_dims: 256
    num_layers: 6
  neck:
    act_cfg: null
    in_channels:
    - 128
    - 256
    - 512
    kernel_size: 1
    norm_cfg:
      num_groups: 32
      type: GN
    num_outs: 4
    out_channels: 256
    type: ChannelMapper
  num_feature_levels: 4
  num_queries: 100
  positional_encoding:
    normalize: true
    num_feats: 128
    offset: -0.5
  test_cfg:
    max_per_img: 100
  train_cfg:
    assigner:
      match_costs:
      - type: FocalLossCost
        weight: 2.0
      - box_format: xywh
        type: BBoxL1Cost
        weight: 5.0
      - iou_mode: giou
        type: IoUCost
        weight: 2.0
      type: HungarianAssigner
  type: DeformableDETR
  with_box_refine: false
optim_wrapper:
  clip_grad:
    max_norm: 0.1
    norm_type: 2
  loss_scale: dynamic
  optimizer:
    lr: 0.0002
    type: AdamW
    weight_decay: 0.0001
  paramwise_cfg:
    custom_keys:
      backbone:
        lr_mult: 0.1
      reference_points:
        lr_mult: 0.1
      sampling_offsets:
        lr_mult: 0.1
  type: AmpOptimWrapper
param_scheduler:
- begin: 0
  by_epoch: false
  end: 500
  start_factor: 0.001
  type: LinearLR
- begin: 0
  by_epoch: true
  end: 200
  gamma: 0.1
  milestones:
  - 160
  type: MultiStepLR
resume: false
test_cfg:
  type: TestLoop
test_dataloader:
  batch_size: 16
  dataset:
    ann_file: annotations/instances_val.json
    backend_args: null
    data_prefix:
      img: ''
    data_root: /root/autodl-tmp/datasets/DAIR-V2X/
    metainfo:
      classes: !!python/tuple
      - Car
      - Truck
      - Van
      - Bus
      - Pedestrian
      - Cyclist
      - Motorcyclist
      - Trafficcone
    pipeline:
    - backend_args: null
      type: LoadImageFromFile
    - keep_ratio: true
      scale: !!python/tuple
      - 1280
      - 720
      type: Resize
    - type: LoadAnnotations
      with_bbox: true
    - meta_keys: !!python/tuple
      - img_id
      - img_path
      - ori_shape
      - img_shape
      - scale_factor
      type: PackDetInputs
    test_mode: true
    type: CocoDataset
  drop_last: false
  num_workers: 16
  persistent_workers: true
  sampler:
    shuffle: false
    type: DefaultSampler
test_evaluator:
  ann_file: /root/autodl-tmp/datasets/DAIR-V2X/annotations/instances_val.json
  backend_args: null
  format_only: false
  metric: bbox
  metric_items:
  - mAP
  - mAP_50
  - mAP_75
  - mAP_s
  - mAP_m
  - mAP_l
  proposal_nums: !!python/tuple
  - 1
  - 10
  - 100
  type: CocoMetric
test_pipeline:
- backend_args: null
  type: LoadImageFromFile
- keep_ratio: true
  scale: !!python/tuple
  - 1333
  - 800
  type: Resize
- type: LoadAnnotations
  with_bbox: true
- meta_keys: !!python/tuple
  - img_id
  - img_path
  - ori_shape
  - img_shape
  - scale_factor
  type: PackDetInputs
train_cfg:
  max_epochs: 200
  type: EpochBasedTrainLoop
  val_interval: 1
train_dataloader:
  batch_sampler:
    type: AspectRatioBatchSampler
  batch_size: 8
  dataset:
    ann_file: annotations/instances_train.json
    backend_args: null
    data_prefix:
      img: ''
    data_root: /root/autodl-tmp/datasets/DAIR-V2X/
    filter_cfg:
      filter_empty_gt: false
      min_size: 32
    metainfo:
      classes: !!python/tuple
      - Car
      - Truck
      - Van
      - Bus
      - Pedestrian
      - Cyclist
      - Motorcyclist
      - Trafficcone
    pipeline:
    - backend_args: null
      type: LoadImageFromFile
    - type: LoadAnnotations
      with_bbox: true
    - type: PhotoMetricDistortion
    - min_crop_size: 0.1
      type: MinIoURandomCrop
    - prob: 0.5
      type: RandomFlip
    - keep_ratio: true
      scales:
      - !!python/tuple
        - 1280
        - 480
      - !!python/tuple
        - 1280
        - 512
      - !!python/tuple
        - 1280
        - 544
      - !!python/tuple
        - 1280
        - 576
      - !!python/tuple
        - 1280
        - 608
      - !!python/tuple
        - 1280
        - 640
      - !!python/tuple
        - 1280
        - 672
      - !!python/tuple
        - 1280
        - 704
      - !!python/tuple
        - 1280
        - 736
      - !!python/tuple
        - 1280
        - 768
      - !!python/tuple
        - 1280
        - 800
      type: RandomChoiceResize
    - type: PackDetInputs
    type: CocoDataset
  num_workers: 16
  persistent_workers: true
  sampler:
    shuffle: true
    type: DefaultSampler
train_pipeline:
- backend_args: null
  type: LoadImageFromFile
- type: LoadAnnotations
  with_bbox: true
- prob: 0.5
  type: RandomFlip
- transforms:
  - - keep_ratio: true
      scales:
      - !!python/tuple
        - 480
        - 1333
      - !!python/tuple
        - 512
        - 1333
      - !!python/tuple
        - 544
        - 1333
      - !!python/tuple
        - 576
        - 1333
      - !!python/tuple
        - 608
        - 1333
      - !!python/tuple
        - 640
        - 1333
      - !!python/tuple
        - 672
        - 1333
      - !!python/tuple
        - 704
        - 1333
      - !!python/tuple
        - 736
        - 1333
      - !!python/tuple
        - 768
        - 1333
      - !!python/tuple
        - 800
        - 1333
      type: RandomChoiceResize
  - - keep_ratio: true
      scales:
      - !!python/tuple
        - 400
        - 4200
      - !!python/tuple
        - 500
        - 4200
      - !!python/tuple
        - 600
        - 4200
      type: RandomChoiceResize
    - allow_negative_crop: true
      crop_size: !!python/tuple
      - 384
      - 600
      crop_type: absolute_range
      type: RandomCrop
    - keep_ratio: true
      scales:
      - !!python/tuple
        - 480
        - 1333
      - !!python/tuple
        - 512
        - 1333
      - !!python/tuple
        - 544
        - 1333
      - !!python/tuple
        - 576
        - 1333
      - !!python/tuple
        - 608
        - 1333
      - !!python/tuple
        - 640
        - 1333
      - !!python/tuple
        - 672
        - 1333
      - !!python/tuple
        - 704
        - 1333
      - !!python/tuple
        - 736
        - 1333
      - !!python/tuple
        - 768
        - 1333
      - !!python/tuple
        - 800
        - 1333
      type: RandomChoiceResize
  type: RandomChoice
- type: PackDetInputs
val_cfg:
  type: ValLoop
val_dataloader:
  batch_size: 16
  dataset:
    ann_file: annotations/instances_val.json
    backend_args: null
    data_prefix:
      img: ''
    data_root: /root/autodl-tmp/datasets/DAIR-V2X/
    metainfo:
      classes: !!python/tuple
      - Car
      - Truck
      - Van
      - Bus
      - Pedestrian
      - Cyclist
      - Motorcyclist
      - Trafficcone
    pipeline:
    - backend_args: null
      type: LoadImageFromFile
    - keep_ratio: true
      scale: !!python/tuple
      - 1280
      - 720
      type: Resize
    - type: LoadAnnotations
      with_bbox: true
    - meta_keys: !!python/tuple
      - img_id
      - img_path
      - ori_shape
      - img_shape
      - scale_factor
      type: PackDetInputs
    test_mode: true
    type: CocoDataset
  drop_last: false
  num_workers: 16
  persistent_workers: true
  sampler:
    shuffle: false
    type: DefaultSampler
val_evaluator:
  ann_file: /root/autodl-tmp/datasets/DAIR-V2X/annotations/instances_val.json
  backend_args: null
  format_only: false
  metric: bbox
  metric_items:
  - mAP
  - mAP_50
  - mAP_75
  - mAP_s
  - mAP_m
  - mAP_l
  proposal_nums: !!python/tuple
  - 1
  - 10
  - 100
  type: CocoMetric
vis_backends:
- type: LocalVisBackend
visualizer:
  name: visualizer
  type: DetLocalVisualizer
  vis_backends:
  - type: LocalVisBackend
work_dir: /root/autodl-tmp/DSET/experiments/deformable-detr/work_dirs/r18_baseline
